/* Generated by CIL v. 1.5.1 */
/* print_CIL_Input is false */

#line 40 "/usr/lib/gcc/x86_64-linux-gnu/4.6/include/stdarg.h"
typedef __builtin_va_list __gnuc_va_list[1U];
#line 102 "/usr/lib/gcc/x86_64-linux-gnu/4.6/include/stdarg.h"
typedef __gnuc_va_list va_list[1U];
#line 11 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef unsigned int __kernel_mode_t;
#line 12 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef unsigned long __kernel_nlink_t;
#line 13 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef long __kernel_off_t;
#line 14 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef int __kernel_pid_t;
#line 16 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef unsigned int __kernel_uid_t;
#line 17 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef unsigned int __kernel_gid_t;
#line 18 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef unsigned long __kernel_size_t;
#line 19 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef long __kernel_ssize_t;
#line 21 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef long __kernel_time_t;
#line 23 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef long __kernel_clock_t;
#line 24 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef int __kernel_timer_t;
#line 25 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef int __kernel_clockid_t;
#line 32 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef long long __kernel_loff_t;
#line 41 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef __kernel_uid_t __kernel_uid32_t;
#line 42 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/posix_types_64.h"
typedef __kernel_gid_t __kernel_gid32_t;
#line 17 "include/asm-generic/int-ll64.h"
typedef signed char __s8;
#line 20 "include/asm-generic/int-ll64.h"
typedef short __s16;
#line 21 "include/asm-generic/int-ll64.h"
typedef unsigned short __u16;
#line 23 "include/asm-generic/int-ll64.h"
typedef int __s32;
#line 24 "include/asm-generic/int-ll64.h"
typedef unsigned int __u32;
#line 27 "include/asm-generic/int-ll64.h"
typedef long long __s64;
#line 28 "include/asm-generic/int-ll64.h"
typedef unsigned long long __u64;
#line 40 "include/asm-generic/int-ll64.h"
typedef signed char s8;
#line 41 "include/asm-generic/int-ll64.h"
typedef unsigned char u8;
#line 44 "include/asm-generic/int-ll64.h"
typedef unsigned short u16;
#line 46 "include/asm-generic/int-ll64.h"
typedef int s32;
#line 47 "include/asm-generic/int-ll64.h"
typedef unsigned int u32;
#line 49 "include/asm-generic/int-ll64.h"
typedef long long s64;
#line 50 "include/asm-generic/int-ll64.h"
typedef unsigned long long u64;
#line 8 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/types.h"
typedef unsigned short umode_t;
#line 28 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/types.h"
typedef u64 dma_addr_t;
#line 16 "include/linux/types.h"
typedef __u32 __kernel_dev_t;
#line 19 "include/linux/types.h"
typedef __kernel_dev_t dev_t;
#line 21 "include/linux/types.h"
typedef __kernel_mode_t mode_t;
#line 22 "include/linux/types.h"
typedef __kernel_nlink_t nlink_t;
#line 23 "include/linux/types.h"
typedef __kernel_off_t off_t;
#line 24 "include/linux/types.h"
typedef __kernel_pid_t pid_t;
#line 28 "include/linux/types.h"
typedef __kernel_timer_t timer_t;
#line 29 "include/linux/types.h"
typedef __kernel_clockid_t clockid_t;
#line 33 "include/linux/types.h"
typedef _Bool bool;
#line 35 "include/linux/types.h"
typedef __kernel_uid32_t uid_t;
#line 36 "include/linux/types.h"
typedef __kernel_gid32_t gid_t;
#line 57 "include/linux/types.h"
typedef __kernel_loff_t loff_t;
#line 66 "include/linux/types.h"
typedef __kernel_size_t size_t;
#line 71 "include/linux/types.h"
typedef __kernel_ssize_t ssize_t;
#line 81 "include/linux/types.h"
typedef __kernel_time_t time_t;
#line 86 "include/linux/types.h"
typedef __kernel_clock_t clock_t;
#line 120 "include/linux/types.h"
typedef __u32 uint32_t;
#line 142 "include/linux/types.h"
typedef unsigned long sector_t;
#line 151 "include/linux/types.h"
typedef unsigned long blkcnt_t;
#line 192 "include/linux/types.h"
typedef unsigned int gfp_t;
#line 193 "include/linux/types.h"
typedef unsigned int fmode_t;
#line 196 "include/linux/types.h"
typedef u64 phys_addr_t;
#line 201 "include/linux/types.h"
typedef phys_addr_t resource_size_t;
#line 58 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/alternative.h"
struct module;
#line 37 "include/linux/dynamic_printk.h"
struct bug_entry {
   unsigned long bug_addr ;
   char const   *file ;
   unsigned short line ;
   unsigned short flags ;
};
#line 102 "include/linux/kernel.h"
struct completion;
#line 103
struct pt_regs;
#line 191
struct pid;
#line 507
struct task_struct;
#line 508
struct mm_struct;
#line 51 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/ds.h"
typedef void (*ds_ovfl_callback_t)(struct task_struct * );
#line 204 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/ds.h"
struct ds_context {
   unsigned char *ds ;
   struct task_struct *owner[2U] ;
   ds_ovfl_callback_t callback[2U] ;
   void *buffer[2U] ;
   unsigned int pages[2U] ;
   unsigned long count ;
   struct ds_context **this ;
   struct task_struct *task ;
};
#line 206 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/segment.h"
struct pt_regs {
   unsigned long r15 ;
   unsigned long r14 ;
   unsigned long r13 ;
   unsigned long r12 ;
   unsigned long bp ;
   unsigned long bx ;
   unsigned long r11 ;
   unsigned long r10 ;
   unsigned long r9 ;
   unsigned long r8 ;
   unsigned long ax ;
   unsigned long cx ;
   unsigned long dx ;
   unsigned long si ;
   unsigned long di ;
   unsigned long orig_ax ;
   unsigned long ip ;
   unsigned long cs ;
   unsigned long flags ;
   unsigned long sp ;
   unsigned long ss ;
};
#line 203 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/vm86.h"
struct info {
   long ___orig_eip ;
   long ___ebx ;
   long ___ecx ;
   long ___edx ;
   long ___esi ;
   long ___edi ;
   long ___ebp ;
   long ___eax ;
   long ___ds ;
   long ___es ;
   long ___fs ;
   long ___orig_eax ;
   long ___eip ;
   long ___cs ;
   long ___eflags ;
   long ___esp ;
   long ___ss ;
   long ___vm86_es ;
   long ___vm86_ds ;
   long ___vm86_fs ;
   long ___vm86_gs ;
};
#line 80 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page_64.h"
typedef unsigned long pgdval_t;
#line 81 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page_64.h"
typedef unsigned long pgprotval_t;
#line 83
struct page;
#line 56 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page.h"
struct __anonstruct_pgd_t_7 {
   pgdval_t pgd ;
};
#line 56 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page.h"
typedef struct __anonstruct_pgd_t_7 pgd_t;
#line 57 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page.h"
struct __anonstruct_pgprot_t_8 {
   pgprotval_t pgprot ;
};
#line 57 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page.h"
typedef struct __anonstruct_pgprot_t_8 pgprot_t;
#line 154 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page.h"
struct __anonstruct_ldv_2034_12 {
   unsigned int a ;
   unsigned int b ;
};
#line 154 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page.h"
struct __anonstruct_ldv_2049_13 {
   u16 limit0 ;
   u16 base0 ;
   unsigned char base1 ;
   unsigned char type : 4 ;
   unsigned char s : 1 ;
   unsigned char dpl : 2 ;
   unsigned char p : 1 ;
   unsigned char limit : 4 ;
   unsigned char avl : 1 ;
   unsigned char l : 1 ;
   unsigned char d : 1 ;
   unsigned char g : 1 ;
   unsigned char base2 ;
};
#line 154 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page.h"
union __anonunion_ldv_2050_11 {
   struct __anonstruct_ldv_2034_12 ldv_2034 ;
   struct __anonstruct_ldv_2049_13 ldv_2049 ;
};
#line 154 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/page.h"
struct desc_struct {
   union __anonunion_ldv_2050_11 ldv_2050 ;
};
#line 289 "include/linux/bitmap.h"
struct cpumask {
   unsigned long bits[1U] ;
};
#line 144 "include/linux/cpumask.h"
typedef struct cpumask cpumask_t;
#line 1102
struct thread_struct;
#line 324 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/paravirt.h"
struct raw_spinlock;
#line 220 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/msr.h"
struct exec_domain;
#line 87 "include/linux/personality.h"
struct map_segment;
#line 87 "include/linux/personality.h"
struct exec_domain {
   char const   *name ;
   void (*handler)(int  , struct pt_regs * ) ;
   unsigned char pers_low ;
   unsigned char pers_high ;
   unsigned long *signal_map ;
   unsigned long *signal_invmap ;
   struct map_segment *err_map ;
   struct map_segment *socktype_map ;
   struct map_segment *sockopt_map ;
   struct map_segment *af_map ;
   struct module *module ;
   struct exec_domain *next ;
};
#line 282 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct i387_fsave_struct {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u32 status ;
};
#line 300 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct __anonstruct_ldv_4633_15 {
   u64 rip ;
   u64 rdp ;
};
#line 300 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct __anonstruct_ldv_4639_16 {
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
};
#line 300 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
union __anonunion_ldv_4640_14 {
   struct __anonstruct_ldv_4633_15 ldv_4633 ;
   struct __anonstruct_ldv_4639_16 ldv_4639 ;
};
#line 300 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
union __anonunion_ldv_4649_17 {
   u32 padding1[12U] ;
   u32 sw_reserved[12U] ;
};
#line 300 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct i387_fxsave_struct {
   u16 cwd ;
   u16 swd ;
   u16 twd ;
   u16 fop ;
   union __anonunion_ldv_4640_14 ldv_4640 ;
   u32 mxcsr ;
   u32 mxcsr_mask ;
   u32 st_space[32U] ;
   u32 xmm_space[64U] ;
   u32 padding[12U] ;
   union __anonunion_ldv_4649_17 ldv_4649 ;
};
#line 334 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct i387_soft_struct {
   u32 cwd ;
   u32 swd ;
   u32 twd ;
   u32 fip ;
   u32 fcs ;
   u32 foo ;
   u32 fos ;
   u32 st_space[20U] ;
   u8 ftop ;
   u8 changed ;
   u8 lookahead ;
   u8 no_update ;
   u8 rm ;
   u8 alimit ;
   struct info *info ;
   u32 entry_eip ;
};
#line 355 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct xsave_hdr_struct {
   u64 xstate_bv ;
   u64 reserved1[2U] ;
   u64 reserved2[5U] ;
};
#line 361 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct xsave_struct {
   struct i387_fxsave_struct i387 ;
   struct xsave_hdr_struct xsave_hdr ;
};
#line 366 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
union thread_xstate {
   struct i387_fsave_struct fsave ;
   struct i387_fxsave_struct fxsave ;
   struct i387_soft_struct soft ;
   struct xsave_struct xsave ;
};
#line 382
struct kmem_cache;
#line 386 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct thread_struct {
   struct desc_struct tls_array[3U] ;
   unsigned long sp0 ;
   unsigned long sp ;
   unsigned long usersp ;
   unsigned short es ;
   unsigned short ds ;
   unsigned short fsindex ;
   unsigned short gsindex ;
   unsigned long ip ;
   unsigned long fs ;
   unsigned long gs ;
   unsigned long debugreg0 ;
   unsigned long debugreg1 ;
   unsigned long debugreg2 ;
   unsigned long debugreg3 ;
   unsigned long debugreg6 ;
   unsigned long debugreg7 ;
   unsigned long cr2 ;
   unsigned long trap_no ;
   unsigned long error_code ;
   union thread_xstate *xstate ;
   unsigned long *io_bitmap_ptr ;
   unsigned long iopl ;
   unsigned int io_bitmap_max ;
   unsigned long debugctlmsr ;
   struct ds_context *ds_ctx ;
   unsigned int bts_ovfl_signal ;
};
#line 591 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
struct __anonstruct_mm_segment_t_18 {
   unsigned long seg ;
};
#line 591 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/processor.h"
typedef struct __anonstruct_mm_segment_t_18 mm_segment_t;
#line 56 "include/linux/prefetch.h"
struct list_head {
   struct list_head *next ;
   struct list_head *prev ;
};
#line 327 "include/linux/list.h"
struct hlist_node;
#line 327 "include/linux/list.h"
struct hlist_head {
   struct hlist_node *first ;
};
#line 543 "include/linux/list.h"
struct hlist_node {
   struct hlist_node *next ;
   struct hlist_node **pprev ;
};
#line 112 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/stat.h"
struct timespec;
#line 113
struct compat_timespec;
#line 114 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/stat.h"
struct __anonstruct_ldv_5073_20 {
   unsigned long arg0 ;
   unsigned long arg1 ;
   unsigned long arg2 ;
   unsigned long arg3 ;
};
#line 114 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/stat.h"
struct __anonstruct_futex_21 {
   u32 *uaddr ;
   u32 val ;
   u32 flags ;
   u32 bitset ;
   u64 time ;
};
#line 114 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/stat.h"
struct __anonstruct_nanosleep_22 {
   clockid_t index ;
   struct timespec *rmtp ;
   struct compat_timespec *compat_rmtp ;
   u64 expires ;
};
#line 114
struct pollfd;
#line 114 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/stat.h"
struct __anonstruct_poll_23 {
   struct pollfd *ufds ;
   int nfds ;
   int has_timeout ;
   unsigned long tv_sec ;
   unsigned long tv_nsec ;
};
#line 114 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/stat.h"
union __anonunion_ldv_5095_19 {
   struct __anonstruct_ldv_5073_20 ldv_5073 ;
   struct __anonstruct_futex_21 futex ;
   struct __anonstruct_nanosleep_22 nanosleep ;
   struct __anonstruct_poll_23 poll ;
};
#line 114 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/stat.h"
struct restart_block {
   long (*fn)(struct restart_block * ) ;
   union __anonunion_ldv_5095_19 ldv_5095 ;
};
#line 53 "include/linux/thread_info.h"
struct thread_info {
   struct task_struct *task ;
   struct exec_domain *exec_domain ;
   unsigned long flags ;
   __u32 status ;
   __u32 cpu ;
   int preempt_count ;
   mm_segment_t addr_limit ;
   struct restart_block restart_block ;
   void *sysenter_return ;
};
#line 9 "include/linux/bottom_half.h"
struct raw_spinlock {
   unsigned int slock ;
};
#line 10 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/spinlock_types.h"
typedef struct raw_spinlock raw_spinlock_t;
#line 16 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/spinlock_types.h"
struct __anonstruct_raw_rwlock_t_24 {
   unsigned int lock ;
};
#line 16 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/spinlock_types.h"
typedef struct __anonstruct_raw_rwlock_t_24 raw_rwlock_t;
#line 17
struct lockdep_map;
#line 48 "include/linux/debug_locks.h"
struct stack_trace {
   unsigned int nr_entries ;
   unsigned int max_entries ;
   unsigned long *entries ;
   int skip ;
};
#line 31 "include/linux/stacktrace.h"
struct lockdep_subclass_key {
   char __one_byte ;
};
#line 71 "include/linux/lockdep.h"
struct lock_class_key {
   struct lockdep_subclass_key subkeys[8U] ;
};
#line 75 "include/linux/lockdep.h"
struct lock_class {
   struct list_head hash_entry ;
   struct list_head lock_entry ;
   struct lockdep_subclass_key *key ;
   unsigned int subclass ;
   unsigned int dep_gen_id ;
   unsigned long usage_mask ;
   struct stack_trace usage_traces[9U] ;
   struct list_head locks_after ;
   struct list_head locks_before ;
   unsigned int version ;
   unsigned long ops ;
   char const   *name ;
   int name_version ;
   unsigned long contention_point[4U] ;
};
#line 156 "include/linux/lockdep.h"
struct lockdep_map {
   struct lock_class_key *key ;
   struct lock_class *class_cache ;
   char const   *name ;
   int cpu ;
};
#line 192 "include/linux/lockdep.h"
struct held_lock {
   u64 prev_chain_key ;
   unsigned long acquire_ip ;
   struct lockdep_map *instance ;
   struct lockdep_map *nest_lock ;
   u64 waittime_stamp ;
   u64 holdtime_stamp ;
   unsigned short class_idx : 13 ;
   unsigned char irq_context : 2 ;
   unsigned char trylock : 1 ;
   unsigned char read : 2 ;
   unsigned char check : 2 ;
   unsigned char hardirqs_off : 1 ;
};
#line 32 "include/linux/spinlock_types.h"
struct __anonstruct_spinlock_t_25 {
   raw_spinlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
#line 32 "include/linux/spinlock_types.h"
typedef struct __anonstruct_spinlock_t_25 spinlock_t;
#line 48 "include/linux/spinlock_types.h"
struct __anonstruct_rwlock_t_26 {
   raw_rwlock_t raw_lock ;
   unsigned int magic ;
   unsigned int owner_cpu ;
   void *owner ;
   struct lockdep_map dep_map ;
};
#line 48 "include/linux/spinlock_types.h"
typedef struct __anonstruct_rwlock_t_26 rwlock_t;
#line 21 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic_64.h"
struct __anonstruct_atomic_t_27 {
   int counter ;
};
#line 21 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic_64.h"
typedef struct __anonstruct_atomic_t_27 atomic_t;
#line 198 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic_64.h"
struct __anonstruct_atomic64_t_28 {
   long counter ;
};
#line 198 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic_64.h"
typedef struct __anonstruct_atomic64_t_28 atomic64_t;
#line 23 "include/asm-generic/atomic.h"
typedef atomic64_t atomic_long_t;
#line 104 "include/linux/math64.h"
struct timespec {
   time_t tv_sec ;
   long tv_nsec ;
};
#line 219 "include/linux/time.h"
struct kstat {
   u64 ino ;
   dev_t dev ;
   umode_t mode ;
   unsigned int nlink ;
   uid_t uid ;
   gid_t gid ;
   dev_t rdev ;
   loff_t size ;
   struct timespec atime ;
   struct timespec mtime ;
   struct timespec ctime ;
   unsigned long blksize ;
   unsigned long long blocks ;
};
#line 28 "include/linux/wait.h"
struct __wait_queue;
#line 28 "include/linux/wait.h"
typedef struct __wait_queue wait_queue_t;
#line 31 "include/linux/wait.h"
struct __wait_queue {
   unsigned int flags ;
   void *private ;
   int (*func)(wait_queue_t * , unsigned int  , int  , void * ) ;
   struct list_head task_list ;
};
#line 49 "include/linux/wait.h"
struct __wait_queue_head {
   spinlock_t lock ;
   struct list_head task_list ;
};
#line 54 "include/linux/wait.h"
typedef struct __wait_queue_head wait_queue_head_t;
#line 92 "include/linux/nodemask.h"
struct __anonstruct_nodemask_t_30 {
   unsigned long bits[1U] ;
};
#line 92 "include/linux/nodemask.h"
typedef struct __anonstruct_nodemask_t_30 nodemask_t;
#line 630 "include/linux/mmzone.h"
struct mutex {
   atomic_t count ;
   spinlock_t wait_lock ;
   struct list_head wait_list ;
   struct thread_info *owner ;
   char const   *name ;
   void *magic ;
   struct lockdep_map dep_map ;
};
#line 61 "include/linux/mutex.h"
struct mutex_waiter {
   struct list_head list ;
   struct task_struct *task ;
   struct mutex *lock ;
   void *magic ;
};
#line 150
struct rw_semaphore;
#line 152 "include/linux/mutex.h"
struct rw_semaphore {
   __s32 activity ;
   spinlock_t wait_lock ;
   struct list_head wait_list ;
   struct lockdep_map dep_map ;
};
#line 740 "include/linux/mmzone.h"
struct file;
#line 32 "include/linux/pm.h"
struct device;
#line 33 "include/linux/pm.h"
struct pm_message {
   int event ;
};
#line 41 "include/linux/pm.h"
typedef struct pm_message pm_message_t;
#line 42 "include/linux/pm.h"
struct pm_ops {
   int (*prepare)(struct device * ) ;
   void (*complete)(struct device * ) ;
   int (*suspend)(struct device * ) ;
   int (*resume)(struct device * ) ;
   int (*freeze)(struct device * ) ;
   int (*thaw)(struct device * ) ;
   int (*poweroff)(struct device * ) ;
   int (*restore)(struct device * ) ;
};
#line 155 "include/linux/pm.h"
struct pm_ext_ops {
   struct pm_ops base ;
   int (*suspend_noirq)(struct device * ) ;
   int (*resume_noirq)(struct device * ) ;
   int (*freeze_noirq)(struct device * ) ;
   int (*thaw_noirq)(struct device * ) ;
   int (*poweroff_noirq)(struct device * ) ;
   int (*restore_noirq)(struct device * ) ;
};
#line 212
enum dpm_state {
    DPM_INVALID = 0,
    DPM_ON = 1,
    DPM_PREPARING = 2,
    DPM_RESUMING = 3,
    DPM_SUSPENDING = 4,
    DPM_OFF = 5,
    DPM_OFF_IRQ = 6
} ;
#line 222 "include/linux/pm.h"
struct dev_pm_info {
   pm_message_t power_state ;
   unsigned char can_wakeup : 1 ;
   unsigned char should_wakeup : 1 ;
   enum dpm_state status ;
   struct list_head entry ;
};
#line 16 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/mmu.h"
struct __anonstruct_mm_context_t_78 {
   void *ldt ;
   int size ;
   struct mutex lock ;
   void *vdso ;
};
#line 16 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/mmu.h"
typedef struct __anonstruct_mm_context_t_78 mm_context_t;
#line 237 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/topology.h"
struct pci_bus;
#line 1081 "include/linux/mmzone.h"
struct vm_area_struct;
#line 33 "include/linux/kmod.h"
struct key;
#line 27 "include/linux/elf.h"
typedef __u64 Elf64_Addr;
#line 28 "include/linux/elf.h"
typedef __u16 Elf64_Half;
#line 32 "include/linux/elf.h"
typedef __u32 Elf64_Word;
#line 33 "include/linux/elf.h"
typedef __u64 Elf64_Xword;
#line 180 "include/linux/elf.h"
struct elf64_sym {
   Elf64_Word st_name ;
   unsigned char st_info ;
   unsigned char st_other ;
   Elf64_Half st_shndx ;
   Elf64_Addr st_value ;
   Elf64_Xword st_size ;
};
#line 188 "include/linux/elf.h"
typedef struct elf64_sym Elf64_Sym;
#line 404
struct kobject;
#line 405 "include/linux/elf.h"
struct attribute {
   char const   *name ;
   struct module *owner ;
   mode_t mode ;
};
#line 33 "include/linux/sysfs.h"
struct attribute_group {
   char const   *name ;
   mode_t (*is_visible)(struct kobject * , struct attribute * , int  ) ;
   struct attribute **attrs ;
};
#line 40 "include/linux/sysfs.h"
struct bin_attribute {
   struct attribute attr ;
   size_t size ;
   void *private ;
   ssize_t (*read)(struct kobject * , struct bin_attribute * , char * , loff_t  ,
                   size_t  ) ;
   ssize_t (*write)(struct kobject * , struct bin_attribute * , char * , loff_t  ,
                    size_t  ) ;
   int (*mmap)(struct kobject * , struct bin_attribute * , struct vm_area_struct * ) ;
};
#line 75 "include/linux/sysfs.h"
struct sysfs_ops {
   ssize_t (*show)(struct kobject * , struct attribute * , char * ) ;
   ssize_t (*store)(struct kobject * , struct attribute * , char const   * , size_t  ) ;
};
#line 81
struct sysfs_dirent;
#line 131 "include/linux/sysfs.h"
struct kref {
   atomic_t refcount ;
};
#line 48 "include/linux/kobject.h"
struct kset;
#line 48
struct kobj_type;
#line 48 "include/linux/kobject.h"
struct kobject {
   char const   *name ;
   struct list_head entry ;
   struct kobject *parent ;
   struct kset *kset ;
   struct kobj_type *ktype ;
   struct sysfs_dirent *sd ;
   struct kref kref ;
   unsigned char state_initialized : 1 ;
   unsigned char state_in_sysfs : 1 ;
   unsigned char state_add_uevent_sent : 1 ;
   unsigned char state_remove_uevent_sent : 1 ;
};
#line 103 "include/linux/kobject.h"
struct kobj_type {
   void (*release)(struct kobject * ) ;
   struct sysfs_ops *sysfs_ops ;
   struct attribute **default_attrs ;
};
#line 109 "include/linux/kobject.h"
struct kobj_uevent_env {
   char *envp[32U] ;
   int envp_idx ;
   char buf[2048U] ;
   int buflen ;
};
#line 116 "include/linux/kobject.h"
struct kset_uevent_ops {
   int (*filter)(struct kset * , struct kobject * ) ;
   char const   *(*name)(struct kset * , struct kobject * ) ;
   int (*uevent)(struct kset * , struct kobject * , struct kobj_uevent_env * ) ;
};
#line 133 "include/linux/kobject.h"
struct kset {
   struct list_head list ;
   spinlock_t list_lock ;
   struct kobject kobj ;
   struct kset_uevent_ops *uevent_ops ;
};
#line 215 "include/linux/moduleparam.h"
struct marker;
#line 32 "include/linux/marker.h"
typedef void marker_probe_func(void * , void * , char const   * , va_list * );
#line 33 "include/linux/marker.h"
struct marker_probe_closure {
   marker_probe_func *func ;
   void *probe_private ;
};
#line 39 "include/linux/marker.h"
struct marker {
   char const   *name ;
   char const   *format ;
   char state ;
   char ptype ;
   void (*call)(struct marker  const  * , void *  , ...) ;
   struct marker_probe_closure single ;
   struct marker_probe_closure *multi ;
};
#line 15 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/tsc.h"
typedef unsigned long long cycles_t;
#line 300 "include/linux/jiffies.h"
union ktime {
   s64 tv64 ;
};
#line 59 "include/linux/ktime.h"
typedef union ktime ktime_t;
#line 85 "include/linux/debugobjects.h"
struct tvec_base;
#line 86 "include/linux/debugobjects.h"
struct timer_list {
   struct list_head entry ;
   unsigned long expires ;
   void (*function)(unsigned long  ) ;
   unsigned long data ;
   struct tvec_base *base ;
   void *start_site ;
   char start_comm[16U] ;
   int start_pid ;
};
#line 181 "include/linux/timer.h"
struct hrtimer;
#line 182
enum hrtimer_restart;
#line 194
struct work_struct;
#line 18 "include/linux/workqueue.h"
struct work_struct {
   atomic_long_t data ;
   struct list_head entry ;
   void (*func)(struct work_struct * ) ;
   struct lockdep_map lockdep_map ;
};
#line 35 "include/linux/workqueue.h"
struct delayed_work {
   struct work_struct work ;
   struct timer_list timer ;
};
#line 272 "include/linux/workqueue.h"
struct kmem_cache_cpu {
   void **freelist ;
   struct page *page ;
   int node ;
   unsigned int offset ;
   unsigned int objsize ;
   unsigned int stat[18U] ;
};
#line 44 "include/linux/slub_def.h"
struct kmem_cache_node {
   spinlock_t list_lock ;
   unsigned long nr_partial ;
   unsigned long min_partial ;
   struct list_head partial ;
   atomic_long_t nr_slabs ;
   atomic_long_t total_objects ;
   struct list_head full ;
};
#line 56 "include/linux/slub_def.h"
struct kmem_cache_order_objects {
   unsigned long x ;
};
#line 66 "include/linux/slub_def.h"
struct kmem_cache {
   unsigned long flags ;
   int size ;
   int objsize ;
   int offset ;
   struct kmem_cache_order_objects oo ;
   struct kmem_cache_node local_node ;
   struct kmem_cache_order_objects max ;
   struct kmem_cache_order_objects min ;
   gfp_t allocflags ;
   int refcount ;
   void (*ctor)(void * ) ;
   int inuse ;
   int align ;
   char const   *name ;
   struct list_head list ;
   struct kobject kobj ;
   int remote_node_defrag_ratio ;
   struct kmem_cache_node *node[64U] ;
   struct kmem_cache_cpu *cpu_slab[8U] ;
};
#line 86 "include/linux/percpu.h"
struct completion {
   unsigned int done ;
   wait_queue_head_t wait ;
};
#line 91 "include/linux/completion.h"
struct rcu_head {
   struct rcu_head *next ;
   void (*func)(struct rcu_head * ) ;
};
#line 275 "include/linux/rcupdate.h"
struct tracepoint;
#line 276 "include/linux/rcupdate.h"
struct tracepoint {
   char const   *name ;
   int state ;
   void **funcs ;
};
#line 12 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/local.h"
struct __anonstruct_local_t_89 {
   atomic_long_t a ;
};
#line 12 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/local.h"
typedef struct __anonstruct_local_t_89 local_t;
#line 155 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/local.h"
struct mod_arch_specific {

};
#line 158 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/local.h"
struct kernel_symbol {
   unsigned long value ;
   char const   *name ;
};
#line 45 "include/linux/module.h"
struct module_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct module_attribute * , struct module * , char * ) ;
   ssize_t (*store)(struct module_attribute * , struct module * , char const   * ,
                    size_t  ) ;
   void (*setup)(struct module * , char const   * ) ;
   int (*test)(struct module * ) ;
   void (*free)(struct module * ) ;
};
#line 57
struct module_param_attrs;
#line 57 "include/linux/module.h"
struct module_kobject {
   struct kobject kobj ;
   struct module *mod ;
   struct kobject *drivers_dir ;
   struct module_param_attrs *mp ;
};
#line 69
struct exception_table_entry;
#line 174 "include/linux/module.h"
struct module_ref {
   local_t count ;
};
#line 226
enum module_state {
    MODULE_STATE_LIVE = 0,
    MODULE_STATE_COMING = 1,
    MODULE_STATE_GOING = 2
} ;
#line 232
struct module_sect_attrs;
#line 232
struct module_notes_attrs;
#line 232 "include/linux/module.h"
struct module {
   enum module_state state ;
   struct list_head list ;
   char name[56U] ;
   struct module_kobject mkobj ;
   struct module_attribute *modinfo_attrs ;
   char const   *version ;
   char const   *srcversion ;
   struct kobject *holders_dir ;
   struct kernel_symbol  const  *syms ;
   unsigned long const   *crcs ;
   unsigned int num_syms ;
   unsigned int num_gpl_syms ;
   struct kernel_symbol  const  *gpl_syms ;
   unsigned long const   *gpl_crcs ;
   struct kernel_symbol  const  *unused_syms ;
   unsigned long const   *unused_crcs ;
   unsigned int num_unused_syms ;
   unsigned int num_unused_gpl_syms ;
   struct kernel_symbol  const  *unused_gpl_syms ;
   unsigned long const   *unused_gpl_crcs ;
   struct kernel_symbol  const  *gpl_future_syms ;
   unsigned long const   *gpl_future_crcs ;
   unsigned int num_gpl_future_syms ;
   unsigned int num_exentries ;
   struct exception_table_entry *extable ;
   int (*init)(void) ;
   void *module_init ;
   void *module_core ;
   unsigned int init_size ;
   unsigned int core_size ;
   unsigned int init_text_size ;
   unsigned int core_text_size ;
   void *unwind_info ;
   struct mod_arch_specific arch ;
   unsigned int taints ;
   unsigned int num_bugs ;
   struct list_head bug_list ;
   struct bug_entry *bug_table ;
   Elf64_Sym *symtab ;
   unsigned int num_symtab ;
   char *strtab ;
   struct module_sect_attrs *sect_attrs ;
   struct module_notes_attrs *notes_attrs ;
   void *percpu ;
   char *args ;
   struct marker *markers ;
   unsigned int num_markers ;
   struct tracepoint *tracepoints ;
   unsigned int num_tracepoints ;
   struct list_head modules_which_use_me ;
   struct task_struct *waiter ;
   void (*exit)(void) ;
   struct module_ref ref[8U] ;
};
#line 463
struct device_driver;
#line 15 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
struct file_operations;
#line 368 "include/linux/rculist.h"
struct nameidata;
#line 369
struct path;
#line 370
struct vfsmount;
#line 371 "include/linux/rculist.h"
struct qstr {
   unsigned int hash ;
   unsigned int len ;
   unsigned char const   *name ;
};
#line 77 "include/linux/dcache.h"
struct dcookie_struct;
#line 78
struct inode;
#line 78 "include/linux/dcache.h"
union __anonunion_d_u_90 {
   struct list_head d_child ;
   struct rcu_head d_rcu ;
};
#line 78
struct dentry_operations;
#line 78
struct super_block;
#line 78 "include/linux/dcache.h"
struct dentry {
   atomic_t d_count ;
   unsigned int d_flags ;
   spinlock_t d_lock ;
   struct inode *d_inode ;
   struct hlist_node d_hash ;
   struct dentry *d_parent ;
   struct qstr d_name ;
   struct list_head d_lru ;
   union __anonunion_d_u_90 d_u ;
   struct list_head d_subdirs ;
   struct list_head d_alias ;
   unsigned long d_time ;
   struct dentry_operations *d_op ;
   struct super_block *d_sb ;
   void *d_fsdata ;
   struct dcookie_struct *d_cookie ;
   int d_mounted ;
   unsigned char d_iname[36U] ;
};
#line 121 "include/linux/dcache.h"
struct dentry_operations {
   int (*d_revalidate)(struct dentry * , struct nameidata * ) ;
   int (*d_hash)(struct dentry * , struct qstr * ) ;
   int (*d_compare)(struct dentry * , struct qstr * , struct qstr * ) ;
   int (*d_delete)(struct dentry * ) ;
   void (*d_release)(struct dentry * ) ;
   void (*d_iput)(struct dentry * , struct inode * ) ;
   char *(*d_dname)(struct dentry * , char * , int  ) ;
};
#line 368 "include/linux/dcache.h"
struct path {
   struct vfsmount *mnt ;
   struct dentry *dentry ;
};
#line 55 "include/linux/radix-tree.h"
struct radix_tree_node;
#line 55 "include/linux/radix-tree.h"
struct radix_tree_root {
   unsigned int height ;
   gfp_t gfp_mask ;
   struct radix_tree_node *rnode ;
};
#line 191
struct prio_tree_node;
#line 191 "include/linux/radix-tree.h"
struct raw_prio_tree_node {
   struct prio_tree_node *left ;
   struct prio_tree_node *right ;
   struct prio_tree_node *parent ;
};
#line 19 "include/linux/prio_tree.h"
struct prio_tree_node {
   struct prio_tree_node *left ;
   struct prio_tree_node *right ;
   struct prio_tree_node *parent ;
   unsigned long start ;
   unsigned long last ;
};
#line 27 "include/linux/prio_tree.h"
struct prio_tree_root {
   struct prio_tree_node *prio_tree_node ;
   unsigned short index_bits ;
   unsigned short raw ;
};
#line 111
enum pid_type {
    PIDTYPE_PID = 0,
    PIDTYPE_PGID = 1,
    PIDTYPE_SID = 2,
    PIDTYPE_MAX = 3
} ;
#line 118
struct pid_namespace;
#line 118 "include/linux/prio_tree.h"
struct upid {
   int nr ;
   struct pid_namespace *ns ;
   struct hlist_node pid_chain ;
};
#line 56 "include/linux/pid.h"
struct pid {
   atomic_t count ;
   unsigned int level ;
   struct hlist_head tasks[3U] ;
   struct rcu_head rcu ;
   struct upid numbers[1U] ;
};
#line 68 "include/linux/pid.h"
struct pid_link {
   struct hlist_node node ;
   struct pid *pid ;
};
#line 79 "include/linux/capability.h"
struct kernel_cap_struct {
   __u32 cap[2U] ;
};
#line 97 "include/linux/capability.h"
typedef struct kernel_cap_struct kernel_cap_t;
#line 519 "include/linux/capability.h"
struct semaphore {
   spinlock_t lock ;
   unsigned int count ;
   struct list_head wait_list ;
};
#line 48 "include/linux/semaphore.h"
struct fiemap_extent {
   __u64 fe_logical ;
   __u64 fe_physical ;
   __u64 fe_length ;
   __u64 fe_reserved64[2U] ;
   __u32 fe_flags ;
   __u32 fe_reserved[3U] ;
};
#line 36 "include/linux/fiemap.h"
struct export_operations;
#line 38
struct iovec;
#line 39
struct kiocb;
#line 40
struct pipe_inode_info;
#line 41
struct poll_table_struct;
#line 42
struct kstatfs;
#line 327 "include/linux/fs.h"
struct iattr {
   unsigned int ia_valid ;
   umode_t ia_mode ;
   uid_t ia_uid ;
   gid_t ia_gid ;
   loff_t ia_size ;
   struct timespec ia_atime ;
   struct timespec ia_mtime ;
   struct timespec ia_ctime ;
   struct file *ia_file ;
};
#line 377 "include/linux/fs.h"
struct if_dqblk {
   __u64 dqb_bhardlimit ;
   __u64 dqb_bsoftlimit ;
   __u64 dqb_curspace ;
   __u64 dqb_ihardlimit ;
   __u64 dqb_isoftlimit ;
   __u64 dqb_curinodes ;
   __u64 dqb_btime ;
   __u64 dqb_itime ;
   __u32 dqb_valid ;
};
#line 109 "include/linux/quota.h"
struct if_dqinfo {
   __u64 dqi_bgrace ;
   __u64 dqi_igrace ;
   __u32 dqi_flags ;
   __u32 dqi_valid ;
};
#line 142 "include/linux/quota.h"
struct fs_disk_quota {
   __s8 d_version ;
   __s8 d_flags ;
   __u16 d_fieldmask ;
   __u32 d_id ;
   __u64 d_blk_hardlimit ;
   __u64 d_blk_softlimit ;
   __u64 d_ino_hardlimit ;
   __u64 d_ino_softlimit ;
   __u64 d_bcount ;
   __u64 d_icount ;
   __s32 d_itimer ;
   __s32 d_btimer ;
   __u16 d_iwarns ;
   __u16 d_bwarns ;
   __s32 d_padding2 ;
   __u64 d_rtb_hardlimit ;
   __u64 d_rtb_softlimit ;
   __u64 d_rtbcount ;
   __s32 d_rtbtimer ;
   __u16 d_rtbwarns ;
   __s16 d_padding3 ;
   char d_padding4[8U] ;
};
#line 75 "include/linux/dqblk_xfs.h"
struct fs_qfilestat {
   __u64 qfs_ino ;
   __u64 qfs_nblks ;
   __u32 qfs_nextents ;
};
#line 141 "include/linux/dqblk_xfs.h"
typedef struct fs_qfilestat fs_qfilestat_t;
#line 142 "include/linux/dqblk_xfs.h"
struct fs_quota_stat {
   __s8 qs_version ;
   __u16 qs_flags ;
   __s8 qs_pad ;
   fs_qfilestat_t qs_uquota ;
   fs_qfilestat_t qs_gquota ;
   __u32 qs_incoredqs ;
   __s32 qs_btimelimit ;
   __s32 qs_itimelimit ;
   __s32 qs_rtbtimelimit ;
   __u16 qs_bwarnlimit ;
   __u16 qs_iwarnlimit ;
};
#line 156 "include/linux/dqblk_xfs.h"
struct v1_mem_dqinfo {

};
#line 159 "include/linux/dqblk_xfs.h"
struct v2_mem_dqinfo {
   unsigned int dqi_blocks ;
   unsigned int dqi_free_blk ;
   unsigned int dqi_free_entry ;
};
#line 174 "include/linux/quota.h"
typedef __kernel_uid32_t qid_t;
#line 175 "include/linux/quota.h"
typedef __u64 qsize_t;
#line 178 "include/linux/quota.h"
struct mem_dqblk {
   __u32 dqb_bhardlimit ;
   __u32 dqb_bsoftlimit ;
   qsize_t dqb_curspace ;
   __u32 dqb_ihardlimit ;
   __u32 dqb_isoftlimit ;
   __u32 dqb_curinodes ;
   time_t dqb_btime ;
   time_t dqb_itime ;
};
#line 199
struct quota_format_type;
#line 200 "include/linux/quota.h"
union __anonunion_u_92 {
   struct v1_mem_dqinfo v1_i ;
   struct v2_mem_dqinfo v2_i ;
};
#line 200 "include/linux/quota.h"
struct mem_dqinfo {
   struct quota_format_type *dqi_format ;
   int dqi_fmt_id ;
   struct list_head dqi_dirty_list ;
   unsigned long dqi_flags ;
   unsigned int dqi_bgrace ;
   unsigned int dqi_igrace ;
   qsize_t dqi_maxblimit ;
   qsize_t dqi_maxilimit ;
   union __anonunion_u_92 u ;
};
#line 245 "include/linux/quota.h"
struct dquot {
   struct hlist_node dq_hash ;
   struct list_head dq_inuse ;
   struct list_head dq_free ;
   struct list_head dq_dirty ;
   struct mutex dq_lock ;
   atomic_t dq_count ;
   wait_queue_head_t dq_wait_unused ;
   struct super_block *dq_sb ;
   unsigned int dq_id ;
   loff_t dq_off ;
   unsigned long dq_flags ;
   short dq_type ;
   struct mem_dqblk dq_dqb ;
};
#line 268 "include/linux/quota.h"
struct quota_format_ops {
   int (*check_quota_file)(struct super_block * , int  ) ;
   int (*read_file_info)(struct super_block * , int  ) ;
   int (*write_file_info)(struct super_block * , int  ) ;
   int (*free_file_info)(struct super_block * , int  ) ;
   int (*read_dqblk)(struct dquot * ) ;
   int (*commit_dqblk)(struct dquot * ) ;
   int (*release_dqblk)(struct dquot * ) ;
};
#line 284 "include/linux/quota.h"
struct dquot_operations {
   int (*initialize)(struct inode * , int  ) ;
   int (*drop)(struct inode * ) ;
   int (*alloc_space)(struct inode * , qsize_t  , int  ) ;
   int (*alloc_inode)(struct inode  const  * , unsigned long  ) ;
   int (*free_space)(struct inode * , qsize_t  ) ;
   int (*free_inode)(struct inode  const  * , unsigned long  ) ;
   int (*transfer)(struct inode * , struct iattr * ) ;
   int (*write_dquot)(struct dquot * ) ;
   int (*acquire_dquot)(struct dquot * ) ;
   int (*release_dquot)(struct dquot * ) ;
   int (*mark_dirty)(struct dquot * ) ;
   int (*write_info)(struct super_block * , int  ) ;
};
#line 300 "include/linux/quota.h"
struct quotactl_ops {
   int (*quota_on)(struct super_block * , int  , int  , char * , int  ) ;
   int (*quota_off)(struct super_block * , int  , int  ) ;
   int (*quota_sync)(struct super_block * , int  ) ;
   int (*get_info)(struct super_block * , int  , struct if_dqinfo * ) ;
   int (*set_info)(struct super_block * , int  , struct if_dqinfo * ) ;
   int (*get_dqblk)(struct super_block * , int  , qid_t  , struct if_dqblk * ) ;
   int (*set_dqblk)(struct super_block * , int  , qid_t  , struct if_dqblk * ) ;
   int (*get_xstate)(struct super_block * , struct fs_quota_stat * ) ;
   int (*set_xstate)(struct super_block * , unsigned int  , int  ) ;
   int (*get_xquota)(struct super_block * , int  , qid_t  , struct fs_disk_quota * ) ;
   int (*set_xquota)(struct super_block * , int  , qid_t  , struct fs_disk_quota * ) ;
};
#line 315 "include/linux/quota.h"
struct quota_format_type {
   int qf_fmt_id ;
   struct quota_format_ops *qf_ops ;
   struct module *qf_owner ;
   struct quota_format_type *qf_next ;
};
#line 322 "include/linux/quota.h"
struct quota_info {
   unsigned int flags ;
   struct mutex dqio_mutex ;
   struct mutex dqonoff_mutex ;
   struct rw_semaphore dqptr_sem ;
   struct inode *files[2U] ;
   struct mem_dqinfo info[2U] ;
   struct quota_format_ops *ops[2U] ;
};
#line 352
struct address_space;
#line 353
struct writeback_control;
#line 473 "include/linux/fs.h"
union __anonunion_arg_94 {
   char *buf ;
   void *data ;
};
#line 473 "include/linux/fs.h"
struct __anonstruct_read_descriptor_t_93 {
   size_t written ;
   size_t count ;
   union __anonunion_arg_94 arg ;
   int error ;
};
#line 473 "include/linux/fs.h"
typedef struct __anonstruct_read_descriptor_t_93 read_descriptor_t;
#line 476 "include/linux/fs.h"
struct address_space_operations {
   int (*writepage)(struct page * , struct writeback_control * ) ;
   int (*readpage)(struct file * , struct page * ) ;
   void (*sync_page)(struct page * ) ;
   int (*writepages)(struct address_space * , struct writeback_control * ) ;
   int (*set_page_dirty)(struct page * ) ;
   int (*readpages)(struct file * , struct address_space * , struct list_head * ,
                    unsigned int  ) ;
   int (*write_begin)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                      unsigned int  , struct page ** , void ** ) ;
   int (*write_end)(struct file * , struct address_space * , loff_t  , unsigned int  ,
                    unsigned int  , struct page * , void * ) ;
   sector_t (*bmap)(struct address_space * , sector_t  ) ;
   void (*invalidatepage)(struct page * , unsigned long  ) ;
   int (*releasepage)(struct page * , gfp_t  ) ;
   ssize_t (*direct_IO)(int  , struct kiocb * , struct iovec  const  * , loff_t  ,
                        unsigned long  ) ;
   int (*get_xip_mem)(struct address_space * , unsigned long  , int  , void ** , unsigned long * ) ;
   int (*migratepage)(struct address_space * , struct page * , struct page * ) ;
   int (*launder_page)(struct page * ) ;
   int (*is_partially_uptodate)(struct page * , read_descriptor_t * , unsigned long  ) ;
};
#line 524
struct backing_dev_info;
#line 525 "include/linux/fs.h"
struct address_space {
   struct inode *host ;
   struct radix_tree_root page_tree ;
   spinlock_t tree_lock ;
   unsigned int i_mmap_writable ;
   struct prio_tree_root i_mmap ;
   struct list_head i_mmap_nonlinear ;
   spinlock_t i_mmap_lock ;
   unsigned int truncate_count ;
   unsigned long nrpages ;
   unsigned long writeback_index ;
   struct address_space_operations  const  *a_ops ;
   unsigned long flags ;
   struct backing_dev_info *backing_dev_info ;
   spinlock_t private_lock ;
   struct list_head private_list ;
   struct address_space *assoc_mapping ;
};
#line 546
struct hd_struct;
#line 546
struct gendisk;
#line 546 "include/linux/fs.h"
struct block_device {
   dev_t bd_dev ;
   struct inode *bd_inode ;
   int bd_openers ;
   struct mutex bd_mutex ;
   struct semaphore bd_mount_sem ;
   struct list_head bd_inodes ;
   void *bd_holder ;
   int bd_holders ;
   struct list_head bd_holder_list ;
   struct block_device *bd_contains ;
   unsigned int bd_block_size ;
   struct hd_struct *bd_part ;
   unsigned int bd_part_count ;
   int bd_invalidated ;
   struct gendisk *bd_disk ;
   struct list_head bd_list ;
   struct backing_dev_info *bd_inode_backing_dev_info ;
   unsigned long bd_private ;
};
#line 610
struct inode_operations;
#line 610
struct file_lock;
#line 610
struct cdev;
#line 610 "include/linux/fs.h"
union __anonunion_ldv_11104_95 {
   struct pipe_inode_info *i_pipe ;
   struct block_device *i_bdev ;
   struct cdev *i_cdev ;
};
#line 610
struct dnotify_struct;
#line 610 "include/linux/fs.h"
struct inode {
   struct hlist_node i_hash ;
   struct list_head i_list ;
   struct list_head i_sb_list ;
   struct list_head i_dentry ;
   unsigned long i_ino ;
   atomic_t i_count ;
   unsigned int i_nlink ;
   uid_t i_uid ;
   gid_t i_gid ;
   dev_t i_rdev ;
   u64 i_version ;
   loff_t i_size ;
   struct timespec i_atime ;
   struct timespec i_mtime ;
   struct timespec i_ctime ;
   unsigned int i_blkbits ;
   blkcnt_t i_blocks ;
   unsigned short i_bytes ;
   umode_t i_mode ;
   spinlock_t i_lock ;
   struct mutex i_mutex ;
   struct rw_semaphore i_alloc_sem ;
   struct inode_operations  const  *i_op ;
   struct file_operations  const  *i_fop ;
   struct super_block *i_sb ;
   struct file_lock *i_flock ;
   struct address_space *i_mapping ;
   struct address_space i_data ;
   struct dquot *i_dquot[2U] ;
   struct list_head i_devices ;
   union __anonunion_ldv_11104_95 ldv_11104 ;
   int i_cindex ;
   __u32 i_generation ;
   unsigned long i_dnotify_mask ;
   struct dnotify_struct *i_dnotify ;
   struct list_head inotify_watches ;
   struct mutex inotify_mutex ;
   unsigned long i_state ;
   unsigned long dirtied_when ;
   unsigned int i_flags ;
   atomic_t i_writecount ;
   void *i_security ;
   void *i_private ;
};
#line 776 "include/linux/fs.h"
struct fown_struct {
   rwlock_t lock ;
   struct pid *pid ;
   enum pid_type pid_type ;
   uid_t uid ;
   uid_t euid ;
   int signum ;
};
#line 784 "include/linux/fs.h"
struct file_ra_state {
   unsigned long start ;
   unsigned int size ;
   unsigned int async_size ;
   unsigned int ra_pages ;
   int mmap_miss ;
   loff_t prev_pos ;
};
#line 807 "include/linux/fs.h"
union __anonunion_f_u_96 {
   struct list_head fu_list ;
   struct rcu_head fu_rcuhead ;
};
#line 807 "include/linux/fs.h"
struct file {
   union __anonunion_f_u_96 f_u ;
   struct path f_path ;
   struct file_operations  const  *f_op ;
   atomic_long_t f_count ;
   unsigned int f_flags ;
   fmode_t f_mode ;
   loff_t f_pos ;
   struct fown_struct f_owner ;
   unsigned int f_uid ;
   unsigned int f_gid ;
   struct file_ra_state f_ra ;
   u64 f_version ;
   void *f_security ;
   void *private_data ;
   struct list_head f_ep_links ;
   spinlock_t f_ep_lock ;
   struct address_space *f_mapping ;
   unsigned long f_mnt_write_state ;
};
#line 930
struct files_struct;
#line 930 "include/linux/fs.h"
typedef struct files_struct *fl_owner_t;
#line 931 "include/linux/fs.h"
struct file_lock_operations {
   void (*fl_copy_lock)(struct file_lock * , struct file_lock * ) ;
   void (*fl_release_private)(struct file_lock * ) ;
};
#line 936 "include/linux/fs.h"
struct lock_manager_operations {
   int (*fl_compare_owner)(struct file_lock * , struct file_lock * ) ;
   void (*fl_notify)(struct file_lock * ) ;
   int (*fl_grant)(struct file_lock * , struct file_lock * , int  ) ;
   void (*fl_copy_lock)(struct file_lock * , struct file_lock * ) ;
   void (*fl_release_private)(struct file_lock * ) ;
   void (*fl_break)(struct file_lock * ) ;
   int (*fl_mylease)(struct file_lock * , struct file_lock * ) ;
   int (*fl_change)(struct file_lock ** , int  ) ;
};
#line 163 "include/linux/nfs.h"
struct nlm_lockowner;
#line 164 "include/linux/nfs.h"
struct nfs_lock_info {
   u32 state ;
   struct nlm_lockowner *owner ;
   struct list_head list ;
};
#line 18 "include/linux/nfs_fs_i.h"
struct nfs4_lock_state;
#line 19 "include/linux/nfs_fs_i.h"
struct nfs4_lock_info {
   struct nfs4_lock_state *owner ;
};
#line 23
struct fasync_struct;
#line 23 "include/linux/nfs_fs_i.h"
struct __anonstruct_afs_98 {
   struct list_head link ;
   int state ;
};
#line 23 "include/linux/nfs_fs_i.h"
union __anonunion_fl_u_97 {
   struct nfs_lock_info nfs_fl ;
   struct nfs4_lock_info nfs4_fl ;
   struct __anonstruct_afs_98 afs ;
};
#line 23 "include/linux/nfs_fs_i.h"
struct file_lock {
   struct file_lock *fl_next ;
   struct list_head fl_link ;
   struct list_head fl_block ;
   fl_owner_t fl_owner ;
   unsigned char fl_flags ;
   unsigned char fl_type ;
   unsigned int fl_pid ;
   struct pid *fl_nspid ;
   wait_queue_head_t fl_wait ;
   struct file *fl_file ;
   loff_t fl_start ;
   loff_t fl_end ;
   struct fasync_struct *fl_fasync ;
   unsigned long fl_break_time ;
   struct file_lock_operations *fl_ops ;
   struct lock_manager_operations *fl_lmops ;
   union __anonunion_fl_u_97 fl_u ;
};
#line 1038 "include/linux/fs.h"
struct fasync_struct {
   int magic ;
   int fa_fd ;
   struct fasync_struct *fa_next ;
   struct file *fa_file ;
};
#line 1102
struct file_system_type;
#line 1102
struct super_operations;
#line 1102
struct xattr_handler;
#line 1102
struct mtd_info;
#line 1102 "include/linux/fs.h"
struct super_block {
   struct list_head s_list ;
   dev_t s_dev ;
   unsigned long s_blocksize ;
   unsigned char s_blocksize_bits ;
   unsigned char s_dirt ;
   unsigned long long s_maxbytes ;
   struct file_system_type *s_type ;
   struct super_operations  const  *s_op ;
   struct dquot_operations *dq_op ;
   struct quotactl_ops *s_qcop ;
   struct export_operations  const  *s_export_op ;
   unsigned long s_flags ;
   unsigned long s_magic ;
   struct dentry *s_root ;
   struct rw_semaphore s_umount ;
   struct mutex s_lock ;
   int s_count ;
   int s_syncing ;
   int s_need_sync_fs ;
   atomic_t s_active ;
   void *s_security ;
   struct xattr_handler **s_xattr ;
   struct list_head s_inodes ;
   struct list_head s_dirty ;
   struct list_head s_io ;
   struct list_head s_more_io ;
   struct hlist_head s_anon ;
   struct list_head s_files ;
   struct list_head s_dentry_lru ;
   int s_nr_dentry_unused ;
   struct block_device *s_bdev ;
   struct mtd_info *s_mtd ;
   struct list_head s_instances ;
   struct quota_info s_dquot ;
   int s_frozen ;
   wait_queue_head_t s_wait_unfrozen ;
   char s_id[32U] ;
   void *s_fs_info ;
   fmode_t s_mode ;
   struct mutex s_vfs_rename_mutex ;
   u32 s_time_gran ;
   char *s_subtype ;
   char *s_options ;
};
#line 1224 "include/linux/fs.h"
struct fiemap_extent_info {
   unsigned int fi_flags ;
   unsigned int fi_extents_mapped ;
   unsigned int fi_extents_max ;
   struct fiemap_extent *fi_extents_start ;
};
#line 1268 "include/linux/fs.h"
struct file_operations {
   struct module *owner ;
   loff_t (*llseek)(struct file * , loff_t  , int  ) ;
   ssize_t (*read)(struct file * , char * , size_t  , loff_t * ) ;
   ssize_t (*write)(struct file * , char const   * , size_t  , loff_t * ) ;
   ssize_t (*aio_read)(struct kiocb * , struct iovec  const  * , unsigned long  ,
                       loff_t  ) ;
   ssize_t (*aio_write)(struct kiocb * , struct iovec  const  * , unsigned long  ,
                        loff_t  ) ;
   int (*readdir)(struct file * , void * , int (*)(void * , char const   * , int  ,
                                                   loff_t  , u64  , unsigned int  ) ) ;
   unsigned int (*poll)(struct file * , struct poll_table_struct * ) ;
   int (*ioctl)(struct inode * , struct file * , unsigned int  , unsigned long  ) ;
   long (*unlocked_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   long (*compat_ioctl)(struct file * , unsigned int  , unsigned long  ) ;
   int (*mmap)(struct file * , struct vm_area_struct * ) ;
   int (*open)(struct inode * , struct file * ) ;
   int (*flush)(struct file * , fl_owner_t  ) ;
   int (*release)(struct inode * , struct file * ) ;
   int (*fsync)(struct file * , struct dentry * , int  ) ;
   int (*aio_fsync)(struct kiocb * , int  ) ;
   int (*fasync)(int  , struct file * , int  ) ;
   int (*lock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*sendpage)(struct file * , struct page * , int  , size_t  , loff_t * ,
                       int  ) ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   int (*check_flags)(int  ) ;
   int (*dir_notify)(struct file * , unsigned long  ) ;
   int (*flock)(struct file * , int  , struct file_lock * ) ;
   ssize_t (*splice_write)(struct pipe_inode_info * , struct file * , loff_t * , size_t  ,
                           unsigned int  ) ;
   ssize_t (*splice_read)(struct file * , loff_t * , struct pipe_inode_info * , size_t  ,
                          unsigned int  ) ;
   int (*setlease)(struct file * , long  , struct file_lock ** ) ;
};
#line 1309 "include/linux/fs.h"
struct inode_operations {
   int (*create)(struct inode * , struct dentry * , int  , struct nameidata * ) ;
   struct dentry *(*lookup)(struct inode * , struct dentry * , struct nameidata * ) ;
   int (*link)(struct dentry * , struct inode * , struct dentry * ) ;
   int (*unlink)(struct inode * , struct dentry * ) ;
   int (*symlink)(struct inode * , struct dentry * , char const   * ) ;
   int (*mkdir)(struct inode * , struct dentry * , int  ) ;
   int (*rmdir)(struct inode * , struct dentry * ) ;
   int (*mknod)(struct inode * , struct dentry * , int  , dev_t  ) ;
   int (*rename)(struct inode * , struct dentry * , struct inode * , struct dentry * ) ;
   int (*readlink)(struct dentry * , char * , int  ) ;
   void *(*follow_link)(struct dentry * , struct nameidata * ) ;
   void (*put_link)(struct dentry * , struct nameidata * , void * ) ;
   void (*truncate)(struct inode * ) ;
   int (*permission)(struct inode * , int  ) ;
   int (*setattr)(struct dentry * , struct iattr * ) ;
   int (*getattr)(struct vfsmount * , struct dentry * , struct kstat * ) ;
   int (*setxattr)(struct dentry * , char const   * , void const   * , size_t  , int  ) ;
   ssize_t (*getxattr)(struct dentry * , char const   * , void * , size_t  ) ;
   ssize_t (*listxattr)(struct dentry * , char * , size_t  ) ;
   int (*removexattr)(struct dentry * , char const   * ) ;
   void (*truncate_range)(struct inode * , loff_t  , loff_t  ) ;
   long (*fallocate)(struct inode * , int  , loff_t  , loff_t  ) ;
   int (*fiemap)(struct inode * , struct fiemap_extent_info * , u64  , u64  ) ;
};
#line 1337
struct seq_file;
#line 1351 "include/linux/fs.h"
struct super_operations {
   struct inode *(*alloc_inode)(struct super_block * ) ;
   void (*destroy_inode)(struct inode * ) ;
   void (*dirty_inode)(struct inode * ) ;
   int (*write_inode)(struct inode * , int  ) ;
   void (*drop_inode)(struct inode * ) ;
   void (*delete_inode)(struct inode * ) ;
   void (*put_super)(struct super_block * ) ;
   void (*write_super)(struct super_block * ) ;
   int (*sync_fs)(struct super_block * , int  ) ;
   void (*write_super_lockfs)(struct super_block * ) ;
   void (*unlockfs)(struct super_block * ) ;
   int (*statfs)(struct dentry * , struct kstatfs * ) ;
   int (*remount_fs)(struct super_block * , int * , char * ) ;
   void (*clear_inode)(struct inode * ) ;
   void (*umount_begin)(struct super_block * ) ;
   int (*show_options)(struct seq_file * , struct vfsmount * ) ;
   int (*show_stats)(struct seq_file * , struct vfsmount * ) ;
   ssize_t (*quota_read)(struct super_block * , int  , char * , size_t  , loff_t  ) ;
   ssize_t (*quota_write)(struct super_block * , int  , char const   * , size_t  ,
                          loff_t  ) ;
};
#line 1534 "include/linux/fs.h"
struct file_system_type {
   char const   *name ;
   int fs_flags ;
   int (*get_sb)(struct file_system_type * , int  , char const   * , void * , struct vfsmount * ) ;
   void (*kill_sb)(struct super_block * ) ;
   struct module *owner ;
   struct file_system_type *next ;
   struct list_head fs_supers ;
   struct lock_class_key s_lock_key ;
   struct lock_class_key s_umount_key ;
   struct lock_class_key i_lock_key ;
   struct lock_class_key i_mutex_key ;
   struct lock_class_key i_mutex_dir_key ;
   struct lock_class_key i_alloc_sem_key ;
};
#line 1913
struct bio;
#line 49 "include/linux/proc_fs.h"
typedef int read_proc_t(char * , char ** , off_t  , int  , int * , void * );
#line 51 "include/linux/proc_fs.h"
typedef int write_proc_t(struct file * , char const   * , unsigned long  , void * );
#line 52 "include/linux/proc_fs.h"
struct proc_dir_entry {
   unsigned int low_ino ;
   unsigned short namelen ;
   char const   *name ;
   mode_t mode ;
   nlink_t nlink ;
   uid_t uid ;
   gid_t gid ;
   loff_t size ;
   struct inode_operations  const  *proc_iops ;
   struct file_operations  const  *proc_fops ;
   struct module *owner ;
   struct proc_dir_entry *next ;
   struct proc_dir_entry *parent ;
   struct proc_dir_entry *subdir ;
   void *data ;
   read_proc_t *read_proc ;
   write_proc_t *write_proc ;
   atomic_t count ;
   int pde_users ;
   spinlock_t pde_unload_lock ;
   struct completion *pde_unload_completion ;
   struct list_head pde_openers ;
};
#line 12 "include/linux/mod_devicetable.h"
typedef unsigned long kernel_ulong_t;
#line 13 "include/linux/mod_devicetable.h"
struct pci_device_id {
   __u32 vendor ;
   __u32 device ;
   __u32 subvendor ;
   __u32 subdevice ;
   __u32 class ;
   __u32 class_mask ;
   kernel_ulong_t driver_data ;
};
#line 446 "include/linux/mod_devicetable.h"
struct resource {
   resource_size_t start ;
   resource_size_t end ;
   char const   *name ;
   unsigned long flags ;
   struct resource *parent ;
   struct resource *sibling ;
   struct resource *child ;
};
#line 25 "include/linux/ioport.h"
struct pci_dev;
#line 178
struct klist_node;
#line 179 "include/linux/ioport.h"
struct klist {
   spinlock_t k_lock ;
   struct list_head k_list ;
   void (*get)(struct klist_node * ) ;
   void (*put)(struct klist_node * ) ;
};
#line 38 "include/linux/klist.h"
struct klist_node {
   void *n_klist ;
   struct list_head n_node ;
   struct kref n_ref ;
   struct completion n_removed ;
};
#line 69
struct dma_mapping_ops;
#line 69 "include/linux/klist.h"
struct dev_archdata {
   void *acpi_handle ;
   struct dma_mapping_ops *dma_ops ;
   void *iommu ;
};
#line 14 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/device.h"
struct driver_private;
#line 15
struct class;
#line 16
struct class_private;
#line 17
struct bus_type;
#line 18
struct bus_type_private;
#line 19 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/device.h"
struct bus_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct bus_type * , char * ) ;
   ssize_t (*store)(struct bus_type * , char const   * , size_t  ) ;
};
#line 50 "include/linux/device.h"
struct device_attribute;
#line 50
struct driver_attribute;
#line 50 "include/linux/device.h"
struct bus_type {
   char const   *name ;
   struct bus_attribute *bus_attrs ;
   struct device_attribute *dev_attrs ;
   struct driver_attribute *drv_attrs ;
   int (*match)(struct device * , struct device_driver * ) ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*suspend_late)(struct device * , pm_message_t  ) ;
   int (*resume_early)(struct device * ) ;
   int (*resume)(struct device * ) ;
   struct pm_ext_ops *pm ;
   struct bus_type_private *p ;
};
#line 121 "include/linux/device.h"
struct device_driver {
   char const   *name ;
   struct bus_type *bus ;
   struct module *owner ;
   char const   *mod_name ;
   int (*probe)(struct device * ) ;
   int (*remove)(struct device * ) ;
   void (*shutdown)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct attribute_group **groups ;
   struct pm_ops *pm ;
   struct driver_private *p ;
};
#line 150 "include/linux/device.h"
struct driver_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct device_driver * , char * ) ;
   ssize_t (*store)(struct device_driver * , char const   * , size_t  ) ;
};
#line 179
struct class_attribute;
#line 179 "include/linux/device.h"
struct class {
   char const   *name ;
   struct module *owner ;
   struct class_attribute *class_attrs ;
   struct device_attribute *dev_attrs ;
   struct kobject *dev_kobj ;
   int (*dev_uevent)(struct device * , struct kobj_uevent_env * ) ;
   void (*class_release)(struct class * ) ;
   void (*dev_release)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct pm_ops *pm ;
   struct class_private *p ;
};
#line 204
struct device_type;
#line 235 "include/linux/device.h"
struct class_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct class * , char * ) ;
   ssize_t (*store)(struct class * , char const   * , size_t  ) ;
};
#line 267 "include/linux/device.h"
struct device_type {
   char const   *name ;
   struct attribute_group **groups ;
   int (*uevent)(struct device * , struct kobj_uevent_env * ) ;
   void (*release)(struct device * ) ;
   int (*suspend)(struct device * , pm_message_t  ) ;
   int (*resume)(struct device * ) ;
   struct pm_ops *pm ;
};
#line 296 "include/linux/device.h"
struct device_attribute {
   struct attribute attr ;
   ssize_t (*show)(struct device * , struct device_attribute * , char * ) ;
   ssize_t (*store)(struct device * , struct device_attribute * , char const   * ,
                    size_t  ) ;
};
#line 357 "include/linux/device.h"
struct device_dma_parameters {
   unsigned int max_segment_size ;
   unsigned long segment_boundary_mask ;
};
#line 366
struct dma_coherent_mem;
#line 366 "include/linux/device.h"
struct device {
   struct klist klist_children ;
   struct klist_node knode_parent ;
   struct klist_node knode_driver ;
   struct klist_node knode_bus ;
   struct device *parent ;
   struct kobject kobj ;
   char bus_id[20U] ;
   char const   *init_name ;
   struct device_type *type ;
   unsigned char uevent_suppress : 1 ;
   struct semaphore sem ;
   struct bus_type *bus ;
   struct device_driver *driver ;
   void *driver_data ;
   void *platform_data ;
   struct dev_pm_info power ;
   int numa_node ;
   u64 *dma_mask ;
   u64 coherent_dma_mask ;
   struct device_dma_parameters *dma_parms ;
   struct list_head dma_pools ;
   struct dma_coherent_mem *dma_mem ;
   struct dev_archdata archdata ;
   spinlock_t devres_lock ;
   struct list_head devres_head ;
   struct klist_node knode_class ;
   struct class *class ;
   dev_t devt ;
   struct attribute_group **groups ;
   void (*release)(struct device * ) ;
};
#line 69 "include/linux/io.h"
struct hotplug_slot;
#line 69 "include/linux/io.h"
struct pci_slot {
   struct pci_bus *bus ;
   struct list_head list ;
   struct hotplug_slot *hotplug ;
   unsigned char number ;
   struct kobject kobj ;
};
#line 87 "include/linux/pci.h"
typedef int pci_power_t;
#line 101 "include/linux/pci.h"
typedef unsigned int pci_channel_state_t;
#line 102
enum pci_channel_state {
    pci_channel_io_normal = 1,
    pci_channel_io_frozen = 2,
    pci_channel_io_perm_failure = 3
} ;
#line 127 "include/linux/pci.h"
typedef unsigned short pci_dev_flags_t;
#line 137 "include/linux/pci.h"
typedef unsigned short pci_bus_flags_t;
#line 148
struct pcie_link_state;
#line 149
struct pci_vpd;
#line 150
struct pci_driver;
#line 150 "include/linux/pci.h"
struct pci_dev {
   struct list_head bus_list ;
   struct pci_bus *bus ;
   struct pci_bus *subordinate ;
   void *sysdata ;
   struct proc_dir_entry *procent ;
   struct pci_slot *slot ;
   unsigned int devfn ;
   unsigned short vendor ;
   unsigned short device ;
   unsigned short subsystem_vendor ;
   unsigned short subsystem_device ;
   unsigned int class ;
   u8 revision ;
   u8 hdr_type ;
   u8 pcie_type ;
   u8 rom_base_reg ;
   u8 pin ;
   struct pci_driver *driver ;
   u64 dma_mask ;
   struct device_dma_parameters dma_parms ;
   pci_power_t current_state ;
   int pm_cap ;
   unsigned char pme_support : 5 ;
   unsigned char d1_support : 1 ;
   unsigned char d2_support : 1 ;
   unsigned char no_d1d2 : 1 ;
   struct pcie_link_state *link_state ;
   pci_channel_state_t error_state ;
   struct device dev ;
   int cfg_size ;
   unsigned int irq ;
   struct resource resource[12U] ;
   unsigned char transparent : 1 ;
   unsigned char multifunction : 1 ;
   unsigned char is_added : 1 ;
   unsigned char is_busmaster : 1 ;
   unsigned char no_msi : 1 ;
   unsigned char block_ucfg_access : 1 ;
   unsigned char broken_parity_status : 1 ;
   unsigned char msi_enabled : 1 ;
   unsigned char msix_enabled : 1 ;
   unsigned char ari_enabled : 1 ;
   unsigned char is_managed : 1 ;
   unsigned char is_pcie : 1 ;
   pci_dev_flags_t dev_flags ;
   atomic_t enable_cnt ;
   u32 saved_config_space[16U] ;
   struct hlist_head saved_cap_space ;
   struct bin_attribute *rom_attr ;
   int rom_attr_enabled ;
   struct bin_attribute *res_attr[12U] ;
   struct bin_attribute *res_attr_wc[12U] ;
   struct list_head msi_list ;
   struct pci_vpd *vpd ;
};
#line 270
struct pci_ops;
#line 270 "include/linux/pci.h"
struct pci_bus {
   struct list_head node ;
   struct pci_bus *parent ;
   struct list_head children ;
   struct list_head devices ;
   struct pci_dev *self ;
   struct list_head slots ;
   struct resource *resource[16U] ;
   struct pci_ops *ops ;
   void *sysdata ;
   struct proc_dir_entry *procdir ;
   unsigned char number ;
   unsigned char primary ;
   unsigned char secondary ;
   unsigned char subordinate ;
   char name[48U] ;
   unsigned short bridge_ctl ;
   pci_bus_flags_t bus_flags ;
   struct device *bridge ;
   struct device dev ;
   struct bin_attribute *legacy_io ;
   struct bin_attribute *legacy_mem ;
   unsigned char is_added : 1 ;
};
#line 318 "include/linux/pci.h"
struct pci_ops {
   int (*read)(struct pci_bus * , unsigned int  , int  , int  , u32 * ) ;
   int (*write)(struct pci_bus * , unsigned int  , int  , int  , u32  ) ;
};
#line 353 "include/linux/pci.h"
struct pci_dynids {
   spinlock_t lock ;
   struct list_head list ;
};
#line 366 "include/linux/pci.h"
typedef unsigned int pci_ers_result_t;
#line 375 "include/linux/pci.h"
struct pci_error_handlers {
   pci_ers_result_t (*error_detected)(struct pci_dev * , enum pci_channel_state  ) ;
   pci_ers_result_t (*mmio_enabled)(struct pci_dev * ) ;
   pci_ers_result_t (*link_reset)(struct pci_dev * ) ;
   pci_ers_result_t (*slot_reset)(struct pci_dev * ) ;
   void (*resume)(struct pci_dev * ) ;
};
#line 403 "include/linux/pci.h"
struct pci_driver {
   struct list_head node ;
   char *name ;
   struct pci_device_id  const  *id_table ;
   int (*probe)(struct pci_dev * , struct pci_device_id  const  * ) ;
   void (*remove)(struct pci_dev * ) ;
   int (*suspend)(struct pci_dev * , pm_message_t  ) ;
   int (*suspend_late)(struct pci_dev * , pm_message_t  ) ;
   int (*resume_early)(struct pci_dev * ) ;
   int (*resume)(struct pci_dev * ) ;
   void (*shutdown)(struct pci_dev * ) ;
   struct pm_ext_ops *pm ;
   struct pci_error_handlers *err_handler ;
   struct device_driver driver ;
   struct pci_dynids dynids ;
};
#line 723 "include/linux/pci.h"
struct scatterlist {
   unsigned long sg_magic ;
   unsigned long page_link ;
   unsigned int offset ;
   unsigned int length ;
   dma_addr_t dma_address ;
   unsigned int dma_length ;
};
#line 805 "include/linux/pci.h"
struct rb_node {
   unsigned long rb_parent_color ;
   struct rb_node *rb_right ;
   struct rb_node *rb_left ;
};
#line 108 "include/linux/rbtree.h"
struct rb_root {
   struct rb_node *rb_node ;
};
#line 27 "include/linux/mm_types.h"
typedef atomic_long_t mm_counter_t;
#line 28 "include/linux/mm_types.h"
struct __anonstruct_ldv_15170_101 {
   u16 inuse ;
   u16 objects ;
};
#line 28 "include/linux/mm_types.h"
union __anonunion_ldv_15171_100 {
   atomic_t _mapcount ;
   struct __anonstruct_ldv_15170_101 ldv_15170 ;
};
#line 28 "include/linux/mm_types.h"
struct __anonstruct_ldv_15176_103 {
   unsigned long private ;
   struct address_space *mapping ;
};
#line 28 "include/linux/mm_types.h"
union __anonunion_ldv_15180_102 {
   struct __anonstruct_ldv_15176_103 ldv_15176 ;
   spinlock_t ptl ;
   struct kmem_cache *slab ;
   struct page *first_page ;
};
#line 28 "include/linux/mm_types.h"
union __anonunion_ldv_15184_104 {
   unsigned long index ;
   void *freelist ;
};
#line 28 "include/linux/mm_types.h"
struct page {
   unsigned long flags ;
   atomic_t _count ;
   union __anonunion_ldv_15171_100 ldv_15171 ;
   union __anonunion_ldv_15180_102 ldv_15180 ;
   union __anonunion_ldv_15184_104 ldv_15184 ;
   struct list_head lru ;
};
#line 82 "include/linux/mm_types.h"
struct __anonstruct_vm_set_106 {
   struct list_head list ;
   void *parent ;
   struct vm_area_struct *head ;
};
#line 82 "include/linux/mm_types.h"
union __anonunion_shared_105 {
   struct __anonstruct_vm_set_106 vm_set ;
   struct raw_prio_tree_node prio_tree_node ;
};
#line 82
struct anon_vma;
#line 82
struct vm_operations_struct;
#line 82
struct mempolicy;
#line 82 "include/linux/mm_types.h"
struct vm_area_struct {
   struct mm_struct *vm_mm ;
   unsigned long vm_start ;
   unsigned long vm_end ;
   struct vm_area_struct *vm_next ;
   pgprot_t vm_page_prot ;
   unsigned long vm_flags ;
   struct rb_node vm_rb ;
   union __anonunion_shared_105 shared ;
   struct list_head anon_vma_node ;
   struct anon_vma *anon_vma ;
   struct vm_operations_struct *vm_ops ;
   unsigned long vm_pgoff ;
   struct file *vm_file ;
   void *vm_private_data ;
   unsigned long vm_truncate_count ;
   struct mempolicy *vm_policy ;
};
#line 160 "include/linux/mm_types.h"
struct core_thread {
   struct task_struct *task ;
   struct core_thread *next ;
};
#line 166 "include/linux/mm_types.h"
struct core_state {
   atomic_t nr_threads ;
   struct core_thread dumper ;
   struct completion startup ;
};
#line 172
struct kioctx;
#line 172
struct mmu_notifier_mm;
#line 172 "include/linux/mm_types.h"
struct mm_struct {
   struct vm_area_struct *mmap ;
   struct rb_root mm_rb ;
   struct vm_area_struct *mmap_cache ;
   unsigned long (*get_unmapped_area)(struct file * , unsigned long  , unsigned long  ,
                                      unsigned long  , unsigned long  ) ;
   void (*unmap_area)(struct mm_struct * , unsigned long  ) ;
   unsigned long mmap_base ;
   unsigned long task_size ;
   unsigned long cached_hole_size ;
   unsigned long free_area_cache ;
   pgd_t *pgd ;
   atomic_t mm_users ;
   atomic_t mm_count ;
   int map_count ;
   struct rw_semaphore mmap_sem ;
   spinlock_t page_table_lock ;
   struct list_head mmlist ;
   mm_counter_t _file_rss ;
   mm_counter_t _anon_rss ;
   unsigned long hiwater_rss ;
   unsigned long hiwater_vm ;
   unsigned long total_vm ;
   unsigned long locked_vm ;
   unsigned long shared_vm ;
   unsigned long exec_vm ;
   unsigned long stack_vm ;
   unsigned long reserved_vm ;
   unsigned long def_flags ;
   unsigned long nr_ptes ;
   unsigned long start_code ;
   unsigned long end_code ;
   unsigned long start_data ;
   unsigned long end_data ;
   unsigned long start_brk ;
   unsigned long brk ;
   unsigned long start_stack ;
   unsigned long arg_start ;
   unsigned long arg_end ;
   unsigned long env_start ;
   unsigned long env_end ;
   unsigned long saved_auxv[42U] ;
   cpumask_t cpu_vm_mask ;
   mm_context_t context ;
   unsigned int faultstamp ;
   unsigned int token_priority ;
   unsigned int last_interval ;
   unsigned long flags ;
   struct core_state *core_state ;
   rwlock_t ioctx_list_lock ;
   struct kioctx *ioctx_list ;
   struct task_struct *owner ;
   struct file *exe_file ;
   unsigned long num_exe_file_vmas ;
   struct mmu_notifier_mm *mmu_notifier_mm ;
};
#line 259
struct user_struct;
#line 144 "include/linux/mm.h"
struct vm_fault {
   unsigned int flags ;
   unsigned long pgoff ;
   void *virtual_address ;
   struct page *page ;
};
#line 165 "include/linux/mm.h"
struct vm_operations_struct {
   void (*open)(struct vm_area_struct * ) ;
   void (*close)(struct vm_area_struct * ) ;
   int (*fault)(struct vm_area_struct * , struct vm_fault * ) ;
   int (*page_mkwrite)(struct vm_area_struct * , struct page * ) ;
   int (*access)(struct vm_area_struct * , unsigned long  , void * , int  , int  ) ;
   int (*set_policy)(struct vm_area_struct * , struct mempolicy * ) ;
   struct mempolicy *(*get_policy)(struct vm_area_struct * , unsigned long  ) ;
   int (*migrate)(struct vm_area_struct * , nodemask_t const   * , nodemask_t const   * ,
                  unsigned long  ) ;
};
#line 18 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/dma-mapping.h"
struct dma_mapping_ops {
   int (*mapping_error)(struct device * , dma_addr_t  ) ;
   void *(*alloc_coherent)(struct device * , size_t  , dma_addr_t * , gfp_t  ) ;
   void (*free_coherent)(struct device * , size_t  , void * , dma_addr_t  ) ;
   dma_addr_t (*map_single)(struct device * , phys_addr_t  , size_t  , int  ) ;
   void (*unmap_single)(struct device * , dma_addr_t  , size_t  , int  ) ;
   void (*sync_single_for_cpu)(struct device * , dma_addr_t  , size_t  , int  ) ;
   void (*sync_single_for_device)(struct device * , dma_addr_t  , size_t  , int  ) ;
   void (*sync_single_range_for_cpu)(struct device * , dma_addr_t  , unsigned long  ,
                                     size_t  , int  ) ;
   void (*sync_single_range_for_device)(struct device * , dma_addr_t  , unsigned long  ,
                                        size_t  , int  ) ;
   void (*sync_sg_for_cpu)(struct device * , struct scatterlist * , int  , int  ) ;
   void (*sync_sg_for_device)(struct device * , struct scatterlist * , int  , int  ) ;
   int (*map_sg)(struct device * , struct scatterlist * , int  , int  ) ;
   void (*unmap_sg)(struct device * , struct scatterlist * , int  , int  ) ;
   int (*dma_supported)(struct device * , u64  ) ;
   int is_phys ;
};
#line 7 "include/asm-generic/cputime.h"
typedef unsigned long cputime_t;
#line 113 "include/linux/sem.h"
struct sem_undo_list;
#line 126 "include/linux/sem.h"
struct sem_undo_list {
   atomic_t refcnt ;
   spinlock_t lock ;
   struct list_head list_proc ;
};
#line 135 "include/linux/sem.h"
struct sysv_sem {
   struct sem_undo_list *undo_list ;
};
#line 144
struct siginfo;
#line 32 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/signal.h"
struct __anonstruct_sigset_t_107 {
   unsigned long sig[1U] ;
};
#line 32 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/signal.h"
typedef struct __anonstruct_sigset_t_107 sigset_t;
#line 17 "include/asm-generic/signal.h"
typedef void __signalfn_t(int  );
#line 18 "include/asm-generic/signal.h"
typedef __signalfn_t *__sighandler_t;
#line 20 "include/asm-generic/signal.h"
typedef void __restorefn_t(void);
#line 21 "include/asm-generic/signal.h"
typedef __restorefn_t *__sigrestore_t;
#line 22 "include/asm-generic/signal.h"
struct sigaction {
   __sighandler_t sa_handler ;
   unsigned long sa_flags ;
   __sigrestore_t sa_restorer ;
   sigset_t sa_mask ;
};
#line 171 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/signal.h"
struct k_sigaction {
   struct sigaction sa ;
};
#line 183 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/signal.h"
union sigval {
   int sival_int ;
   void *sival_ptr ;
};
#line 10 "include/asm-generic/siginfo.h"
typedef union sigval sigval_t;
#line 11 "include/asm-generic/siginfo.h"
struct __anonstruct__kill_109 {
   pid_t _pid ;
   uid_t _uid ;
};
#line 11 "include/asm-generic/siginfo.h"
struct __anonstruct__timer_110 {
   timer_t _tid ;
   int _overrun ;
   char _pad[0U] ;
   sigval_t _sigval ;
   int _sys_private ;
};
#line 11 "include/asm-generic/siginfo.h"
struct __anonstruct__rt_111 {
   pid_t _pid ;
   uid_t _uid ;
   sigval_t _sigval ;
};
#line 11 "include/asm-generic/siginfo.h"
struct __anonstruct__sigchld_112 {
   pid_t _pid ;
   uid_t _uid ;
   int _status ;
   clock_t _utime ;
   clock_t _stime ;
};
#line 11 "include/asm-generic/siginfo.h"
struct __anonstruct__sigfault_113 {
   void *_addr ;
};
#line 11 "include/asm-generic/siginfo.h"
struct __anonstruct__sigpoll_114 {
   long _band ;
   int _fd ;
};
#line 11 "include/asm-generic/siginfo.h"
union __anonunion__sifields_108 {
   int _pad[28U] ;
   struct __anonstruct__kill_109 _kill ;
   struct __anonstruct__timer_110 _timer ;
   struct __anonstruct__rt_111 _rt ;
   struct __anonstruct__sigchld_112 _sigchld ;
   struct __anonstruct__sigfault_113 _sigfault ;
   struct __anonstruct__sigpoll_114 _sigpoll ;
};
#line 11 "include/asm-generic/siginfo.h"
struct siginfo {
   int si_signo ;
   int si_errno ;
   int si_code ;
   union __anonunion__sifields_108 _sifields ;
};
#line 93 "include/asm-generic/siginfo.h"
typedef struct siginfo siginfo_t;
#line 20 "include/linux/signal.h"
struct sigpending {
   struct list_head list ;
   sigset_t signal ;
};
#line 374 "include/linux/signal.h"
struct fs_struct {
   atomic_t count ;
   rwlock_t lock ;
   int umask ;
   struct path root ;
   struct path pwd ;
};
#line 90 "include/linux/proportions.h"
struct prop_local_single {
   unsigned long events ;
   unsigned long period ;
   int shift ;
   spinlock_t lock ;
};
#line 10 "include/linux/seccomp.h"
struct __anonstruct_seccomp_t_117 {
   int mode ;
};
#line 10 "include/linux/seccomp.h"
typedef struct __anonstruct_seccomp_t_117 seccomp_t;
#line 21 "include/linux/seccomp.h"
struct plist_head {
   struct list_head prio_list ;
   struct list_head node_list ;
   spinlock_t *lock ;
};
#line 36 "include/linux/rtmutex.h"
struct rt_mutex_waiter;
#line 42 "include/linux/resource.h"
struct rlimit {
   unsigned long rlim_cur ;
   unsigned long rlim_max ;
};
#line 74
struct hrtimer_clock_base;
#line 75
struct hrtimer_cpu_base;
#line 81
enum hrtimer_restart {
    HRTIMER_NORESTART = 0,
    HRTIMER_RESTART = 1
} ;
#line 86
enum hrtimer_cb_mode {
    HRTIMER_CB_SOFTIRQ = 0,
    HRTIMER_CB_IRQSAFE_PERCPU = 1,
    HRTIMER_CB_IRQSAFE_UNLOCKED = 2
} ;
#line 92 "include/linux/resource.h"
struct hrtimer {
   struct rb_node node ;
   ktime_t _expires ;
   ktime_t _softexpires ;
   enum hrtimer_restart (*function)(struct hrtimer * ) ;
   struct hrtimer_clock_base *base ;
   unsigned long state ;
   struct list_head cb_entry ;
   enum hrtimer_cb_mode cb_mode ;
   int start_pid ;
   void *start_site ;
   char start_comm[16U] ;
};
#line 151 "include/linux/hrtimer.h"
struct hrtimer_clock_base {
   struct hrtimer_cpu_base *cpu_base ;
   clockid_t index ;
   struct rb_root active ;
   struct rb_node *first ;
   ktime_t resolution ;
   ktime_t (*get_time)(void) ;
   ktime_t softirq_time ;
   ktime_t offset ;
};
#line 175 "include/linux/hrtimer.h"
struct hrtimer_cpu_base {
   spinlock_t lock ;
   struct hrtimer_clock_base clock_base[2U] ;
   struct list_head cb_pending ;
   ktime_t expires_next ;
   int hres_active ;
   unsigned long nr_events ;
};
#line 488 "include/linux/hrtimer.h"
struct task_io_accounting {
   u64 rchar ;
   u64 wchar ;
   u64 syscr ;
   u64 syscw ;
   u64 read_bytes ;
   u64 write_bytes ;
   u64 cancelled_write_bytes ;
};
#line 45 "include/linux/task_io_accounting.h"
struct latency_record {
   unsigned long backtrace[12U] ;
   unsigned int count ;
   unsigned long time ;
   unsigned long max ;
};
#line 31 "include/linux/latencytop.h"
struct futex_pi_state;
#line 32
struct robust_list_head;
#line 138 "include/linux/sched.h"
struct cfs_rq;
#line 139
struct task_group;
#line 334
struct nsproxy;
#line 43 "include/linux/aio_abi.h"
struct io_event {
   __u64 data ;
   __u64 obj ;
   __s64 res ;
   __s64 res2 ;
};
#line 105 "include/linux/aio_abi.h"
struct iovec {
   void *iov_base ;
   __kernel_size_t iov_len ;
};
#line 56 "include/linux/uio.h"
union __anonunion_ki_obj_118 {
   void *user ;
   struct task_struct *tsk ;
};
#line 56 "include/linux/uio.h"
struct kiocb {
   struct list_head ki_run_list ;
   unsigned long ki_flags ;
   int ki_users ;
   unsigned int ki_key ;
   struct file *ki_filp ;
   struct kioctx *ki_ctx ;
   int (*ki_cancel)(struct kiocb * , struct io_event * ) ;
   ssize_t (*ki_retry)(struct kiocb * ) ;
   void (*ki_dtor)(struct kiocb * ) ;
   union __anonunion_ki_obj_118 ki_obj ;
   __u64 ki_user_data ;
   wait_queue_t ki_wait ;
   loff_t ki_pos ;
   void *private ;
   unsigned short ki_opcode ;
   size_t ki_nbytes ;
   char *ki_buf ;
   size_t ki_left ;
   struct iovec ki_inline_vec ;
   struct iovec *ki_iovec ;
   unsigned long ki_nr_segs ;
   unsigned long ki_cur_seg ;
   struct list_head ki_list ;
   struct file *ki_eventfd ;
};
#line 162 "include/linux/aio.h"
struct aio_ring_info {
   unsigned long mmap_base ;
   unsigned long mmap_size ;
   struct page **ring_pages ;
   spinlock_t ring_lock ;
   long nr_pages ;
   unsigned int nr ;
   unsigned int tail ;
   struct page *internal_pages[8U] ;
};
#line 178 "include/linux/aio.h"
struct kioctx {
   atomic_t users ;
   int dead ;
   struct mm_struct *mm ;
   unsigned long user_id ;
   struct kioctx *next ;
   wait_queue_head_t wait ;
   spinlock_t ctx_lock ;
   int reqs_active ;
   struct list_head active_reqs ;
   struct list_head run_list ;
   unsigned int max_reqs ;
   struct aio_ring_info ring_info ;
   struct delayed_work wq ;
};
#line 393 "include/linux/sched.h"
struct sighand_struct {
   atomic_t count ;
   struct k_sigaction action[64U] ;
   spinlock_t siglock ;
   wait_queue_head_t signalfd_wqh ;
};
#line 428 "include/linux/sched.h"
struct pacct_struct {
   int ac_flag ;
   long ac_exitcode ;
   unsigned long ac_mem ;
   cputime_t ac_utime ;
   cputime_t ac_stime ;
   unsigned long ac_minflt ;
   unsigned long ac_majflt ;
};
#line 436 "include/linux/sched.h"
struct task_cputime {
   cputime_t utime ;
   cputime_t stime ;
   unsigned long long sum_exec_runtime ;
};
#line 453 "include/linux/sched.h"
struct thread_group_cputime {
   struct task_cputime *totals ;
};
#line 469 "include/linux/sched.h"
union __anonunion_ldv_18775_119 {
   pid_t pgrp ;
   pid_t __pgrp ;
};
#line 469 "include/linux/sched.h"
union __anonunion_ldv_18780_120 {
   pid_t session ;
   pid_t __session ;
};
#line 469
struct tty_struct;
#line 469
struct taskstats;
#line 469
struct tty_audit_buf;
#line 469 "include/linux/sched.h"
struct signal_struct {
   atomic_t count ;
   atomic_t live ;
   wait_queue_head_t wait_chldexit ;
   struct task_struct *curr_target ;
   struct sigpending shared_pending ;
   int group_exit_code ;
   int notify_count ;
   struct task_struct *group_exit_task ;
   int group_stop_count ;
   unsigned int flags ;
   struct list_head posix_timers ;
   struct hrtimer real_timer ;
   struct pid *leader_pid ;
   ktime_t it_real_incr ;
   cputime_t it_prof_expires ;
   cputime_t it_virt_expires ;
   cputime_t it_prof_incr ;
   cputime_t it_virt_incr ;
   struct thread_group_cputime cputime ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   union __anonunion_ldv_18775_119 ldv_18775 ;
   struct pid *tty_old_pgrp ;
   union __anonunion_ldv_18780_120 ldv_18780 ;
   int leader ;
   struct tty_struct *tty ;
   cputime_t cutime ;
   cputime_t cstime ;
   cputime_t gtime ;
   cputime_t cgtime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   unsigned long cnvcsw ;
   unsigned long cnivcsw ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   unsigned long cmin_flt ;
   unsigned long cmaj_flt ;
   unsigned long inblock ;
   unsigned long oublock ;
   unsigned long cinblock ;
   unsigned long coublock ;
   struct task_io_accounting ioac ;
   struct rlimit rlim[16U] ;
   struct key *session_keyring ;
   struct key *process_keyring ;
   struct pacct_struct pacct ;
   struct taskstats *stats ;
   unsigned int audit_tty ;
   struct tty_audit_buf *tty_audit_buf ;
};
#line 620 "include/linux/sched.h"
struct user_struct {
   atomic_t __count ;
   atomic_t processes ;
   atomic_t files ;
   atomic_t sigpending ;
   atomic_t inotify_watches ;
   atomic_t inotify_devs ;
   atomic_t epoll_devs ;
   atomic_t epoll_watches ;
   unsigned long mq_bytes ;
   unsigned long locked_shm ;
   struct key *uid_keyring ;
   struct key *session_keyring ;
   struct hlist_node uidhash_node ;
   uid_t uid ;
   struct task_group *tg ;
   struct kobject kobj ;
   struct work_struct work ;
};
#line 666
struct reclaim_state;
#line 667 "include/linux/sched.h"
struct sched_info {
   unsigned long pcount ;
   unsigned long long cpu_time ;
   unsigned long long run_delay ;
   unsigned long long last_arrival ;
   unsigned long long last_queued ;
   unsigned int bkl_count ;
};
#line 685 "include/linux/sched.h"
struct task_delay_info {
   spinlock_t lock ;
   unsigned int flags ;
   struct timespec blkio_start ;
   struct timespec blkio_end ;
   u64 blkio_delay ;
   u64 swapin_delay ;
   u32 blkio_count ;
   u32 swapin_count ;
   struct timespec freepages_start ;
   struct timespec freepages_end ;
   u64 freepages_delay ;
   u32 freepages_count ;
};
#line 727
enum cpu_idle_type {
    CPU_IDLE = 0,
    CPU_NOT_IDLE = 1,
    CPU_NEWLY_IDLE = 2,
    CPU_MAX_IDLE_TYPES = 3
} ;
#line 734 "include/linux/sched.h"
struct sched_group {
   struct sched_group *next ;
   cpumask_t cpumask ;
   unsigned int __cpu_power ;
   u32 reciprocal_cpu_power ;
};
#line 794
enum sched_domain_level {
    SD_LV_NONE = 0,
    SD_LV_SIBLING = 1,
    SD_LV_MC = 2,
    SD_LV_CPU = 3,
    SD_LV_NODE = 4,
    SD_LV_ALLNODES = 5,
    SD_LV_MAX = 6
} ;
#line 808 "include/linux/sched.h"
struct sched_domain {
   struct sched_domain *parent ;
   struct sched_domain *child ;
   struct sched_group *groups ;
   cpumask_t span ;
   unsigned long min_interval ;
   unsigned long max_interval ;
   unsigned int busy_factor ;
   unsigned int imbalance_pct ;
   unsigned int cache_nice_tries ;
   unsigned int busy_idx ;
   unsigned int idle_idx ;
   unsigned int newidle_idx ;
   unsigned int wake_idx ;
   unsigned int forkexec_idx ;
   int flags ;
   enum sched_domain_level level ;
   unsigned long last_balance ;
   unsigned int balance_interval ;
   unsigned int nr_balance_failed ;
   u64 last_update ;
   unsigned int lb_count[3U] ;
   unsigned int lb_failed[3U] ;
   unsigned int lb_balanced[3U] ;
   unsigned int lb_imbalance[3U] ;
   unsigned int lb_gained[3U] ;
   unsigned int lb_hot_gained[3U] ;
   unsigned int lb_nobusyg[3U] ;
   unsigned int lb_nobusyq[3U] ;
   unsigned int alb_count ;
   unsigned int alb_failed ;
   unsigned int alb_pushed ;
   unsigned int sbe_count ;
   unsigned int sbe_balanced ;
   unsigned int sbe_pushed ;
   unsigned int sbf_count ;
   unsigned int sbf_balanced ;
   unsigned int sbf_pushed ;
   unsigned int ttwu_wake_remote ;
   unsigned int ttwu_move_affine ;
   unsigned int ttwu_move_balance ;
   char *name ;
};
#line 878
struct io_context;
#line 879 "include/linux/sched.h"
struct group_info {
   int ngroups ;
   atomic_t usage ;
   gid_t small_block[32U] ;
   int nblocks ;
   gid_t *blocks[0U] ;
};
#line 930
struct audit_context;
#line 932
struct rq;
#line 933 "include/linux/sched.h"
struct sched_class {
   struct sched_class  const  *next ;
   void (*enqueue_task)(struct rq * , struct task_struct * , int  ) ;
   void (*dequeue_task)(struct rq * , struct task_struct * , int  ) ;
   void (*yield_task)(struct rq * ) ;
   void (*check_preempt_curr)(struct rq * , struct task_struct * , int  ) ;
   struct task_struct *(*pick_next_task)(struct rq * ) ;
   void (*put_prev_task)(struct rq * , struct task_struct * ) ;
   int (*select_task_rq)(struct task_struct * , int  ) ;
   unsigned long (*load_balance)(struct rq * , int  , struct rq * , unsigned long  ,
                                 struct sched_domain * , enum cpu_idle_type  , int * ,
                                 int * ) ;
   int (*move_one_task)(struct rq * , int  , struct rq * , struct sched_domain * ,
                        enum cpu_idle_type  ) ;
   void (*pre_schedule)(struct rq * , struct task_struct * ) ;
   void (*post_schedule)(struct rq * ) ;
   void (*task_wake_up)(struct rq * , struct task_struct * ) ;
   void (*set_cpus_allowed)(struct task_struct * , cpumask_t const   * ) ;
   void (*rq_online)(struct rq * ) ;
   void (*rq_offline)(struct rq * ) ;
   void (*set_curr_task)(struct rq * ) ;
   void (*task_tick)(struct rq * , struct task_struct * , int  ) ;
   void (*task_new)(struct rq * , struct task_struct * ) ;
   void (*switched_from)(struct rq * , struct task_struct * , int  ) ;
   void (*switched_to)(struct rq * , struct task_struct * , int  ) ;
   void (*prio_changed)(struct rq * , struct task_struct * , int  , int  ) ;
   void (*moved_group)(struct task_struct * ) ;
};
#line 986 "include/linux/sched.h"
struct load_weight {
   unsigned long weight ;
   unsigned long inv_weight ;
};
#line 991 "include/linux/sched.h"
struct sched_entity {
   struct load_weight load ;
   struct rb_node run_node ;
   struct list_head group_node ;
   unsigned int on_rq ;
   u64 exec_start ;
   u64 sum_exec_runtime ;
   u64 vruntime ;
   u64 prev_sum_exec_runtime ;
   u64 last_wakeup ;
   u64 avg_overlap ;
   u64 wait_start ;
   u64 wait_max ;
   u64 wait_count ;
   u64 wait_sum ;
   u64 sleep_start ;
   u64 sleep_max ;
   s64 sum_sleep_runtime ;
   u64 block_start ;
   u64 block_max ;
   u64 exec_max ;
   u64 slice_max ;
   u64 nr_migrations ;
   u64 nr_migrations_cold ;
   u64 nr_failed_migrations_affine ;
   u64 nr_failed_migrations_running ;
   u64 nr_failed_migrations_hot ;
   u64 nr_forced_migrations ;
   u64 nr_forced2_migrations ;
   u64 nr_wakeups ;
   u64 nr_wakeups_sync ;
   u64 nr_wakeups_migrate ;
   u64 nr_wakeups_local ;
   u64 nr_wakeups_remote ;
   u64 nr_wakeups_affine ;
   u64 nr_wakeups_affine_attempts ;
   u64 nr_wakeups_passive ;
   u64 nr_wakeups_idle ;
   struct sched_entity *parent ;
   struct cfs_rq *cfs_rq ;
   struct cfs_rq *my_q ;
};
#line 1057
struct rt_rq;
#line 1057 "include/linux/sched.h"
struct sched_rt_entity {
   struct list_head run_list ;
   unsigned long timeout ;
   unsigned int time_slice ;
   int nr_cpus_allowed ;
   struct sched_rt_entity *back ;
   struct sched_rt_entity *parent ;
   struct rt_rq *rt_rq ;
   struct rt_rq *my_q ;
};
#line 1073
struct linux_binfmt;
#line 1073
struct css_set;
#line 1073
struct compat_robust_list_head;
#line 1073 "include/linux/sched.h"
struct task_struct {
   long volatile   state ;
   void *stack ;
   atomic_t usage ;
   unsigned int flags ;
   unsigned int ptrace ;
   int lock_depth ;
   int prio ;
   int static_prio ;
   int normal_prio ;
   unsigned int rt_priority ;
   struct sched_class  const  *sched_class ;
   struct sched_entity se ;
   struct sched_rt_entity rt ;
   struct hlist_head preempt_notifiers ;
   unsigned char fpu_counter ;
   s8 oomkilladj ;
   unsigned int btrace_seq ;
   unsigned int policy ;
   cpumask_t cpus_allowed ;
   struct sched_info sched_info ;
   struct list_head tasks ;
   struct mm_struct *mm ;
   struct mm_struct *active_mm ;
   struct linux_binfmt *binfmt ;
   int exit_state ;
   int exit_code ;
   int exit_signal ;
   int pdeath_signal ;
   unsigned int personality ;
   unsigned char did_exec : 1 ;
   pid_t pid ;
   pid_t tgid ;
   struct task_struct *real_parent ;
   struct task_struct *parent ;
   struct list_head children ;
   struct list_head sibling ;
   struct task_struct *group_leader ;
   struct list_head ptraced ;
   struct list_head ptrace_entry ;
   struct pid_link pids[3U] ;
   struct list_head thread_group ;
   struct completion *vfork_done ;
   int *set_child_tid ;
   int *clear_child_tid ;
   cputime_t utime ;
   cputime_t stime ;
   cputime_t utimescaled ;
   cputime_t stimescaled ;
   cputime_t gtime ;
   cputime_t prev_utime ;
   cputime_t prev_stime ;
   unsigned long nvcsw ;
   unsigned long nivcsw ;
   struct timespec start_time ;
   struct timespec real_start_time ;
   unsigned long min_flt ;
   unsigned long maj_flt ;
   struct task_cputime cputime_expires ;
   struct list_head cpu_timers[3U] ;
   uid_t uid ;
   uid_t euid ;
   uid_t suid ;
   uid_t fsuid ;
   gid_t gid ;
   gid_t egid ;
   gid_t sgid ;
   gid_t fsgid ;
   struct group_info *group_info ;
   kernel_cap_t cap_effective ;
   kernel_cap_t cap_inheritable ;
   kernel_cap_t cap_permitted ;
   kernel_cap_t cap_bset ;
   struct user_struct *user ;
   unsigned int securebits ;
   unsigned char jit_keyring ;
   struct key *request_key_auth ;
   struct key *thread_keyring ;
   char comm[16U] ;
   int link_count ;
   int total_link_count ;
   struct sysv_sem sysvsem ;
   unsigned long last_switch_timestamp ;
   unsigned long last_switch_count ;
   struct thread_struct thread ;
   struct fs_struct *fs ;
   struct files_struct *files ;
   struct nsproxy *nsproxy ;
   struct signal_struct *signal ;
   struct sighand_struct *sighand ;
   sigset_t blocked ;
   sigset_t real_blocked ;
   sigset_t saved_sigmask ;
   struct sigpending pending ;
   unsigned long sas_ss_sp ;
   size_t sas_ss_size ;
   int (*notifier)(void * ) ;
   void *notifier_data ;
   sigset_t *notifier_mask ;
   void *security ;
   struct audit_context *audit_context ;
   uid_t loginuid ;
   unsigned int sessionid ;
   seccomp_t seccomp ;
   u32 parent_exec_id ;
   u32 self_exec_id ;
   spinlock_t alloc_lock ;
   spinlock_t pi_lock ;
   struct plist_head pi_waiters ;
   struct rt_mutex_waiter *pi_blocked_on ;
   struct mutex_waiter *blocked_on ;
   unsigned int irq_events ;
   int hardirqs_enabled ;
   unsigned long hardirq_enable_ip ;
   unsigned int hardirq_enable_event ;
   unsigned long hardirq_disable_ip ;
   unsigned int hardirq_disable_event ;
   int softirqs_enabled ;
   unsigned long softirq_disable_ip ;
   unsigned int softirq_disable_event ;
   unsigned long softirq_enable_ip ;
   unsigned int softirq_enable_event ;
   int hardirq_context ;
   int softirq_context ;
   u64 curr_chain_key ;
   int lockdep_depth ;
   unsigned int lockdep_recursion ;
   struct held_lock held_locks[48U] ;
   void *journal_info ;
   struct bio *bio_list ;
   struct bio **bio_tail ;
   struct reclaim_state *reclaim_state ;
   struct backing_dev_info *backing_dev_info ;
   struct io_context *io_context ;
   unsigned long ptrace_message ;
   siginfo_t *last_siginfo ;
   struct task_io_accounting ioac ;
   u64 acct_rss_mem1 ;
   u64 acct_vm_mem1 ;
   cputime_t acct_timexpd ;
   nodemask_t mems_allowed ;
   int cpuset_mems_generation ;
   int cpuset_mem_spread_rotor ;
   struct css_set *cgroups ;
   struct list_head cg_list ;
   struct robust_list_head *robust_list ;
   struct compat_robust_list_head *compat_robust_list ;
   struct list_head pi_state_list ;
   struct futex_pi_state *pi_state_cache ;
   struct mempolicy *mempolicy ;
   short il_next ;
   atomic_t fs_excl ;
   struct rcu_head rcu ;
   struct pipe_inode_info *splice_pipe ;
   struct task_delay_info *delays ;
   int make_it_fail ;
   struct prop_local_single dirties ;
   int latency_record_count ;
   struct latency_record latency_record[32U] ;
   unsigned long timer_slack_ns ;
   unsigned long default_timer_slack_ns ;
   struct list_head *scm_work_list ;
};
#line 41 "include/linux/smp_lock.h"
struct cdev {
   struct kobject kobj ;
   struct module *owner ;
   struct file_operations  const  *ops ;
   struct list_head list ;
   dev_t dev ;
   unsigned int count ;
};
#line 34 "include/linux/cdev.h"
struct exception_table_entry {
   unsigned long insn ;
   unsigned long fixup ;
};
#line 15 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/compat.h"
typedef s32 compat_time_t;
#line 36 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/compat.h"
typedef s32 compat_long_t;
#line 41 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/compat.h"
struct compat_timespec {
   compat_time_t tv_sec ;
   s32 tv_nsec ;
};
#line 195 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/compat.h"
typedef u32 compat_uptr_t;
#line 149 "include/linux/compat.h"
struct compat_robust_list {
   compat_uptr_t next ;
};
#line 153 "include/linux/compat.h"
struct compat_robust_list_head {
   struct compat_robust_list list ;
   compat_long_t futex_offset ;
   compat_uptr_t list_op_pending ;
};
#line 155 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/mtrr.h"
enum chipset_type {
    NOT_SUPPORTED = 0,
    SUPPORTED = 1
} ;
#line 160 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/mtrr.h"
struct agp_version {
   u16 major ;
   u16 minor ;
};
#line 44 "include/linux/agp_backend.h"
struct agp_kern_info {
   struct agp_version version ;
   struct pci_dev *device ;
   enum chipset_type chipset ;
   unsigned long mode ;
   unsigned long aper_base ;
   size_t aper_size ;
   int max_memory ;
   int current_memory ;
   bool cant_use_aperture ;
   unsigned long page_mask ;
   struct vm_operations_struct *vm_ops ;
};
#line 58
struct agp_bridge_data;
#line 108 "include/linux/agp_backend.h"
struct pollfd {
   int fd ;
   short events ;
   short revents ;
};
#line 32 "include/linux/poll.h"
struct poll_table_struct {
   void (*qproc)(struct file * , wait_queue_head_t * , struct poll_table_struct * ) ;
};
#line 19 "include/linux/irqreturn.h"
typedef int irqreturn_t;
#line 63 "include/drm/drm.h"
typedef unsigned int drm_handle_t;
#line 66 "include/drm/drm.h"
typedef unsigned int drm_magic_t;
#line 91 "include/drm/drm.h"
struct drm_tex_region {
   unsigned char next ;
   unsigned char prev ;
   unsigned char in_use ;
   unsigned char padding ;
   unsigned int age ;
};
#line 102 "include/drm/drm.h"
struct drm_hw_lock {
   unsigned int volatile   lock ;
   char padding[60U] ;
};
#line 165
enum drm_map_type {
    _DRM_FRAME_BUFFER = 0,
    _DRM_REGISTERS = 1,
    _DRM_SHM = 2,
    _DRM_AGP = 3,
    _DRM_SCATTER_GATHER = 4,
    _DRM_CONSISTENT = 5
} ;
#line 174
enum drm_map_flags {
    _DRM_RESTRICTED = 1,
    _DRM_READ_ONLY = 2,
    _DRM_LOCKED = 4,
    _DRM_KERNEL = 8,
    _DRM_WRITE_COMBINING = 16,
    _DRM_CONTAINS_LOCK = 32,
    _DRM_REMOVABLE = 64,
    _DRM_DRIVER = 128
} ;
#line 196 "include/drm/drm.h"
struct drm_map {
   unsigned long offset ;
   unsigned long size ;
   enum drm_map_type type ;
   enum drm_map_flags flags ;
   void *handle ;
   int mtrr ;
};
#line 225
enum drm_stat_type {
    _DRM_STAT_LOCK = 0,
    _DRM_STAT_OPENS = 1,
    _DRM_STAT_CLOSES = 2,
    _DRM_STAT_IOCTLS = 3,
    _DRM_STAT_LOCKS = 4,
    _DRM_STAT_UNLOCKS = 5,
    _DRM_STAT_VALUE = 6,
    _DRM_STAT_BYTE = 7,
    _DRM_STAT_COUNT = 8,
    _DRM_STAT_IRQ = 9,
    _DRM_STAT_PRIMARY = 10,
    _DRM_STAT_SECONDARY = 11,
    _DRM_STAT_DMA = 12,
    _DRM_STAT_SPECIAL = 13,
    _DRM_STAT_MISSED = 14
} ;
#line 390
enum drm_ctx_flags {
    _DRM_CONTEXT_PRESERVED = 1,
    _DRM_CONTEXT_2DONLY = 2
} ;
#line 562 "include/drm/drm.h"
struct drm_set_version {
   int drm_di_major ;
   int drm_di_minor ;
   int drm_dd_major ;
   int drm_dd_minor ;
};
#line 600 "include/drm/drm.h"
struct idr_layer {
   unsigned long bitmap ;
   struct idr_layer *ary[64U] ;
   int count ;
   int layer ;
   struct rcu_head rcu_head ;
};
#line 58 "include/linux/idr.h"
struct idr {
   struct idr_layer *top ;
   struct idr_layer *id_free ;
   int layers ;
   int id_free_cnt ;
   spinlock_t lock ;
};
#line 145
struct drm_file;
#line 146
struct drm_device;
#line 44 "include/drm/drm_hashtab.h"
struct drm_open_hash {
   unsigned int size ;
   unsigned int order ;
   unsigned int fill ;
   struct hlist_head *table ;
   int use_vmalloc ;
};
#line 270 "include/drm/drmP.h"
typedef int drm_ioctl_t(struct drm_device * , void * , struct drm_file * );
#line 274 "include/drm/drmP.h"
struct drm_ioctl_desc {
   unsigned int cmd ;
   drm_ioctl_t *func ;
   int flags ;
};
#line 304
enum ldv_18252 {
    DRM_LIST_NONE = 0,
    DRM_LIST_FREE = 1,
    DRM_LIST_WAIT = 2,
    DRM_LIST_PEND = 3,
    DRM_LIST_PRIO = 4,
    DRM_LIST_RECLAIM = 5
} ;
#line 313 "include/drm/drmP.h"
struct drm_buf {
   int idx ;
   int total ;
   int order ;
   int used ;
   unsigned long offset ;
   void *address ;
   unsigned long bus_address ;
   struct drm_buf *next ;
   int volatile   waiting ;
   int volatile   pending ;
   wait_queue_head_t dma_wait ;
   struct drm_file *file_priv ;
   int context ;
   int while_locked ;
   enum ldv_18252 list ;
   int dev_priv_size ;
   void *dev_private ;
};
#line 335 "include/drm/drmP.h"
struct drm_waitlist {
   int count ;
   struct drm_buf **bufs ;
   struct drm_buf **rp ;
   struct drm_buf **wp ;
   struct drm_buf **end ;
   spinlock_t read_lock ;
   spinlock_t write_lock ;
};
#line 346 "include/drm/drmP.h"
struct drm_freelist {
   int initialized ;
   atomic_t count ;
   struct drm_buf *next ;
   wait_queue_head_t waiting ;
   int low_mark ;
   int high_mark ;
   atomic_t wfh ;
   spinlock_t lock ;
};
#line 358 "include/drm/drmP.h"
struct drm_dma_handle {
   dma_addr_t busaddr ;
   void *vaddr ;
   size_t size ;
};
#line 363 "include/drm/drmP.h"
typedef struct drm_dma_handle drm_dma_handle_t;
#line 364 "include/drm/drmP.h"
struct drm_buf_entry {
   int buf_size ;
   int buf_count ;
   struct drm_buf *buflist ;
   int seg_count ;
   int page_order ;
   struct drm_dma_handle **seglist ;
   struct drm_freelist freelist ;
};
#line 378
struct drm_minor;
#line 378 "include/drm/drmP.h"
struct drm_file {
   int authenticated ;
   int master ;
   pid_t pid ;
   uid_t uid ;
   drm_magic_t magic ;
   unsigned long ioctl_count ;
   struct list_head lhead ;
   struct drm_minor *minor ;
   int remove_auth_on_close ;
   unsigned long lock_count ;
   struct idr object_idr ;
   spinlock_t table_lock ;
   struct file *filp ;
   void *driver_priv ;
};
#line 398 "include/drm/drmP.h"
struct drm_queue {
   atomic_t use_count ;
   atomic_t finalization ;
   atomic_t block_count ;
   atomic_t block_read ;
   wait_queue_head_t read_queue ;
   atomic_t block_write ;
   wait_queue_head_t write_queue ;
   atomic_t total_queued ;
   atomic_t total_flushed ;
   atomic_t total_locks ;
   enum drm_ctx_flags flags ;
   struct drm_waitlist waitlist ;
   wait_queue_head_t flush_queue ;
};
#line 415 "include/drm/drmP.h"
struct drm_lock_data {
   struct drm_hw_lock *hw_lock ;
   struct drm_file *file_priv ;
   wait_queue_head_t lock_queue ;
   unsigned long lock_time ;
   spinlock_t spinlock ;
   uint32_t kernel_waiters ;
   uint32_t user_waiters ;
   int idle_has_lock ;
};
#line 430
enum ldv_18270 {
    _DRM_DMA_USE_AGP = 1,
    _DRM_DMA_USE_SG = 2,
    _DRM_DMA_USE_FB = 4,
    _DRM_DMA_USE_PCI_RO = 8
} ;
#line 437 "include/drm/drmP.h"
struct drm_device_dma {
   struct drm_buf_entry bufs[23U] ;
   int buf_count ;
   struct drm_buf **buflist ;
   int seg_count ;
   int page_count ;
   unsigned long *pagelist ;
   unsigned long byte_count ;
   enum ldv_18270 flags ;
};
#line 462 "include/drm/drmP.h"
struct drm_agp_head {
   struct agp_kern_info agp_info ;
   struct list_head memory ;
   unsigned long mode ;
   struct agp_bridge_data *bridge ;
   int enabled ;
   int acquired ;
   unsigned long base ;
   int agp_mtrr ;
   int cant_use_aperture ;
   unsigned long page_mask ;
};
#line 480 "include/drm/drmP.h"
struct drm_sg_mem {
   unsigned long handle ;
   void *virtual ;
   int pages ;
   struct page **pagelist ;
   dma_addr_t *busaddr ;
};
#line 491 "include/drm/drmP.h"
struct drm_sigdata {
   int context ;
   struct drm_hw_lock *lock ;
};
#line 496
struct drm_mm;
#line 511 "include/drm/drmP.h"
struct drm_mm {
   struct list_head fl_entry ;
   struct list_head ml_entry ;
};
#line 528 "include/drm/drmP.h"
typedef struct drm_map drm_local_map_t;
#line 564 "include/drm/drmP.h"
struct drm_gem_object {
   struct kref refcount ;
   struct kref handlecount ;
   struct drm_device *dev ;
   struct file *filp ;
   size_t size ;
   int name ;
   uint32_t read_domains ;
   uint32_t write_domain ;
   uint32_t pending_read_domains ;
   uint32_t pending_write_domain ;
   void *driver_private ;
};
#line 614 "include/drm/drmP.h"
struct drm_driver {
   int (*load)(struct drm_device * , unsigned long  ) ;
   int (*firstopen)(struct drm_device * ) ;
   int (*open)(struct drm_device * , struct drm_file * ) ;
   void (*preclose)(struct drm_device * , struct drm_file * ) ;
   void (*postclose)(struct drm_device * , struct drm_file * ) ;
   void (*lastclose)(struct drm_device * ) ;
   int (*unload)(struct drm_device * ) ;
   int (*suspend)(struct drm_device * , pm_message_t  ) ;
   int (*resume)(struct drm_device * ) ;
   int (*dma_ioctl)(struct drm_device * , void * , struct drm_file * ) ;
   void (*dma_ready)(struct drm_device * ) ;
   int (*dma_quiescent)(struct drm_device * ) ;
   int (*context_ctor)(struct drm_device * , int  ) ;
   int (*context_dtor)(struct drm_device * , int  ) ;
   int (*kernel_context_switch)(struct drm_device * , int  , int  ) ;
   void (*kernel_context_switch_unlock)(struct drm_device * ) ;
   int (*dri_library_name)(struct drm_device * , char * ) ;
   u32 (*get_vblank_counter)(struct drm_device * , int  ) ;
   int (*enable_vblank)(struct drm_device * , int  ) ;
   void (*disable_vblank)(struct drm_device * , int  ) ;
   int (*device_is_agp)(struct drm_device * ) ;
   irqreturn_t (*irq_handler)(int  , void * ) ;
   void (*irq_preinstall)(struct drm_device * ) ;
   int (*irq_postinstall)(struct drm_device * ) ;
   void (*irq_uninstall)(struct drm_device * ) ;
   void (*reclaim_buffers)(struct drm_device * , struct drm_file * ) ;
   void (*reclaim_buffers_locked)(struct drm_device * , struct drm_file * ) ;
   void (*reclaim_buffers_idlelocked)(struct drm_device * , struct drm_file * ) ;
   unsigned long (*get_map_ofs)(struct drm_map * ) ;
   unsigned long (*get_reg_ofs)(struct drm_device * ) ;
   void (*set_version)(struct drm_device * , struct drm_set_version * ) ;
   int (*proc_init)(struct drm_minor * ) ;
   void (*proc_cleanup)(struct drm_minor * ) ;
   int (*gem_init_object)(struct drm_gem_object * ) ;
   void (*gem_free_object)(struct drm_gem_object * ) ;
   int major ;
   int minor ;
   int patchlevel ;
   char *name ;
   char *desc ;
   char *date ;
   u32 driver_features ;
   int dev_priv_size ;
   struct drm_ioctl_desc *ioctls ;
   int num_ioctls ;
   struct file_operations fops ;
   struct pci_driver pci_driver ;
};
#line 741 "include/drm/drmP.h"
struct drm_minor {
   int index ;
   int type ;
   dev_t device ;
   struct device kdev ;
   struct drm_device *dev ;
   struct proc_dir_entry *dev_root ;
};
#line 756 "include/drm/drmP.h"
struct drm_device {
   char *unique ;
   int unique_len ;
   char *devname ;
   int if_version ;
   int blocked ;
   spinlock_t count_lock ;
   struct mutex struct_mutex ;
   int open_count ;
   atomic_t ioctl_count ;
   atomic_t vma_count ;
   int buf_use ;
   atomic_t buf_alloc ;
   unsigned long counters ;
   enum drm_stat_type types[15U] ;
   atomic_t counts[15U] ;
   struct list_head filelist ;
   struct drm_open_hash magiclist ;
   struct list_head magicfree ;
   struct list_head maplist ;
   int map_count ;
   struct drm_open_hash map_hash ;
   struct list_head ctxlist ;
   int ctx_count ;
   struct mutex ctxlist_mutex ;
   struct idr ctx_idr ;
   struct list_head vmalist ;
   struct drm_lock_data lock ;
   int queue_count ;
   int queue_reserved ;
   int queue_slots ;
   struct drm_queue **queuelist ;
   struct drm_device_dma *dma ;
   int irq_enabled ;
   long volatile   context_flag ;
   long volatile   interrupt_flag ;
   long volatile   dma_flag ;
   struct timer_list timer ;
   wait_queue_head_t context_wait ;
   int last_checked ;
   int last_context ;
   unsigned long last_switch ;
   struct work_struct work ;
   int vblank_disable_allowed ;
   wait_queue_head_t *vbl_queue ;
   atomic_t *_vblank_count ;
   spinlock_t vbl_lock ;
   struct list_head *vbl_sigs ;
   atomic_t vbl_signal_pending ;
   atomic_t *vblank_refcount ;
   u32 *last_vblank ;
   int *vblank_enabled ;
   int *vblank_inmodeset ;
   struct timer_list vblank_disable_timer ;
   u32 max_vblank_count ;
   cycles_t ctx_start ;
   cycles_t lck_start ;
   struct fasync_struct *buf_async ;
   wait_queue_head_t buf_readers ;
   wait_queue_head_t buf_writers ;
   struct drm_agp_head *agp ;
   struct pci_dev *pdev ;
   int pci_vendor ;
   int pci_device ;
   struct drm_sg_mem *sg ;
   int num_crtcs ;
   void *dev_private ;
   struct drm_sigdata sigdata ;
   sigset_t sigmask ;
   struct drm_driver *driver ;
   drm_local_map_t *agp_buffer_map ;
   unsigned int agp_buffer_token ;
   struct drm_minor *primary ;
   spinlock_t drw_lock ;
   struct idr drw_idr ;
   spinlock_t object_name_lock ;
   struct idr object_name_idr ;
   atomic_t object_count ;
   atomic_t object_memory ;
   atomic_t pin_count ;
   atomic_t pin_memory ;
   atomic_t gtt_count ;
   atomic_t gtt_memory ;
   uint32_t gtt_total ;
   uint32_t invalidate_domains ;
   uint32_t flush_domains ;
};
#line 65 "include/drm/i915_drm.h"
struct _drm_i915_sarea {
   struct drm_tex_region texList[256U] ;
   int last_upload ;
   int last_enqueue ;
   int last_dispatch ;
   int ctxOwner ;
   int texAge ;
   int pf_enabled ;
   int pf_active ;
   int pf_current_page ;
   int perf_boxes ;
   int width ;
   int height ;
   drm_handle_t front_handle ;
   int front_offset ;
   int front_size ;
   drm_handle_t back_handle ;
   int back_offset ;
   int back_size ;
   drm_handle_t depth_handle ;
   int depth_offset ;
   int depth_size ;
   drm_handle_t tex_handle ;
   int tex_offset ;
   int tex_size ;
   int log_tex_granularity ;
   int pitch ;
   int rotation ;
   int rotated_offset ;
   int rotated_size ;
   int rotated_pitch ;
   int virtualX ;
   int virtualY ;
   unsigned int front_tiled ;
   unsigned int back_tiled ;
   unsigned int depth_tiled ;
   unsigned int rotated_tiled ;
   unsigned int rotated2_tiled ;
   int pipeA_x ;
   int pipeA_y ;
   int pipeA_w ;
   int pipeA_h ;
   int pipeB_x ;
   int pipeB_y ;
   int pipeB_w ;
   int pipeB_h ;
};
#line 116 "include/drm/i915_drm.h"
typedef struct _drm_i915_sarea drm_i915_sarea_t;
#line 31 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/iomap.h"
struct io_mapping;
#line 127 "include/linux/io-mapping.h"
struct _drm_i915_ring_buffer {
   int tail_mask ;
   unsigned long Size ;
   u8 *virtual_start ;
   int head ;
   int tail ;
   int space ;
   drm_local_map_t map ;
   struct drm_gem_object *ring_obj ;
};
#line 83 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
typedef struct _drm_i915_ring_buffer drm_i915_ring_buffer_t;
#line 84 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
struct mem_block {
   struct mem_block *next ;
   struct mem_block *prev ;
   int start ;
   int size ;
   struct drm_file *file_priv ;
};
#line 92
struct opregion_header;
#line 93
struct opregion_acpi;
#line 94
struct opregion_swsci;
#line 95
struct opregion_asle;
#line 96 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
struct intel_opregion {
   struct opregion_header *header ;
   struct opregion_acpi *acpi ;
   struct opregion_swsci *swsci ;
   struct opregion_asle *asle ;
   int enabled ;
};
#line 105 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
struct __anonstruct_mm_126 {
   struct drm_mm gtt_space ;
   struct io_mapping *gtt_mapping ;
   struct list_head active_list ;
   struct list_head flushing_list ;
   struct list_head inactive_list ;
   struct list_head request_list ;
   struct delayed_work retire_work ;
   uint32_t next_gem_seqno ;
   uint32_t waiting_gem_seqno ;
   uint32_t irq_gem_seqno ;
   int suspended ;
   int wedged ;
   uint32_t bit_6_swizzle_x ;
   uint32_t bit_6_swizzle_y ;
};
#line 105 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
struct drm_i915_private {
   struct drm_device *dev ;
   void *regs ;
   drm_local_map_t *sarea ;
   drm_i915_sarea_t *sarea_priv ;
   drm_i915_ring_buffer_t ring ;
   drm_dma_handle_t *status_page_dmah ;
   void *hw_status_page ;
   dma_addr_t dma_status_page ;
   uint32_t counter ;
   unsigned int status_gfx_addr ;
   drm_local_map_t hws_map ;
   struct drm_gem_object *hws_obj ;
   unsigned int cpp ;
   int back_offset ;
   int front_offset ;
   int current_page ;
   int page_flipping ;
   wait_queue_head_t irq_queue ;
   atomic_t irq_received ;
   spinlock_t user_irq_lock ;
   int user_irq_refcount ;
   u32 irq_mask_reg ;
   u32 pipestat[2U] ;
   int tex_lru_log_granularity ;
   int allow_batchbuffer ;
   struct mem_block *agp_heap ;
   unsigned int sr01 ;
   unsigned int adpa ;
   unsigned int ppcr ;
   unsigned int dvob ;
   unsigned int dvoc ;
   unsigned int lvds ;
   int vblank_pipe ;
   struct intel_opregion opregion ;
   u8 saveLBB ;
   u32 saveDSPACNTR ;
   u32 saveDSPBCNTR ;
   u32 saveDSPARB ;
   u32 saveRENDERSTANDBY ;
   u32 saveHWS ;
   u32 savePIPEACONF ;
   u32 savePIPEBCONF ;
   u32 savePIPEASRC ;
   u32 savePIPEBSRC ;
   u32 saveFPA0 ;
   u32 saveFPA1 ;
   u32 saveDPLL_A ;
   u32 saveDPLL_A_MD ;
   u32 saveHTOTAL_A ;
   u32 saveHBLANK_A ;
   u32 saveHSYNC_A ;
   u32 saveVTOTAL_A ;
   u32 saveVBLANK_A ;
   u32 saveVSYNC_A ;
   u32 saveBCLRPAT_A ;
   u32 savePIPEASTAT ;
   u32 saveDSPASTRIDE ;
   u32 saveDSPASIZE ;
   u32 saveDSPAPOS ;
   u32 saveDSPAADDR ;
   u32 saveDSPASURF ;
   u32 saveDSPATILEOFF ;
   u32 savePFIT_PGM_RATIOS ;
   u32 saveBLC_PWM_CTL ;
   u32 saveBLC_PWM_CTL2 ;
   u32 saveFPB0 ;
   u32 saveFPB1 ;
   u32 saveDPLL_B ;
   u32 saveDPLL_B_MD ;
   u32 saveHTOTAL_B ;
   u32 saveHBLANK_B ;
   u32 saveHSYNC_B ;
   u32 saveVTOTAL_B ;
   u32 saveVBLANK_B ;
   u32 saveVSYNC_B ;
   u32 saveBCLRPAT_B ;
   u32 savePIPEBSTAT ;
   u32 saveDSPBSTRIDE ;
   u32 saveDSPBSIZE ;
   u32 saveDSPBPOS ;
   u32 saveDSPBADDR ;
   u32 saveDSPBSURF ;
   u32 saveDSPBTILEOFF ;
   u32 saveVGA0 ;
   u32 saveVGA1 ;
   u32 saveVGA_PD ;
   u32 saveVGACNTRL ;
   u32 saveADPA ;
   u32 saveLVDS ;
   u32 savePP_ON_DELAYS ;
   u32 savePP_OFF_DELAYS ;
   u32 saveDVOA ;
   u32 saveDVOB ;
   u32 saveDVOC ;
   u32 savePP_ON ;
   u32 savePP_OFF ;
   u32 savePP_CONTROL ;
   u32 savePP_DIVISOR ;
   u32 savePFIT_CONTROL ;
   u32 save_palette_a[256U] ;
   u32 save_palette_b[256U] ;
   u32 saveFBC_CFB_BASE ;
   u32 saveFBC_LL_BASE ;
   u32 saveFBC_CONTROL ;
   u32 saveFBC_CONTROL2 ;
   u32 saveIER ;
   u32 saveIIR ;
   u32 saveIMR ;
   u32 saveCACHE_MODE_0 ;
   u32 saveD_STATE ;
   u32 saveCG_2D_DIS ;
   u32 saveMI_ARB_STATE ;
   u32 saveSWF0[16U] ;
   u32 saveSWF1[16U] ;
   u32 saveSWF2[3U] ;
   u8 saveMSR ;
   u8 saveSR[8U] ;
   u8 saveGR[25U] ;
   u8 saveAR_INDEX ;
   u8 saveAR[21U] ;
   u8 saveDACMASK ;
   u8 saveDACDATA[768U] ;
   u8 saveCR[37U] ;
   struct __anonstruct_mm_126 mm ;
};
#line 123 "include/linux/types.h"
typedef __u64 uint64_t;
#line 21 "include/asm-generic/page.h"
struct x8664_pda {
   struct task_struct *pcurrent ;
   unsigned long data_offset ;
   unsigned long kernelstack ;
   unsigned long oldrsp ;
   int irqcount ;
   unsigned int cpunumber ;
   char *irqstackptr ;
   short nodenumber ;
   short in_bootmem ;
   unsigned int __softirq_pending ;
   unsigned int __nmi_count ;
   short mmu_state ;
   short isidle ;
   struct mm_struct *active_mm ;
   unsigned int apic_timer_irqs ;
   unsigned int irq0_irqs ;
   unsigned int irq_resched_count ;
   unsigned int irq_call_count ;
   unsigned int irq_tlb_count ;
   unsigned int irq_thermal_count ;
   unsigned int irq_threshold_count ;
   unsigned int irq_spurious_count ;
};
#line 182 "include/linux/timer.h"
enum hrtimer_restart;
#line 220 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/uaccess.h"
struct __large_struct {
   unsigned long buf[100U] ;
};
#line 67 "include/drm/drm.h"
struct drm_clip_rect {
   unsigned short x1 ;
   unsigned short y1 ;
   unsigned short x2 ;
   unsigned short y2 ;
};
#line 1366 "include/drm/drmP.h"
enum ldv_18577 {
    I915_INIT_DMA = 1,
    I915_CLEANUP_DMA = 2,
    I915_RESUME_DMA = 3
} ;
#line 1372 "include/drm/drmP.h"
struct _drm_i915_init {
   enum ldv_18577 func ;
   unsigned int mmio_offset ;
   int sarea_priv_offset ;
   unsigned int ring_start ;
   unsigned int ring_end ;
   unsigned int ring_size ;
   unsigned int front_offset ;
   unsigned int back_offset ;
   unsigned int depth_offset ;
   unsigned int w ;
   unsigned int h ;
   unsigned int pitch ;
   unsigned int pitch_bits ;
   unsigned int back_pitch ;
   unsigned int depth_pitch ;
   unsigned int cpp ;
   unsigned int chipset ;
};
#line 64 "include/drm/i915_drm.h"
typedef struct _drm_i915_init drm_i915_init_t;
#line 117 "include/drm/i915_drm.h"
struct _drm_i915_batchbuffer {
   int start ;
   int used ;
   int DR1 ;
   int DR4 ;
   int num_cliprects ;
   struct drm_clip_rect *cliprects ;
};
#line 206 "include/drm/i915_drm.h"
typedef struct _drm_i915_batchbuffer drm_i915_batchbuffer_t;
#line 207 "include/drm/i915_drm.h"
struct _drm_i915_cmdbuffer {
   char *buf ;
   int sz ;
   int DR1 ;
   int DR4 ;
   int num_cliprects ;
   struct drm_clip_rect *cliprects ;
};
#line 218 "include/drm/i915_drm.h"
typedef struct _drm_i915_cmdbuffer drm_i915_cmdbuffer_t;
#line 229 "include/drm/i915_drm.h"
struct drm_i915_getparam {
   int param ;
   int *value ;
};
#line 241 "include/drm/i915_drm.h"
typedef struct drm_i915_getparam drm_i915_getparam_t;
#line 242 "include/drm/i915_drm.h"
struct drm_i915_setparam {
   int param ;
   int value ;
};
#line 252 "include/drm/i915_drm.h"
typedef struct drm_i915_setparam drm_i915_setparam_t;
#line 299 "include/drm/i915_drm.h"
struct drm_i915_hws_addr {
   uint64_t addr ;
};
#line 302 "include/drm/i915_drm.h"
typedef struct drm_i915_hws_addr drm_i915_hws_addr_t;
#line 329 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
typedef struct drm_i915_private drm_i915_private_t;
#line 407 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
struct __anonstruct_mm_127 {
   uint32_t last_gem_seqno ;
   uint32_t last_gem_throttle_seqno ;
};
#line 407 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
struct drm_i915_file_private {
   struct __anonstruct_mm_127 mm ;
};
#line 182 "include/linux/timer.h"
enum hrtimer_restart;
#line 219 "include/drm/i915_drm.h"
struct drm_i915_irq_emit {
   int *irq_seq ;
};
#line 224 "include/drm/i915_drm.h"
typedef struct drm_i915_irq_emit drm_i915_irq_emit_t;
#line 225 "include/drm/i915_drm.h"
struct drm_i915_irq_wait {
   int irq_seq ;
};
#line 228 "include/drm/i915_drm.h"
typedef struct drm_i915_irq_wait drm_i915_irq_wait_t;
#line 282 "include/drm/i915_drm.h"
struct drm_i915_vblank_pipe {
   int pipe ;
};
#line 290 "include/drm/i915_drm.h"
typedef struct drm_i915_vblank_pipe drm_i915_vblank_pipe_t;
#line 182 "include/linux/timer.h"
enum hrtimer_restart;
#line 253 "include/drm/i915_drm.h"
struct drm_i915_mem_alloc {
   int region ;
   int alignment ;
   int size ;
   int *region_offset ;
};
#line 263 "include/drm/i915_drm.h"
typedef struct drm_i915_mem_alloc drm_i915_mem_alloc_t;
#line 264 "include/drm/i915_drm.h"
struct drm_i915_mem_free {
   int region ;
   int region_offset ;
};
#line 268 "include/drm/i915_drm.h"
typedef struct drm_i915_mem_free drm_i915_mem_free_t;
#line 269 "include/drm/i915_drm.h"
struct drm_i915_mem_init_heap {
   int region ;
   int size ;
   int start ;
};
#line 274 "include/drm/i915_drm.h"
typedef struct drm_i915_mem_init_heap drm_i915_mem_init_heap_t;
#line 275 "include/drm/i915_drm.h"
struct drm_i915_mem_destroy_heap {
   int region ;
};
#line 281 "include/drm/i915_drm.h"
typedef struct drm_i915_mem_destroy_heap drm_i915_mem_destroy_heap_t;
#line 182 "include/linux/timer.h"
enum hrtimer_restart;
#line 122 "include/linux/io-mapping.h"
enum pipe {
    PIPE_A = 0,
    PIPE_B = 1
} ;
#line 18 "include/asm-generic/int-ll64.h"
typedef unsigned char __u8;
#line 118 "include/linux/types.h"
typedef __u8 uint8_t;
#line 182 "include/linux/timer.h"
enum hrtimer_restart;
#line 59 "include/linux/agp_backend.h"
struct agp_memory {
   struct agp_memory *next ;
   struct agp_memory *prev ;
   struct agp_bridge_data *bridge ;
   unsigned long *memory ;
   size_t page_count ;
   int key ;
   int num_scratch_pages ;
   off_t pg_start ;
   u32 type ;
   u32 physical ;
   bool is_bound ;
   bool is_flushed ;
   bool vmalloc_flag ;
   struct list_head mapped_list ;
};
#line 229 "include/linux/pagemap.h"
typedef int filler_t(void * , struct page * );
#line 496 "include/drm/drmP.h"
struct drm_mm_node {
   struct list_head fl_entry ;
   struct list_head ml_entry ;
   int free ;
   unsigned long start ;
   unsigned long size ;
   struct drm_mm *mm ;
   void *private ;
};
#line 303 "include/drm/i915_drm.h"
struct drm_i915_gem_init {
   uint64_t gtt_start ;
   uint64_t gtt_end ;
};
#line 316 "include/drm/i915_drm.h"
struct drm_i915_gem_create {
   uint64_t size ;
   uint32_t handle ;
   uint32_t pad ;
};
#line 332 "include/drm/i915_drm.h"
struct drm_i915_gem_pread {
   uint32_t handle ;
   uint32_t pad ;
   uint64_t offset ;
   uint64_t size ;
   uint64_t data_ptr ;
};
#line 348 "include/drm/i915_drm.h"
struct drm_i915_gem_pwrite {
   uint32_t handle ;
   uint32_t pad ;
   uint64_t offset ;
   uint64_t size ;
   uint64_t data_ptr ;
};
#line 364 "include/drm/i915_drm.h"
struct drm_i915_gem_mmap {
   uint32_t handle ;
   uint32_t pad ;
   uint64_t offset ;
   uint64_t size ;
   uint64_t addr_ptr ;
};
#line 384 "include/drm/i915_drm.h"
struct drm_i915_gem_set_domain {
   uint32_t handle ;
   uint32_t read_domains ;
   uint32_t write_domain ;
};
#line 395 "include/drm/i915_drm.h"
struct drm_i915_gem_sw_finish {
   uint32_t handle ;
};
#line 400 "include/drm/i915_drm.h"
struct drm_i915_gem_relocation_entry {
   uint32_t target_handle ;
   uint32_t delta ;
   uint64_t offset ;
   uint64_t presumed_offset ;
   uint32_t read_domains ;
   uint32_t write_domain ;
};
#line 445 "include/drm/i915_drm.h"
struct drm_i915_gem_exec_object {
   uint32_t handle ;
   uint32_t relocation_count ;
   uint64_t relocs_ptr ;
   uint64_t alignment ;
   uint64_t offset ;
};
#line 493 "include/drm/i915_drm.h"
struct drm_i915_gem_execbuffer {
   uint64_t buffers_ptr ;
   uint32_t buffer_count ;
   uint32_t batch_start_offset ;
   uint32_t batch_len ;
   uint32_t DR1 ;
   uint32_t DR4 ;
   uint32_t num_cliprects ;
   uint64_t cliprects_ptr ;
};
#line 518 "include/drm/i915_drm.h"
struct drm_i915_gem_pin {
   uint32_t handle ;
   uint32_t pad ;
   uint64_t alignment ;
   uint64_t offset ;
};
#line 536 "include/drm/i915_drm.h"
struct drm_i915_gem_busy {
   uint32_t handle ;
   uint32_t busy ;
};
#line 604 "include/drm/i915_drm.h"
struct drm_i915_gem_get_aperture {
   uint64_t aper_size ;
   uint64_t aper_available_size ;
};
#line 330 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
struct drm_i915_gem_object {
   struct drm_gem_object *obj ;
   struct drm_mm_node *gtt_space ;
   struct list_head list ;
   int active ;
   int dirty ;
   struct agp_memory *agp_mem ;
   struct page **page_list ;
   uint32_t gtt_offset ;
   int gtt_bound ;
   int pin_count ;
   uint32_t last_rendering_seqno ;
   uint32_t tiling_mode ;
   uint32_t agp_type ;
   uint8_t *page_cpu_valid ;
};
#line 387 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
struct drm_i915_gem_request {
   uint32_t seqno ;
   unsigned long emitted_jiffies ;
   struct list_head list ;
};
#line 82 "include/linux/swap.h"
struct reclaim_state {
   unsigned long reclaimed_slab ;
};
#line 182 "include/linux/timer.h"
enum hrtimer_restart;
#line 182
enum hrtimer_restart;
#line 266 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
struct drm_proc_list {
   char const   *name ;
   int (*f)(char * , char ** , off_t  , int  , int * , void * ) ;
};
#line 182 "include/linux/timer.h"
enum hrtimer_restart;
#line 544 "include/drm/i915_drm.h"
struct drm_i915_gem_set_tiling {
   uint32_t handle ;
   uint32_t tiling_mode ;
   uint32_t stride ;
   uint32_t swizzle_mode ;
};
#line 587 "include/drm/i915_drm.h"
struct drm_i915_gem_get_tiling {
   uint32_t handle ;
   uint32_t tiling_mode ;
   uint32_t swizzle_mode ;
};
#line 52 "include/linux/srcu.h"
struct notifier_block {
   int (*notifier_call)(struct notifier_block * , unsigned long  , void * ) ;
   struct notifier_block *next ;
   int priority ;
};
#line 182 "include/linux/timer.h"
enum hrtimer_restart;
#line 632 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
struct opregion_header {
   u8 signature[16U] ;
   u32 size ;
   u32 opregion_ver ;
   u8 bios_ver[32U] ;
   u8 vbios_ver[16U] ;
   u8 driver_ver[16U] ;
   u32 mboxes ;
   u8 reserved[164U] ;
};
#line 75 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
struct opregion_acpi {
   u32 drdy ;
   u32 csts ;
   u32 cevt ;
   u8 rsvd1[20U] ;
   u32 didl[8U] ;
   u32 cpdl[8U] ;
   u32 cadl[8U] ;
   u32 nadl[8U] ;
   u32 aslp ;
   u32 tidx ;
   u32 chpd ;
   u32 clid ;
   u32 cdck ;
   u32 sxsw ;
   u32 evts ;
   u32 cnot ;
   u32 nrdy ;
   u8 rsvd2[60U] ;
};
#line 97 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
struct opregion_swsci {
   u32 scic ;
   u32 parm ;
   u32 dslp ;
   u8 rsvd[244U] ;
};
#line 105 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
struct opregion_asle {
   u32 ardy ;
   u32 aslc ;
   u32 tche ;
   u32 alsi ;
   u32 bclp ;
   u32 pfit ;
   u32 cblv ;
   u16 bclm[20U] ;
   u32 cpfm ;
   u32 epfm ;
   u8 plut[74U] ;
   u32 pfmb ;
   u8 rsvd[102U] ;
};
#line 182 "include/linux/timer.h"
enum hrtimer_restart;
#line 273 "include/drm/drmP.h"
typedef int drm_ioctl_compat_t(struct file * , unsigned int  , unsigned long  );
#line 615 "include/drm/i915_drm.h"
struct _drm_i915_batchbuffer32 {
   int start ;
   int used ;
   int DR1 ;
   int DR4 ;
   int num_cliprects ;
   u32 cliprects ;
};
#line 59 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
typedef struct _drm_i915_batchbuffer32 drm_i915_batchbuffer32_t;
#line 87 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
struct _drm_i915_cmdbuffer32 {
   u32 buf ;
   int sz ;
   int DR1 ;
   int DR4 ;
   int num_cliprects ;
   u32 cliprects ;
};
#line 95 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
typedef struct _drm_i915_cmdbuffer32 drm_i915_cmdbuffer32_t;
#line 122 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
struct drm_i915_irq_emit32 {
   u32 irq_seq ;
};
#line 125 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
typedef struct drm_i915_irq_emit32 drm_i915_irq_emit32_t;
#line 145 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
struct drm_i915_getparam32 {
   int param ;
   u32 value ;
};
#line 148 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
typedef struct drm_i915_getparam32 drm_i915_getparam32_t;
#line 169 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
struct drm_i915_mem_alloc32 {
   int region ;
   int alignment ;
   int size ;
   u32 region_offset ;
};
#line 175 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
typedef struct drm_i915_mem_alloc32 drm_i915_mem_alloc32_t;
#line 14 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/rule-instrumentor/43_1a/common-model/ldv_common_model.c"
enum __anonenum_97 {
    LDV_SPIN_UNLOCKED = 0,
    LDV_SPIN_LOCKED = 1
} ;
#line 221 "include/linux/kernel.h"
extern int printk(char const   *  , ...) ;
#line 223 "include/linux/gfp.h"
extern struct page *alloc_page_vma(gfp_t  , struct vm_area_struct * , unsigned long  ) ;
#line 227
struct page *ldv_alloc_page_vma_12(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) ;
#line 236
extern unsigned long __get_free_pages(gfp_t  , unsigned int  ) ;
#line 239
unsigned long ldv___get_free_pages_2(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 204 "include/linux/slub_def.h"
extern void *kmem_cache_alloc(struct kmem_cache * , gfp_t  ) ;
#line 207
void *ldv_kmem_cache_alloc_4(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_8(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 86 "include/linux/module.h"
extern struct module __this_module ;
#line 11 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
void ldv_check_alloc_flags(gfp_t flags ) ;
#line 613 "include/linux/pci.h"
extern int pci_enable_device(struct pci_dev * ) ;
#line 625
extern void pci_disable_device(struct pci_dev * ) ;
#line 626
extern void pci_set_master(struct pci_dev * ) ;
#line 657
extern int pci_save_state(struct pci_dev * ) ;
#line 658
extern int pci_restore_state(struct pci_dev * ) ;
#line 659
extern int pci_set_power_state(struct pci_dev * , pci_power_t  ) ;
#line 984 "include/drm/drmP.h"
extern int drm_init(struct drm_driver * ) ;
#line 985
extern void drm_exit(struct drm_driver * ) ;
#line 986
extern int drm_ioctl(struct inode * , struct file * , unsigned int  , unsigned long  ) ;
#line 993
extern int drm_open(struct inode * , struct file * ) ;
#line 995
extern int drm_fasync(int  , struct file * , int  ) ;
#line 996
extern int drm_release(struct inode * , struct file * ) ;
#line 999
extern int drm_mmap(struct file * , struct vm_area_struct * ) ;
#line 1000
extern unsigned long drm_core_get_map_ofs(struct drm_map * ) ;
#line 1001
extern unsigned long drm_core_get_reg_ofs(struct drm_device * ) ;
#line 1002
extern unsigned int drm_poll(struct file * , struct poll_table_struct * ) ;
#line 1133
extern void drm_core_reclaim_buffers(struct drm_device * , struct drm_file * ) ;
#line 415 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
struct drm_ioctl_desc i915_ioctls[36U] ;
#line 416
int i915_max_ioctl ;
#line 420
int i915_driver_load(struct drm_device *dev , unsigned long flags ) ;
#line 421
int i915_driver_unload(struct drm_device *dev ) ;
#line 422
int i915_driver_open(struct drm_device *dev , struct drm_file *file_priv ) ;
#line 423
void i915_driver_lastclose(struct drm_device *dev ) ;
#line 424
void i915_driver_preclose(struct drm_device *dev , struct drm_file *file_priv ) ;
#line 426
void i915_driver_postclose(struct drm_device *dev , struct drm_file *file_priv ) ;
#line 428
int i915_driver_device_is_agp(struct drm_device *dev ) ;
#line 429
long i915_compat_ioctl(struct file *filp , unsigned int cmd , unsigned long arg ) ;
#line 443
irqreturn_t i915_driver_irq_handler(int irq , void *arg ) ;
#line 444
void i915_driver_irq_preinstall(struct drm_device *dev ) ;
#line 445
int i915_driver_irq_postinstall(struct drm_device *dev ) ;
#line 446
void i915_driver_irq_uninstall(struct drm_device *dev ) ;
#line 451
int i915_enable_vblank(struct drm_device *dev , int pipe ) ;
#line 452
void i915_disable_vblank(struct drm_device *dev , int pipe ) ;
#line 453
u32 i915_get_vblank_counter(struct drm_device *dev , int pipe ) ;
#line 513
int i915_gem_proc_init(struct drm_minor *minor ) ;
#line 514
void i915_gem_proc_cleanup(struct drm_minor *minor ) ;
#line 515
int i915_gem_init_object(struct drm_gem_object *obj ) ;
#line 516
void i915_gem_free_object(struct drm_gem_object *obj ) ;
#line 542
int i915_save_state(struct drm_device *dev ) ;
#line 543
int i915_restore_state(struct drm_device *dev ) ;
#line 551
int intel_opregion_init(struct drm_device *dev ) ;
#line 552
void intel_opregion_free(struct drm_device *dev ) ;
#line 52 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
static struct pci_device_id pciidlist[24U]  = 
#line 52 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
  {      {32902U, 13687U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 9570U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 13698U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 9586U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 9602U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 9610U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 9618U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10098U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10146U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10158U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10610U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10626U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10642U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10658U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10674U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10690U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10706U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10754U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10770U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 10818U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 11778U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 11794U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {32902U, 11810U, 4294967295U, 4294967295U, 196608U, 16776960U, 0UL}, 
        {0U, 0U, 0U, 0U, 0U, 0U, 0UL}};
#line 56 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
static int i915_suspend(struct drm_device *dev , pm_message_t state ) 
{ 
  struct drm_i915_private *dev_priv ;

  {
#line 58
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 60
  if ((unsigned long )dev == (unsigned long )((struct drm_device *)0) || (unsigned long )dev_priv == (unsigned long )((struct drm_i915_private *)0)) {
#line 61
    printk("<3>dev: %p, dev_priv: %p\n", dev, dev_priv);
#line 62
    printk("<3>DRM not initialized, aborting suspend.\n");
#line 63
    return (-19);
  } else {

  }
#line 66
  if (state.event == 8) {
#line 67
    return (0);
  } else {

  }
#line 69
  pci_save_state(dev->pdev);
#line 71
  i915_save_state(dev);
#line 73
  intel_opregion_free(dev);
#line 75
  if (state.event == 2) {
#line 77
    pci_disable_device(dev->pdev);
#line 78
    pci_set_power_state(dev->pdev, 3);
  } else {

  }
#line 81
  return (0);
}
}
#line 84 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
static int i915_resume(struct drm_device *dev ) 
{ 
  int tmp ;

  {
#line 86
  pci_set_power_state(dev->pdev, 0);
#line 87
  pci_restore_state(dev->pdev);
#line 88
  tmp = pci_enable_device(dev->pdev);
#line 88
  if (tmp != 0) {
#line 89
    return (-1);
  } else {

  }
#line 90
  pci_set_master(dev->pdev);
#line 92
  i915_restore_state(dev);
#line 94
  intel_opregion_init(dev);
#line 96
  return (0);
}
}
#line 99 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
static struct drm_driver driver  = 
#line 99
     {& i915_driver_load, 0, & i915_driver_open, & i915_driver_preclose, & i915_driver_postclose,
    & i915_driver_lastclose, & i915_driver_unload, & i915_suspend, & i915_resume,
    0, 0, 0, 0, 0, 0, 0, 0, & i915_get_vblank_counter, & i915_enable_vblank, & i915_disable_vblank,
    & i915_driver_device_is_agp, & i915_driver_irq_handler, & i915_driver_irq_preinstall,
    & i915_driver_irq_postinstall, & i915_driver_irq_uninstall, & drm_core_reclaim_buffers,
    0, 0, & drm_core_get_map_ofs, & drm_core_get_reg_ofs, 0, & i915_gem_proc_init,
    & i915_gem_proc_cleanup, & i915_gem_init_object, & i915_gem_free_object, 1, 6,
    0, (char *)"i915", (char *)"Intel Graphics", (char *)"20080730", 4291U, 0, (struct drm_ioctl_desc *)(& i915_ioctls),
    0, {& __this_module, 0, 0, 0, 0, 0, 0, & drm_poll, & drm_ioctl, 0, & i915_compat_ioctl,
        & drm_mmap, & drm_open, 0, & drm_release, 0, 0, & drm_fasync, 0, 0, 0, 0,
        0, 0, 0, 0, 0}, {{0, 0}, (char *)"i915", (struct pci_device_id  const  *)(& pciidlist),
                         0, 0, 0, 0, 0, 0, 0, 0, 0, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                                                     0, 0}, {{{0U}, 0U, 0U, 0, {0,
                                                                                0,
                                                                                0,
                                                                                0}},
                                                             {0, 0}}}};
#line 156 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
static int i915_init(void) 
{ 
  int tmp ;

  {
#line 158
  driver.num_ioctls = i915_max_ioctl;
#line 159
  tmp = drm_init(& driver);
#line 159
  return (tmp);
}
}
#line 162 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
static void i915_exit(void) 
{ 


  {
#line 164
  drm_exit(& driver);
#line 165
  return;
}
}
#line 190
extern void ldv_check_final_state(void) ;
#line 199
extern void ldv_initialize(void) ;
#line 202
extern void ldv_handler_precall(void) ;
#line 205
extern int nondet_int(void) ;
#line 208 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
int LDV_IN_INTERRUPT  ;
#line 211 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
void main(void) 
{ 
  struct drm_device *var_group1 ;
  pm_message_t var_i915_suspend_0_p1 ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;

  {
#line 241
  LDV_IN_INTERRUPT = 1;
#line 250
  ldv_initialize();
#line 259
  ldv_handler_precall();
#line 260
  tmp = i915_init();
#line 260
  if (tmp != 0) {
#line 261
    goto ldv_final;
  } else {

  }
#line 265
  goto ldv_23844;
  ldv_23843: 
#line 268
  tmp___0 = nondet_int();
#line 268
  switch (tmp___0) {
  case 0: 
#line 278
  ldv_handler_precall();
#line 279
  i915_suspend(var_group1, var_i915_suspend_0_p1);
#line 290
  goto ldv_23840;
  case 1: 
#line 299
  ldv_handler_precall();
#line 300
  i915_resume(var_group1);
#line 311
  goto ldv_23840;
  default: ;
#line 312
  goto ldv_23840;
  }
  ldv_23840: ;
  ldv_23844: 
#line 265
  tmp___1 = nondet_int();
#line 265
  if (tmp___1 != 0) {
#line 266
    goto ldv_23843;
  } else {

  }

#line 327
  ldv_handler_precall();
#line 328
  i915_exit();
  ldv_final: 
#line 331
  ldv_check_final_state();
#line 334
  return;
}
}
#line 349 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
unsigned long ldv___get_free_pages_2(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 355
  ldv_check_alloc_flags(ldv_func_arg1);
#line 357
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 357
  return (tmp);
}
}
#line 371 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
void *ldv_kmem_cache_alloc_4(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 377
  ldv_check_alloc_flags(ldv_func_arg2);
#line 379
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 380
  return ((void *)0);
}
}
#line 415 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
void *ldv_kmem_cache_alloc_8(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 421
  ldv_check_alloc_flags(ldv_func_arg2);
#line 423
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 424
  return ((void *)0);
}
}
#line 458 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_drv.c.prepared"
struct page *ldv_alloc_page_vma_12(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 465
  ldv_check_alloc_flags(ldv_func_arg1);
#line 467
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 467
  return (tmp);
}
}
#line 1 "<compiler builtins>"
long __builtin_expect(long exp , long c ) ;
#line 47 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/string_64.h"
extern void *memset(void * , int  , size_t  ) ;
#line 51 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/pda.h"
extern void __bad_pda_field(void) ;
#line 57
extern struct x8664_pda _proxy_pda ;
#line 205 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/thread_info.h"
__inline static struct thread_info *current_thread_info(void) 
{ 
  struct thread_info *ti ;
  unsigned long ret__ ;

  {
#line 208
  switch (8UL) {
  case 2UL: 
#line 208
  __asm__  ("movw %%gs:%c1,%0": "=r" (ret__): "i" (16UL), "m" (_proxy_pda.kernelstack));
#line 208
  goto ldv_5114;
  case 4UL: 
#line 208
  __asm__  ("movl %%gs:%c1,%0": "=r" (ret__): "i" (16UL), "m" (_proxy_pda.kernelstack));
#line 208
  goto ldv_5114;
  case 8UL: 
#line 208
  __asm__  ("movq %%gs:%c1,%0": "=r" (ret__): "i" (16UL), "m" (_proxy_pda.kernelstack));
#line 208
  goto ldv_5114;
  default: 
#line 208
  __bad_pda_field();
  }
  ldv_5114: 
#line 208
  ti = (struct thread_info *)(ret__ - 8152UL);
#line 209
  return (ti);
}
}
#line 94 "include/linux/spinlock.h"
extern void __spin_lock_init(spinlock_t * , char const   * , struct lock_class_key * ) ;
#line 125 "include/linux/mutex.h"
extern void mutex_lock_nested(struct mutex * , unsigned int  ) ;
#line 149
extern void mutex_unlock(struct mutex * ) ;
#line 47 "include/linux/delay.h"
extern unsigned long msleep_interruptible(unsigned int  ) ;
#line 227 "include/linux/gfp.h"
struct page *ldv_alloc_page_vma_28(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) ;
#line 239
unsigned long ldv___get_free_pages_18(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 129 "include/linux/slab.h"
extern void kfree(void const   * ) ;
#line 207 "include/linux/slub_def.h"
void *ldv_kmem_cache_alloc_20(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_24(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 213
extern void *__kmalloc(size_t  , gfp_t  ) ;
#line 220 "include/linux/slub_def.h"
__inline static void *ldv_kmalloc_19(size_t size , gfp_t flags ) 
{ 
  void *tmp___2 ;

  {
#line 235
  tmp___2 = __kmalloc(size, flags);
#line 235
  return (tmp___2);
}
}
#line 220
__inline static void *kmalloc(size_t size , gfp_t flags ) ;
#line 20 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/io.h"
__inline static unsigned int readl(void const volatile   *addr ) 
{ 
  unsigned int ret ;

  {
#line 20
  __asm__  volatile   ("movl %1,%0": "=r" (ret): "m" (*((unsigned int volatile   *)addr)): "memory");
#line 20
  return (ret);
}
}
#line 28 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/io.h"
__inline static void writel(unsigned int val , void volatile   *addr ) 
{ 


  {
#line 28
  __asm__  volatile   ("movl %0,%1": : "r" (val), "m" (*((unsigned int volatile   *)addr)): "memory");
#line 29
  return;
}
}
#line 173 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/io_64.h"
extern void *ioremap_nocache(resource_size_t  , unsigned long  ) ;
#line 181 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/io_64.h"
__inline static void *ioremap(resource_size_t offset , unsigned long size ) 
{ 
  void *tmp ;

  {
#line 183
  tmp = ioremap_nocache(offset, size);
#line 183
  return (tmp);
}
}
#line 186
extern void iounmap(void volatile   * ) ;
#line 778 "include/linux/pci.h"
extern int pci_enable_msi(struct pci_dev * ) ;
#line 780
extern void pci_disable_msi(struct pci_dev * ) ;
#line 19 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/uaccess_64.h"
extern unsigned long copy_user_generic(void * , void const   * , unsigned int  ) ;
#line 22
extern unsigned long copy_to_user(void * , void const   * , unsigned int  ) ;
#line 29 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/uaccess_64.h"
__inline static int __copy_from_user(void *dst , void const   *src , unsigned int size ) 
{ 
  int ret ;
  unsigned long tmp ;
  long tmp___0 ;
  long tmp___1 ;
  unsigned long tmp___2 ;

  {
#line 31
  ret = 0;
#line 33
  tmp = copy_user_generic(dst, src, size);
#line 33
  return ((int )tmp);
#line 34
  switch (size) {
  case 1U: 
#line 35
  __asm__  volatile   ("1:\tmovb %2,%b1\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\txorb %b1,%b1\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (ret),
                       "=q" (*((u8 *)dst)): "m" (*((struct __large_struct *)src)),
                       "i" (1), "0" (ret));
#line 37
  return (ret);
  case 2U: 
#line 38
  __asm__  volatile   ("1:\tmovw %2,%w1\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\txorw %w1,%w1\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (ret),
                       "=r" (*((u16 *)dst)): "m" (*((struct __large_struct *)src)),
                       "i" (2), "0" (ret));
#line 40
  return (ret);
  case 4U: 
#line 41
  __asm__  volatile   ("1:\tmovl %2,%k1\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\txorl %k1,%k1\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (ret),
                       "=r" (*((u32 *)dst)): "m" (*((struct __large_struct *)src)),
                       "i" (4), "0" (ret));
#line 43
  return (ret);
  case 8U: 
#line 44
  __asm__  volatile   ("1:\tmovq %2,%1\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\txorq %1,%1\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (ret),
                       "=r" (*((u64 *)dst)): "m" (*((struct __large_struct *)src)),
                       "i" (8), "0" (ret));
#line 46
  return (ret);
  case 10U: 
#line 48
  __asm__  volatile   ("1:\tmovq %2,%1\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\txorq %1,%1\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (ret),
                       "=r" (*((u64 *)dst)): "m" (*((struct __large_struct *)src)),
                       "i" (10), "0" (ret));
#line 50
  tmp___0 = __builtin_expect(ret != 0, 0L);
#line 50
  if (tmp___0 != 0L) {
#line 51
    return (ret);
  } else {

  }
#line 52
  __asm__  volatile   ("1:\tmovw %2,%w1\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\txorw %w1,%w1\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (ret),
                       "=r" (*((u16 *)dst + 8U)): "m" (*((struct __large_struct *)src + 8U)),
                       "i" (2), "0" (ret));
#line 55
  return (ret);
  case 16U: 
#line 57
  __asm__  volatile   ("1:\tmovq %2,%1\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\txorq %1,%1\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (ret),
                       "=r" (*((u64 *)dst)): "m" (*((struct __large_struct *)src)),
                       "i" (16), "0" (ret));
#line 59
  tmp___1 = __builtin_expect(ret != 0, 0L);
#line 59
  if (tmp___1 != 0L) {
#line 60
    return (ret);
  } else {

  }
#line 61
  __asm__  volatile   ("1:\tmovq %2,%1\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\txorq %1,%1\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (ret),
                       "=r" (*((u64 *)dst + 8U)): "m" (*((struct __large_struct *)src + 8U)),
                       "i" (8), "0" (ret));
#line 64
  return (ret);
  default: 
#line 66
  tmp___2 = copy_user_generic(dst, src, size);
#line 66
  return ((int )tmp___2);
  }
}
}
#line 1124 "include/drm/drmP.h"
extern unsigned long drm_get_resource_start(struct drm_device * , unsigned int  ) ;
#line 1126
extern unsigned long drm_get_resource_len(struct drm_device * , unsigned int  ) ;
#line 1141
extern int drm_irq_uninstall(struct drm_device * ) ;
#line 1146
extern int drm_vblank_init(struct drm_device * , int  ) ;
#line 1196
extern unsigned int drm_debug ;
#line 1203
extern drm_local_map_t *drm_getsarea(struct drm_device * ) ;
#line 1224
extern drm_dma_handle_t *drm_pci_alloc(struct drm_device * , size_t  , size_t  , dma_addr_t  ) ;
#line 1227
extern void drm_pci_free(struct drm_device * , drm_dma_handle_t * ) ;
#line 1312
extern void drm_core_ioremap(struct drm_map * , struct drm_device * ) ;
#line 1314
extern void drm_core_ioremapfree(struct drm_map * , struct drm_device * ) ;
#line 1350 "include/drm/drmP.h"
__inline static void *drm_alloc(size_t size , int area ) 
{ 
  void *tmp ;

  {
#line 1352
  tmp = kmalloc(size, 208U);
#line 1352
  return (tmp);
}
}
#line 1356 "include/drm/drmP.h"
__inline static void drm_free(void *pt , size_t size , int area ) 
{ 


  {
#line 1358
  kfree((void const   *)pt);
#line 1359
  return;
}
}
#line 419 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
void i915_kernel_lost_context(struct drm_device *dev ) ;
#line 431
int i915_emit_box(struct drm_device *dev , struct drm_clip_rect *boxes , int i , int DR1 ,
                  int DR4 ) ;
#line 436
int i915_irq_emit(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 438
int i915_irq_wait(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 447
int i915_vblank_pipe_set(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 449
int i915_vblank_pipe_get(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 454
int i915_vblank_swap(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 466
int i915_mem_alloc(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 468
int i915_mem_free(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 470
int i915_mem_init_heap(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 472
int i915_mem_destroy_heap(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 474
void i915_mem_takedown(struct mem_block **heap ) ;
#line 475
void i915_mem_release(struct drm_device *dev , struct drm_file *file_priv , struct mem_block *heap ) ;
#line 478
int i915_gem_init_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 480
int i915_gem_create_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 482
int i915_gem_pread_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 484
int i915_gem_pwrite_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 486
int i915_gem_mmap_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 488
int i915_gem_set_domain_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 490
int i915_gem_sw_finish_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 492
int i915_gem_execbuffer(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 494
int i915_gem_pin_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 496
int i915_gem_unpin_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 498
int i915_gem_busy_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 500
int i915_gem_throttle_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 502
int i915_gem_entervt_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 504
int i915_gem_leavevt_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 506
int i915_gem_set_tiling(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 508
int i915_gem_get_tiling(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 510
int i915_gem_get_aperture_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) ;
#line 512
void i915_gem_load(struct drm_device *dev ) ;
#line 519
void i915_gem_lastclose(struct drm_device *dev ) ;
#line 631
int i915_wait_ring(struct drm_device *dev , int n , char const   *caller ) ;
#line 53 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
int i915_wait_ring(struct drm_device *dev , int n , char const   *caller ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_ring_buffer_t *ring ;
  u32 acthd_reg ;
  u32 last_acthd ;
  unsigned int tmp ;
  u32 acthd ;
  u32 last_head ;
  unsigned int tmp___0 ;
  int i ;
  unsigned int tmp___1 ;

  {
#line 55
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 56
  ring = & dev_priv->ring;
#line 57
  acthd_reg = ((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810 ? 8308U : 8392U;
#line 58
  tmp = readl((void const volatile   *)dev_priv->regs + (unsigned long )acthd_reg);
#line 58
  last_acthd = tmp;
#line 60
  tmp___0 = readl((void const volatile   *)dev_priv->regs + 8244U);
#line 60
  last_head = tmp___0 & 2097148U;
#line 63
  i = 0;
#line 63
  goto ldv_23804;
  ldv_23803: 
#line 64
  tmp___1 = readl((void const volatile   *)dev_priv->regs + 8244U);
#line 64
  ring->head = (int )tmp___1 & 2097148;
#line 65
  acthd = readl((void const volatile   *)dev_priv->regs + (unsigned long )acthd_reg);
#line 66
  ring->space = ring->head + (-8 - ring->tail);
#line 67
  if (ring->space < 0) {
#line 68
    ring->space = (int )((unsigned int )ring->space + (unsigned int )ring->Size);
  } else {

  }
#line 69
  if (ring->space >= n) {
#line 70
    return (0);
  } else {

  }
#line 72
  if ((unsigned long )dev_priv->sarea_priv != (unsigned long )((drm_i915_sarea_t *)0)) {
#line 73
    (dev_priv->sarea_priv)->perf_boxes = (dev_priv->sarea_priv)->perf_boxes | 4;
  } else {

  }
#line 75
  if ((u32 )ring->head != last_head) {
#line 76
    i = 0;
  } else {

  }
#line 77
  if (acthd != last_acthd) {
#line 78
    i = 0;
  } else {

  }
#line 80
  last_head = (u32 )ring->head;
#line 81
  last_acthd = acthd;
#line 82
  msleep_interruptible(10U);
#line 63
  i = i + 1;
  ldv_23804: ;
#line 63
  if (i <= 99999) {
#line 64
    goto ldv_23803;
  } else {

  }

#line 86
  return (-16);
}
}
#line 93 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_init_phys_hws(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 95
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 97
  dev_priv->status_page_dmah = drm_pci_alloc(dev, 4096UL, 4096UL, 4294967295ULL);
#line 100
  if ((unsigned long )dev_priv->status_page_dmah == (unsigned long )((drm_dma_handle_t *)0)) {
#line 101
    printk("<3>[drm:%s] *ERROR* Can not allocate hardware status page\n", "i915_init_phys_hws");
#line 102
    return (-12);
  } else {

  }
#line 104
  dev_priv->hw_status_page = (dev_priv->status_page_dmah)->vaddr;
#line 105
  dev_priv->dma_status_page = (dev_priv->status_page_dmah)->busaddr;
#line 107
  memset(dev_priv->hw_status_page, 0, 4096UL);
#line 109
  writel((unsigned int )dev_priv->dma_status_page, (void volatile   *)dev_priv->regs + 8320U);
#line 110
  if (drm_debug != 0U) {
#line 110
    printk("<7>[drm:%s] Enabled hardware status page\n", "i915_init_phys_hws");
  } else {

  }
#line 111
  return (0);
}
}
#line 118 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static void i915_free_hws(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 120
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 121
  if ((unsigned long )dev_priv->status_page_dmah != (unsigned long )((drm_dma_handle_t *)0)) {
#line 122
    drm_pci_free(dev, dev_priv->status_page_dmah);
#line 123
    dev_priv->status_page_dmah = 0;
  } else {

  }
#line 126
  if (dev_priv->status_gfx_addr != 0U) {
#line 127
    dev_priv->status_gfx_addr = 0U;
#line 128
    drm_core_ioremapfree(& dev_priv->hws_map, dev);
  } else {

  }
#line 132
  writel(536866816U, (void volatile   *)dev_priv->regs + 8320U);
#line 133
  return;
}
}
#line 135 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
void i915_kernel_lost_context(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_ring_buffer_t *ring ;
  unsigned int tmp ;
  unsigned int tmp___0 ;

  {
#line 137
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 138
  ring = & dev_priv->ring;
#line 140
  tmp = readl((void const volatile   *)dev_priv->regs + 8244U);
#line 140
  ring->head = (int )tmp & 2097148;
#line 141
  tmp___0 = readl((void const volatile   *)dev_priv->regs + 8240U);
#line 141
  ring->tail = (int )tmp___0 & 2097144;
#line 142
  ring->space = ring->head + (-8 - ring->tail);
#line 143
  if (ring->space < 0) {
#line 144
    ring->space = (int )((unsigned int )ring->space + (unsigned int )ring->Size);
  } else {

  }
#line 146
  if (ring->head == ring->tail && (unsigned long )dev_priv->sarea_priv != (unsigned long )((drm_i915_sarea_t *)0)) {
#line 147
    (dev_priv->sarea_priv)->perf_boxes = (dev_priv->sarea_priv)->perf_boxes | 1;
  } else {

  }
#line 148
  return;
}
}
#line 150 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_dma_cleanup(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 152
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 157
  if (dev->irq_enabled != 0) {
#line 158
    drm_irq_uninstall(dev);
  } else {

  }
#line 160
  if ((unsigned long )dev_priv->ring.virtual_start != (unsigned long )((u8 *)0)) {
#line 161
    drm_core_ioremapfree(& dev_priv->ring.map, dev);
#line 162
    dev_priv->ring.virtual_start = 0;
#line 163
    dev_priv->ring.map.handle = 0;
#line 164
    dev_priv->ring.map.size = 0UL;
  } else {

  }
#line 168
  if ((((dev->pci_device == 10690 || dev->pci_device == 10674) || dev->pci_device == 10706) || dev->pci_device == 10818) || ((dev->pci_device == 11778 || dev->pci_device == 11794) || dev->pci_device == 11810)) {
#line 169
    i915_free_hws(dev);
  } else {

  }
#line 171
  dev_priv->sarea = 0;
#line 172
  dev_priv->sarea_priv = 0;
#line 174
  return (0);
}
}
#line 177 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_initialize(struct drm_device *dev , drm_i915_init_t *init ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 179
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 181
  dev_priv->sarea = drm_getsarea(dev);
#line 182
  if ((unsigned long )dev_priv->sarea == (unsigned long )((drm_local_map_t *)0)) {
#line 183
    printk("<3>[drm:%s] *ERROR* can not find sarea!\n", "i915_initialize");
#line 184
    i915_dma_cleanup(dev);
#line 185
    return (-22);
  } else {

  }
#line 188
  dev_priv->sarea_priv = (drm_i915_sarea_t *)(dev_priv->sarea)->handle + (unsigned long )init->sarea_priv_offset;
#line 191
  if (init->ring_size != 0U) {
#line 192
    if ((unsigned long )dev_priv->ring.ring_obj != (unsigned long )((struct drm_gem_object *)0)) {
#line 193
      i915_dma_cleanup(dev);
#line 194
      printk("<3>[drm:%s] *ERROR* Client tried to initialize ringbuffer in GEM mode\n",
             "i915_initialize");
#line 196
      return (-22);
    } else {

    }
#line 199
    dev_priv->ring.Size = (unsigned long )init->ring_size;
#line 200
    dev_priv->ring.tail_mask = (int )((unsigned int )dev_priv->ring.Size - 1U);
#line 202
    dev_priv->ring.map.offset = (unsigned long )init->ring_start;
#line 203
    dev_priv->ring.map.size = (unsigned long )init->ring_size;
#line 204
    dev_priv->ring.map.type = _DRM_FRAME_BUFFER;
#line 205
    dev_priv->ring.map.flags = 0;
#line 206
    dev_priv->ring.map.mtrr = 0;
#line 208
    drm_core_ioremap(& dev_priv->ring.map, dev);
#line 210
    if ((unsigned long )dev_priv->ring.map.handle == (unsigned long )((void *)0)) {
#line 211
      i915_dma_cleanup(dev);
#line 212
      printk("<3>[drm:%s] *ERROR* can not ioremap virtual address for ring buffer\n",
             "i915_initialize");
#line 214
      return (-12);
    } else {

    }
  } else {

  }
#line 218
  dev_priv->ring.virtual_start = (u8 *)dev_priv->ring.map.handle;
#line 220
  dev_priv->cpp = init->cpp;
#line 221
  dev_priv->back_offset = (int )init->back_offset;
#line 222
  dev_priv->front_offset = (int )init->front_offset;
#line 223
  dev_priv->current_page = 0;
#line 224
  (dev_priv->sarea_priv)->pf_current_page = dev_priv->current_page;
#line 228
  dev_priv->allow_batchbuffer = 1;
#line 230
  return (0);
}
}
#line 233 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_dma_resume(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 235
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 237
  if (drm_debug != 0U) {
#line 237
    printk("<7>[drm:%s] %s\n", "i915_dma_resume", "i915_dma_resume");
  } else {

  }
#line 239
  if ((unsigned long )dev_priv->sarea == (unsigned long )((drm_local_map_t *)0)) {
#line 240
    printk("<3>[drm:%s] *ERROR* can not find sarea!\n", "i915_dma_resume");
#line 241
    return (-22);
  } else {

  }
#line 244
  if ((unsigned long )dev_priv->ring.map.handle == (unsigned long )((void *)0)) {
#line 245
    printk("<3>[drm:%s] *ERROR* can not ioremap virtual address for ring buffer\n",
           "i915_dma_resume");
#line 247
    return (-12);
  } else {

  }
#line 251
  if ((unsigned long )dev_priv->hw_status_page == (unsigned long )((void *)0)) {
#line 252
    printk("<3>[drm:%s] *ERROR* Can not find hardware status page\n", "i915_dma_resume");
#line 253
    return (-22);
  } else {

  }
#line 255
  if (drm_debug != 0U) {
#line 255
    printk("<7>[drm:%s] hw status page @ %p\n", "i915_dma_resume", dev_priv->hw_status_page);
  } else {

  }
#line 257
  if (dev_priv->status_gfx_addr != 0U) {
#line 258
    writel(dev_priv->status_gfx_addr, (void volatile   *)dev_priv->regs + 8320U);
  } else {
#line 260
    writel((unsigned int )dev_priv->dma_status_page, (void volatile   *)dev_priv->regs + 8320U);
  }
#line 261
  if (drm_debug != 0U) {
#line 261
    printk("<7>[drm:%s] Enabled hardware status page\n", "i915_dma_resume");
  } else {

  }
#line 263
  return (0);
}
}
#line 266 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_dma_init(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_init_t *init ;
  int retcode ;

  {
#line 269
  init = (drm_i915_init_t *)data;
#line 270
  retcode = 0;
#line 272
  switch ((unsigned int )init->func) {
  case 1U: 
#line 274
  retcode = i915_initialize(dev, init);
#line 275
  goto ldv_23843;
  case 2U: 
#line 277
  retcode = i915_dma_cleanup(dev);
#line 278
  goto ldv_23843;
  case 3U: 
#line 280
  retcode = i915_dma_resume(dev);
#line 281
  goto ldv_23843;
  default: 
#line 283
  retcode = -22;
#line 284
  goto ldv_23843;
  }
  ldv_23843: ;
#line 287
  return (retcode);
}
}
#line 299 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int do_validate_cmd(int cmd ) 
{ 


  {
#line 301
  switch ((int )((unsigned int )cmd >> 29)) {
  case 0: ;
#line 303
  switch ((cmd >> 23) & 63) {
  case 0: ;
#line 305
  return (1);
  case 4: ;
#line 307
  return (1);
  default: ;
#line 309
  return (0);
  }
#line 311
  goto ldv_23854;
  case 1: ;
#line 313
  return (0);
  case 2: ;
#line 315
  return ((cmd & 255) + 2);
  case 3: ;
#line 317
  if (((cmd >> 24) & 31) <= 24) {
#line 318
    return (1);
  } else {

  }
#line 320
  switch ((cmd >> 24) & 31) {
  case 28: ;
#line 322
  return (1);
  case 29: ;
#line 324
  switch ((cmd >> 16) & 255) {
  case 3: ;
#line 326
  return ((cmd & 31) + 2);
  case 4: ;
#line 328
  return ((cmd & 15) + 2);
  default: ;
#line 330
  return ((cmd & 65535) + 2);
  }
  case 30: ;
#line 333
  if ((cmd & 8388608) != 0) {
#line 334
    return ((cmd & 65535) + 1);
  } else {
#line 336
    return (1);
  }
  case 31: ;
#line 338
  if ((cmd & 8388608) == 0) {
#line 339
    return ((cmd & 131071) + 2);
  } else
#line 340
  if ((cmd & 131072) != 0) {
#line 341
    if ((cmd & 65535) == 0) {
#line 342
      return (0);
    } else {
#line 344
      return (((cmd & 65535) + 1) / 2 + 1);
    }
  } else {
#line 346
    return (2);
  }
  default: ;
#line 348
  return (0);
  }
  default: ;
#line 351
  return (0);
  }
  ldv_23854: ;
#line 354
  return (0);
}
}
#line 357 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int validate_cmd(int cmd ) 
{ 
  int ret ;
  int tmp ;

  {
#line 359
  tmp = do_validate_cmd(cmd);
#line 359
  ret = tmp;
#line 363
  return (ret);
}
}
#line 366 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_emit_cmds(struct drm_device *dev , int *buffer , int dwords ) 
{ 
  drm_i915_private_t *dev_priv ;
  int i ;
  unsigned int outring ;
  unsigned int ringmask ;
  unsigned int outcount ;
  char volatile   *virt ;
  int cmd ;
  int sz ;
  int tmp ;
  int tmp___0 ;

  {
#line 368
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 372
  if ((unsigned long )(dwords + 1) * 4UL >= dev_priv->ring.Size - 8UL) {
#line 373
    return (-22);
  } else {

  }
#line 375
  if (dev_priv->ring.space < ((dwords + 1) & -2) * 4) {
#line 375
    i915_wait_ring(dev, ((dwords + 1) & -2) * 4, "i915_emit_cmds");
  } else {

  }
#line 375
  outcount = 0U;
#line 375
  outring = (unsigned int )dev_priv->ring.tail;
#line 375
  ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 375
  virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 377
  i = 0;
#line 377
  goto ldv_23889;
  ldv_23888: 
#line 380
  tmp = __copy_from_user((void *)(& cmd), (void const   *)buffer + (unsigned long )i,
                         4U);
#line 380
  if (tmp != 0) {
#line 381
    return (-22);
  } else {

  }
#line 383
  sz = validate_cmd(cmd);
#line 383
  if (sz == 0 || i + sz > dwords) {
#line 384
    return (-22);
  } else {

  }
#line 386
  *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )cmd;
#line 386
  outcount = outcount + 1U;
#line 386
  outring = outring + 4U;
#line 386
  outring = outring & ringmask;
#line 388
  goto ldv_23886;
  ldv_23885: 
#line 389
  tmp___0 = __copy_from_user((void *)(& cmd), (void const   *)buffer + (unsigned long )i,
                             4U);
#line 389
  if (tmp___0 != 0) {
#line 391
    return (-22);
  } else {

  }
#line 393
  *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )cmd;
#line 393
  outcount = outcount + 1U;
#line 393
  outring = outring + 4U;
#line 393
  outring = outring & ringmask;
  ldv_23886: 
#line 388
  i = i + 1;
#line 388
  sz = sz - 1;
#line 388
  if (sz != 0) {
#line 389
    goto ldv_23885;
  } else {

  }

  ldv_23889: ;
#line 377
  if (i < dwords) {
#line 378
    goto ldv_23888;
  } else {

  }

#line 397
  if (dwords & 1) {
#line 398
    *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 398
    outcount = outcount + 1U;
#line 398
    outring = outring + 4U;
#line 398
    outring = outring & ringmask;
  } else {

  }
#line 400
  dev_priv->ring.tail = (int )outring;
#line 400
  dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 400
  writel(outring, (void volatile   *)dev_priv->regs + 8240U);
#line 402
  return (0);
}
}
#line 406 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
int i915_emit_box(struct drm_device *dev , struct drm_clip_rect *boxes , int i , int DR1 ,
                  int DR4 ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_clip_rect box ;
  unsigned int outring ;
  unsigned int ringmask ;
  unsigned int outcount ;
  char volatile   *virt ;
  int tmp ;

  {
#line 410
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 414
  tmp = __copy_from_user((void *)(& box), (void const   *)boxes + (unsigned long )i,
                         8U);
#line 414
  if (tmp != 0) {
#line 415
    return (-14);
  } else {

  }
#line 418
  if ((((int )box.y2 <= (int )box.y1 || (int )box.x2 <= (int )box.x1) || (unsigned int )box.y2 == 0U) || (unsigned int )box.x2 == 0U) {
#line 419
    printk("<3>[drm:%s] *ERROR* Bad box %d,%d..%d,%d\n", "i915_emit_box", (int )box.x1,
           (int )box.y1, (int )box.x2, (int )box.y2);
#line 421
    return (-22);
  } else {

  }
#line 424
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 425
    if (dev_priv->ring.space <= 15) {
#line 425
      i915_wait_ring(dev, 16, "i915_emit_box");
    } else {

    }
#line 425
    outcount = 0U;
#line 425
    outring = (unsigned int )dev_priv->ring.tail;
#line 425
    ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 425
    virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 426
    *((unsigned int volatile   *)virt + (unsigned long )outring) = 2030043138U;
#line 426
    outcount = outcount + 1U;
#line 426
    outring = outring + 4U;
#line 426
    outring = outring & ringmask;
#line 427
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )((int )box.x1 | ((int )box.y1 << 16));
#line 427
    outcount = outcount + 1U;
#line 427
    outring = outring + 4U;
#line 427
    outring = outring & ringmask;
#line 428
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )((((int )box.x2 + -1) & 65535) | (((int )box.y2 + -1) << 16));
#line 428
    outcount = outcount + 1U;
#line 428
    outring = outring + 4U;
#line 428
    outring = outring & ringmask;
#line 429
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )DR4;
#line 429
    outcount = outcount + 1U;
#line 429
    outring = outring + 4U;
#line 429
    outring = outring & ringmask;
#line 430
    dev_priv->ring.tail = (int )outring;
#line 430
    dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 430
    writel(outring, (void volatile   *)dev_priv->regs + 8240U);
  } else {
#line 432
    if (dev_priv->ring.space <= 23) {
#line 432
      i915_wait_ring(dev, 24, "i915_emit_box");
    } else {

    }
#line 432
    outcount = 0U;
#line 432
    outring = (unsigned int )dev_priv->ring.tail;
#line 432
    ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 432
    virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 433
    *((unsigned int volatile   *)virt + (unsigned long )outring) = 2105540611U;
#line 433
    outcount = outcount + 1U;
#line 433
    outring = outring + 4U;
#line 433
    outring = outring & ringmask;
#line 434
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )DR1;
#line 434
    outcount = outcount + 1U;
#line 434
    outring = outring + 4U;
#line 434
    outring = outring & ringmask;
#line 435
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )((int )box.x1 | ((int )box.y1 << 16));
#line 435
    outcount = outcount + 1U;
#line 435
    outring = outring + 4U;
#line 435
    outring = outring & ringmask;
#line 436
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )((((int )box.x2 + -1) & 65535) | (((int )box.y2 + -1) << 16));
#line 436
    outcount = outcount + 1U;
#line 436
    outring = outring + 4U;
#line 436
    outring = outring & ringmask;
#line 437
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )DR4;
#line 437
    outcount = outcount + 1U;
#line 437
    outring = outring + 4U;
#line 437
    outring = outring & ringmask;
#line 438
    *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 438
    outcount = outcount + 1U;
#line 438
    outring = outring + 4U;
#line 438
    outring = outring & ringmask;
#line 439
    dev_priv->ring.tail = (int )outring;
#line 439
    dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 439
    writel(outring, (void volatile   *)dev_priv->regs + 8240U);
  }
#line 442
  return (0);
}
}
#line 449 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static void i915_emit_breadcrumb(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  unsigned int outring ;
  unsigned int ringmask ;
  unsigned int outcount ;
  char volatile   *virt ;

  {
#line 451
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 454
  dev_priv->counter = dev_priv->counter + (uint32_t )1;
#line 455
  if ((int )dev_priv->counter < 0) {
#line 456
    dev_priv->counter = 0U;
  } else {

  }
#line 457
  if ((unsigned long )dev_priv->sarea_priv != (unsigned long )((drm_i915_sarea_t *)0)) {
#line 458
    (dev_priv->sarea_priv)->last_enqueue = (int )dev_priv->counter;
  } else {

  }
#line 460
  if (dev_priv->ring.space <= 15) {
#line 460
    i915_wait_ring(dev, 16, "i915_emit_breadcrumb");
  } else {

  }
#line 460
  outcount = 0U;
#line 460
  outring = (unsigned int )dev_priv->ring.tail;
#line 460
  ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 460
  virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 461
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 276824065U;
#line 461
  outcount = outcount + 1U;
#line 461
  outring = outring + 4U;
#line 461
  outring = outring & ringmask;
#line 462
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 132U;
#line 462
  outcount = outcount + 1U;
#line 462
  outring = outring + 4U;
#line 462
  outring = outring & ringmask;
#line 463
  *((unsigned int volatile   *)virt + (unsigned long )outring) = dev_priv->counter;
#line 463
  outcount = outcount + 1U;
#line 463
  outring = outring + 4U;
#line 463
  outring = outring & ringmask;
#line 464
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 464
  outcount = outcount + 1U;
#line 464
  outring = outring + 4U;
#line 464
  outring = outring & ringmask;
#line 465
  dev_priv->ring.tail = (int )outring;
#line 465
  dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 465
  writel(outring, (void volatile   *)dev_priv->regs + 8240U);
#line 466
  return;
}
}
#line 468 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_dispatch_cmdbuffer(struct drm_device *dev , drm_i915_cmdbuffer_t *cmd ) 
{ 
  int nbox ;
  int i ;
  int count ;
  int ret ;

  {
#line 471
  nbox = cmd->num_cliprects;
#line 472
  i = 0;
#line 474
  if ((cmd->sz & 3) != 0) {
#line 475
    printk("<3>[drm:%s] *ERROR* alignment", "i915_dispatch_cmdbuffer");
#line 476
    return (-22);
  } else {

  }
#line 479
  i915_kernel_lost_context(dev);
#line 481
  count = nbox != 0 ? nbox : 1;
#line 483
  i = 0;
#line 483
  goto ldv_23924;
  ldv_23923: ;
#line 484
  if (i < nbox) {
#line 485
    ret = i915_emit_box(dev, cmd->cliprects, i, cmd->DR1, cmd->DR4);
#line 487
    if (ret != 0) {
#line 488
      return (ret);
    } else {

    }
  } else {

  }
#line 491
  ret = i915_emit_cmds(dev, (int *)cmd->buf, cmd->sz / 4);
#line 492
  if (ret != 0) {
#line 493
    return (ret);
  } else {

  }
#line 483
  i = i + 1;
  ldv_23924: ;
#line 483
  if (i < count) {
#line 484
    goto ldv_23923;
  } else {

  }
#line 496
  i915_emit_breadcrumb(dev);
#line 497
  return (0);
}
}
#line 500 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_dispatch_batchbuffer(struct drm_device *dev , drm_i915_batchbuffer_t *batch ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_clip_rect *boxes ;
  int nbox ;
  int i ;
  int count ;
  unsigned int outring ;
  unsigned int ringmask ;
  unsigned int outcount ;
  char volatile   *virt ;
  int ret ;
  int tmp ;

  {
#line 503
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 504
  boxes = batch->cliprects;
#line 505
  nbox = batch->num_cliprects;
#line 506
  i = 0;
#line 509
  if (((batch->start | batch->used) & 7) != 0) {
#line 510
    printk("<3>[drm:%s] *ERROR* alignment", "i915_dispatch_batchbuffer");
#line 511
    return (-22);
  } else {

  }
#line 514
  i915_kernel_lost_context(dev);
#line 516
  count = nbox != 0 ? nbox : 1;
#line 518
  i = 0;
#line 518
  goto ldv_23942;
  ldv_23941: ;
#line 519
  if (i < nbox) {
#line 520
    tmp = i915_emit_box(dev, boxes, i, batch->DR1, batch->DR4);
#line 520
    ret = tmp;
#line 522
    if (ret != 0) {
#line 523
      return (ret);
    } else {

    }
  } else {

  }
#line 526
  if (dev->pci_device != 13687 && dev->pci_device != 9570) {
#line 527
    if (dev_priv->ring.space <= 7) {
#line 527
      i915_wait_ring(dev, 8, "i915_dispatch_batchbuffer");
    } else {

    }
#line 527
    outcount = 0U;
#line 527
    outring = (unsigned int )dev_priv->ring.tail;
#line 527
    ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 527
    virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 528
    if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 529
      *((unsigned int volatile   *)virt + (unsigned long )outring) = 411042176U;
#line 529
      outcount = outcount + 1U;
#line 529
      outring = outring + 4U;
#line 529
      outring = outring & ringmask;
#line 530
      *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )batch->start;
#line 530
      outcount = outcount + 1U;
#line 530
      outring = outring + 4U;
#line 530
      outring = outring & ringmask;
    } else {
#line 532
      *((unsigned int volatile   *)virt + (unsigned long )outring) = 411041920U;
#line 532
      outcount = outcount + 1U;
#line 532
      outring = outring + 4U;
#line 532
      outring = outring & ringmask;
#line 533
      *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )(batch->start | 1);
#line 533
      outcount = outcount + 1U;
#line 533
      outring = outring + 4U;
#line 533
      outring = outring & ringmask;
    }
#line 535
    dev_priv->ring.tail = (int )outring;
#line 535
    dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 535
    writel(outring, (void volatile   *)dev_priv->regs + 8240U);
  } else {
#line 537
    if (dev_priv->ring.space <= 15) {
#line 537
      i915_wait_ring(dev, 16, "i915_dispatch_batchbuffer");
    } else {

    }
#line 537
    outcount = 0U;
#line 537
    outring = (unsigned int )dev_priv->ring.tail;
#line 537
    ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 537
    virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 538
    *((unsigned int volatile   *)virt + (unsigned long )outring) = 402653185U;
#line 538
    outcount = outcount + 1U;
#line 538
    outring = outring + 4U;
#line 538
    outring = outring & ringmask;
#line 539
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )(batch->start | 1);
#line 539
    outcount = outcount + 1U;
#line 539
    outring = outring + 4U;
#line 539
    outring = outring & ringmask;
#line 540
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )((batch->start + batch->used) + -4);
#line 540
    outcount = outcount + 1U;
#line 540
    outring = outring + 4U;
#line 540
    outring = outring & ringmask;
#line 541
    *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 541
    outcount = outcount + 1U;
#line 541
    outring = outring + 4U;
#line 541
    outring = outring & ringmask;
#line 542
    dev_priv->ring.tail = (int )outring;
#line 542
    dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 542
    writel(outring, (void volatile   *)dev_priv->regs + 8240U);
  }
#line 518
  i = i + 1;
  ldv_23942: ;
#line 518
  if (i < count) {
#line 519
    goto ldv_23941;
  } else {

  }
#line 546
  i915_emit_breadcrumb(dev);
#line 548
  return (0);
}
}
#line 551 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_dispatch_flip(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  unsigned int outring ;
  unsigned int ringmask ;
  unsigned int outcount ;
  char volatile   *virt ;
  uint32_t tmp ;

  {
#line 553
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 556
  if ((unsigned long )dev_priv->sarea_priv == (unsigned long )((drm_i915_sarea_t *)0)) {
#line 557
    return (-22);
  } else {

  }
#line 559
  if (drm_debug != 0U) {
#line 559
    printk("<7>[drm:%s] %s: page=%d pfCurrentPage=%d\n", "i915_dispatch_flip", "i915_dispatch_flip",
           dev_priv->current_page, (dev_priv->sarea_priv)->pf_current_page);
  } else {

  }
#line 564
  i915_kernel_lost_context(dev);
#line 566
  if (dev_priv->ring.space <= 7) {
#line 566
    i915_wait_ring(dev, 8, "i915_dispatch_flip");
  } else {

  }
#line 566
  outcount = 0U;
#line 566
  outring = (unsigned int )dev_priv->ring.tail;
#line 566
  ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 566
  virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 567
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 33554433U;
#line 567
  outcount = outcount + 1U;
#line 567
  outring = outring + 4U;
#line 567
  outring = outring & ringmask;
#line 568
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 568
  outcount = outcount + 1U;
#line 568
  outring = outring + 4U;
#line 568
  outring = outring & ringmask;
#line 569
  dev_priv->ring.tail = (int )outring;
#line 569
  dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 569
  writel(outring, (void volatile   *)dev_priv->regs + 8240U);
#line 571
  if (dev_priv->ring.space <= 23) {
#line 571
    i915_wait_ring(dev, 24, "i915_dispatch_flip");
  } else {

  }
#line 571
  outcount = 0U;
#line 571
  outring = (unsigned int )dev_priv->ring.tail;
#line 571
  ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 571
  virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 572
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 171966466U;
#line 572
  outcount = outcount + 1U;
#line 572
  outring = outring + 4U;
#line 572
  outring = outring & ringmask;
#line 573
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 573
  outcount = outcount + 1U;
#line 573
  outring = outring + 4U;
#line 573
  outring = outring & ringmask;
#line 574
  if (dev_priv->current_page == 0) {
#line 575
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )dev_priv->back_offset;
#line 575
    outcount = outcount + 1U;
#line 575
    outring = outring + 4U;
#line 575
    outring = outring & ringmask;
#line 576
    dev_priv->current_page = 1;
  } else {
#line 578
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (unsigned int volatile   )dev_priv->front_offset;
#line 578
    outcount = outcount + 1U;
#line 578
    outring = outring + 4U;
#line 578
    outring = outring & ringmask;
#line 579
    dev_priv->current_page = 0;
  }
#line 581
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 581
  outcount = outcount + 1U;
#line 581
  outring = outring + 4U;
#line 581
  outring = outring & ringmask;
#line 582
  dev_priv->ring.tail = (int )outring;
#line 582
  dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 582
  writel(outring, (void volatile   *)dev_priv->regs + 8240U);
#line 584
  if (dev_priv->ring.space <= 7) {
#line 584
    i915_wait_ring(dev, 8, "i915_dispatch_flip");
  } else {

  }
#line 584
  outcount = 0U;
#line 584
  outring = (unsigned int )dev_priv->ring.tail;
#line 584
  ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 584
  virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 585
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 25165828U;
#line 585
  outcount = outcount + 1U;
#line 585
  outring = outring + 4U;
#line 585
  outring = outring & ringmask;
#line 586
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 586
  outcount = outcount + 1U;
#line 586
  outring = outring + 4U;
#line 586
  outring = outring & ringmask;
#line 587
  dev_priv->ring.tail = (int )outring;
#line 587
  dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 587
  writel(outring, (void volatile   *)dev_priv->regs + 8240U);
#line 589
  tmp = dev_priv->counter;
#line 589
  dev_priv->counter = dev_priv->counter + (uint32_t )1;
#line 589
  (dev_priv->sarea_priv)->last_enqueue = (int )tmp;
#line 591
  if (dev_priv->ring.space <= 15) {
#line 591
    i915_wait_ring(dev, 16, "i915_dispatch_flip");
  } else {

  }
#line 591
  outcount = 0U;
#line 591
  outring = (unsigned int )dev_priv->ring.tail;
#line 591
  ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 591
  virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 592
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 276824065U;
#line 592
  outcount = outcount + 1U;
#line 592
  outring = outring + 4U;
#line 592
  outring = outring & ringmask;
#line 593
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 132U;
#line 593
  outcount = outcount + 1U;
#line 593
  outring = outring + 4U;
#line 593
  outring = outring & ringmask;
#line 594
  *((unsigned int volatile   *)virt + (unsigned long )outring) = dev_priv->counter;
#line 594
  outcount = outcount + 1U;
#line 594
  outring = outring + 4U;
#line 594
  outring = outring & ringmask;
#line 595
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 595
  outcount = outcount + 1U;
#line 595
  outring = outring + 4U;
#line 595
  outring = outring & ringmask;
#line 596
  dev_priv->ring.tail = (int )outring;
#line 596
  dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 596
  writel(outring, (void volatile   *)dev_priv->regs + 8240U);
#line 598
  (dev_priv->sarea_priv)->pf_current_page = dev_priv->current_page;
#line 599
  return (0);
}
}
#line 602 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_quiescent(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  int tmp ;

  {
#line 604
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 606
  i915_kernel_lost_context(dev);
#line 607
  tmp = i915_wait_ring(dev, (int )((unsigned int )dev_priv->ring.Size - 8U), "i915_quiescent");
#line 607
  return (tmp);
}
}
#line 610 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_flush_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  int ret ;

  {
#line 615
  if ((unsigned long )((drm_i915_private_t *)dev->dev_private)->ring.ring_obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 615
    if ((int )(dev->lock.hw_lock)->lock >= 0 || (unsigned long )dev->lock.file_priv != (unsigned long )file_priv) {
#line 615
      printk("<3>[drm:%s] *ERROR* %s called without lock held, held  %d owner %p %p\n",
             "i915_flush_ioctl", "i915_flush_ioctl", (unsigned int )(dev->lock.hw_lock)->lock & 2147483648U,
             dev->lock.file_priv, file_priv);
#line 615
      return (-22);
    } else {

    }
  } else {

  }
#line 617
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 618
  ret = i915_quiescent(dev);
#line 619
  mutex_unlock(& dev->struct_mutex);
#line 621
  return (ret);
}
}
#line 624 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_batchbuffer(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_sarea_t *sarea_priv ;
  drm_i915_batchbuffer_t *batch ;
  int ret ;
  unsigned long flag ;
  unsigned long roksum ;
  struct thread_info *tmp ;
  long tmp___0 ;

  {
#line 627
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 628
  sarea_priv = dev_priv->sarea_priv;
#line 630
  batch = (drm_i915_batchbuffer_t *)data;
#line 633
  if (dev_priv->allow_batchbuffer == 0) {
#line 634
    printk("<3>[drm:%s] *ERROR* Batchbuffer ioctl disabled\n", "i915_batchbuffer");
#line 635
    return (-22);
  } else {

  }
#line 638
  if (drm_debug != 0U) {
#line 638
    printk("<7>[drm:%s] i915 batchbuffer, start %x used %d cliprects %d\n", "i915_batchbuffer",
           batch->start, batch->used, batch->num_cliprects);
  } else {

  }
#line 641
  if ((unsigned long )((drm_i915_private_t *)dev->dev_private)->ring.ring_obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 641
    if ((int )(dev->lock.hw_lock)->lock >= 0 || (unsigned long )dev->lock.file_priv != (unsigned long )file_priv) {
#line 641
      printk("<3>[drm:%s] *ERROR* %s called without lock held, held  %d owner %p %p\n",
             "i915_batchbuffer", "i915_batchbuffer", (unsigned int )(dev->lock.hw_lock)->lock & 2147483648U,
             dev->lock.file_priv, file_priv);
#line 641
      return (-22);
    } else {

    }
  } else {

  }
#line 643
  if (batch->num_cliprects != 0) {
#line 643
    tmp = current_thread_info();
#line 643
    __asm__  ("add %3,%1 ; sbb %0,%0 ; cmp %1,%4 ; sbb $0,%0": "=&r" (flag), "=r" (roksum): "1" (batch->cliprects),
              "g" ((long )((unsigned long )batch->num_cliprects * 8UL)), "rm" (tmp->addr_limit.seg));
#line 643
    tmp___0 = __builtin_expect(flag == 0UL, 1L);
#line 643
    if (tmp___0 == 0L) {
#line 646
      return (-14);
    } else {

    }
  } else {

  }
#line 648
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 649
  ret = i915_dispatch_batchbuffer(dev, batch);
#line 650
  mutex_unlock(& dev->struct_mutex);
#line 652
  if ((unsigned long )sarea_priv != (unsigned long )((drm_i915_sarea_t *)0)) {
#line 653
    sarea_priv->last_dispatch = (int )*((u32 volatile   *)dev_priv->hw_status_page + 33UL);
  } else {

  }
#line 654
  return (ret);
}
}
#line 657 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_cmdbuffer(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_sarea_t *sarea_priv ;
  drm_i915_cmdbuffer_t *cmdbuf ;
  int ret ;
  unsigned long flag ;
  unsigned long roksum ;
  struct thread_info *tmp ;
  long tmp___0 ;

  {
#line 660
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 661
  sarea_priv = dev_priv->sarea_priv;
#line 663
  cmdbuf = (drm_i915_cmdbuffer_t *)data;
#line 666
  if (drm_debug != 0U) {
#line 666
    printk("<7>[drm:%s] i915 cmdbuffer, buf %p sz %d cliprects %d\n", "i915_cmdbuffer",
           cmdbuf->buf, cmdbuf->sz, cmdbuf->num_cliprects);
  } else {

  }
#line 669
  if ((unsigned long )((drm_i915_private_t *)dev->dev_private)->ring.ring_obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 669
    if ((int )(dev->lock.hw_lock)->lock >= 0 || (unsigned long )dev->lock.file_priv != (unsigned long )file_priv) {
#line 669
      printk("<3>[drm:%s] *ERROR* %s called without lock held, held  %d owner %p %p\n",
             "i915_cmdbuffer", "i915_cmdbuffer", (unsigned int )(dev->lock.hw_lock)->lock & 2147483648U,
             dev->lock.file_priv, file_priv);
#line 669
      return (-22);
    } else {

    }
  } else {

  }
#line 672
  if (cmdbuf->num_cliprects != 0) {
#line 672
    tmp = current_thread_info();
#line 672
    __asm__  ("add %3,%1 ; sbb %0,%0 ; cmp %1,%4 ; sbb $0,%0": "=&r" (flag), "=r" (roksum): "1" (cmdbuf->cliprects),
              "g" ((long )((unsigned long )cmdbuf->num_cliprects * 8UL)), "rm" (tmp->addr_limit.seg));
#line 672
    tmp___0 = __builtin_expect(flag == 0UL, 1L);
#line 672
    if (tmp___0 == 0L) {
#line 675
      printk("<3>[drm:%s] *ERROR* Fault accessing cliprects\n", "i915_cmdbuffer");
#line 676
      return (-14);
    } else {

    }
  } else {

  }
#line 679
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 680
  ret = i915_dispatch_cmdbuffer(dev, cmdbuf);
#line 681
  mutex_unlock(& dev->struct_mutex);
#line 682
  if (ret != 0) {
#line 683
    printk("<3>[drm:%s] *ERROR* i915_dispatch_cmdbuffer failed\n", "i915_cmdbuffer");
#line 684
    return (ret);
  } else {

  }
#line 687
  if ((unsigned long )sarea_priv != (unsigned long )((drm_i915_sarea_t *)0)) {
#line 688
    sarea_priv->last_dispatch = (int )*((u32 volatile   *)dev_priv->hw_status_page + 33UL);
  } else {

  }
#line 689
  return (0);
}
}
#line 692 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_flip_bufs(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  int ret ;

  {
#line 697
  if (drm_debug != 0U) {
#line 697
    printk("<7>[drm:%s] %s\n", "i915_flip_bufs", "i915_flip_bufs");
  } else {

  }
#line 699
  if ((unsigned long )((drm_i915_private_t *)dev->dev_private)->ring.ring_obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 699
    if ((int )(dev->lock.hw_lock)->lock >= 0 || (unsigned long )dev->lock.file_priv != (unsigned long )file_priv) {
#line 699
      printk("<3>[drm:%s] *ERROR* %s called without lock held, held  %d owner %p %p\n",
             "i915_flip_bufs", "i915_flip_bufs", (unsigned int )(dev->lock.hw_lock)->lock & 2147483648U,
             dev->lock.file_priv, file_priv);
#line 699
      return (-22);
    } else {

    }
  } else {

  }
#line 701
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 702
  ret = i915_dispatch_flip(dev);
#line 703
  mutex_unlock(& dev->struct_mutex);
#line 705
  return (ret);
}
}
#line 708 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_getparam(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_getparam_t *param ;
  int value ;
  unsigned long tmp ;

  {
#line 711
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 712
  param = (drm_i915_getparam_t *)data;
#line 715
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 716
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_getparam");
#line 717
    return (-22);
  } else {

  }
#line 720
  switch (param->param) {
  case 1: 
#line 722
  value = (dev->pdev)->irq != 0U;
#line 723
  goto ldv_24008;
  case 2: 
#line 725
  value = dev_priv->allow_batchbuffer != 0;
#line 726
  goto ldv_24008;
  case 3: 
#line 728
  value = (int )*((u32 volatile   *)dev_priv->hw_status_page + 33UL);
#line 729
  goto ldv_24008;
  case 4: 
#line 731
  value = dev->pci_device;
#line 732
  goto ldv_24008;
  case 5: 
#line 734
  value = 1;
#line 735
  goto ldv_24008;
  default: 
#line 737
  printk("<3>[drm:%s] *ERROR* Unknown parameter %d\n", "i915_getparam", param->param);
#line 738
  return (-22);
  }
  ldv_24008: 
#line 741
  tmp = copy_to_user((void *)param->value, (void const   *)(& value), 4U);
#line 741
  if (tmp != 0UL) {
#line 742
    printk("<3>[drm:%s] *ERROR* DRM_COPY_TO_USER failed\n", "i915_getparam");
#line 743
    return (-14);
  } else {

  }
#line 746
  return (0);
}
}
#line 749 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_setparam(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_setparam_t *param ;

  {
#line 752
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 753
  param = (drm_i915_setparam_t *)data;
#line 755
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 756
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_setparam");
#line 757
    return (-22);
  } else {

  }
#line 760
  switch (param->param) {
  case 1: ;
#line 762
  goto ldv_24023;
  case 2: 
#line 764
  dev_priv->tex_lru_log_granularity = param->value;
#line 765
  goto ldv_24023;
  case 3: 
#line 767
  dev_priv->allow_batchbuffer = param->value;
#line 768
  goto ldv_24023;
  default: 
#line 770
  printk("<3>[drm:%s] *ERROR* unknown parameter %d\n", "i915_setparam", param->param);
#line 771
  return (-22);
  }
  ldv_24023: ;
#line 774
  return (0);
}
}
#line 777 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
static int i915_set_status_page(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_hws_addr_t *hws ;

  {
#line 780
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 781
  hws = (drm_i915_hws_addr_t *)data;
#line 783
  if ((((dev->pci_device != 10690 && dev->pci_device != 10674) && dev->pci_device != 10706) && dev->pci_device != 10818) && ((dev->pci_device != 11778 && dev->pci_device != 11794) && dev->pci_device != 11810)) {
#line 784
    return (-22);
  } else {

  }
#line 786
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 787
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_set_status_page");
#line 788
    return (-22);
  } else {

  }
#line 791
  printk("<7>set status page addr 0x%08x\n", (unsigned int )hws->addr);
#line 793
  dev_priv->status_gfx_addr = (unsigned int )hws->addr & 536866816U;
#line 795
  dev_priv->hws_map.offset = (unsigned long )((unsigned long long )(dev->agp)->base + hws->addr);
#line 796
  dev_priv->hws_map.size = 4096UL;
#line 797
  dev_priv->hws_map.type = _DRM_FRAME_BUFFER;
#line 798
  dev_priv->hws_map.flags = 0;
#line 799
  dev_priv->hws_map.mtrr = 0;
#line 801
  drm_core_ioremap(& dev_priv->hws_map, dev);
#line 802
  if ((unsigned long )dev_priv->hws_map.handle == (unsigned long )((void *)0)) {
#line 803
    i915_dma_cleanup(dev);
#line 804
    dev_priv->status_gfx_addr = 0U;
#line 805
    printk("<3>[drm:%s] *ERROR* can not ioremap virtual address for G33 hw status page\n",
           "i915_set_status_page");
#line 807
    return (-12);
  } else {

  }
#line 809
  dev_priv->hw_status_page = dev_priv->hws_map.handle;
#line 811
  memset(dev_priv->hw_status_page, 0, 4096UL);
#line 812
  writel(dev_priv->status_gfx_addr, (void volatile   *)dev_priv->regs + 8320U);
#line 813
  if (drm_debug != 0U) {
#line 813
    printk("<7>[drm:%s] load hws HWS_PGA with gfx mem 0x%x\n", "i915_set_status_page",
           dev_priv->status_gfx_addr);
  } else {

  }
#line 815
  if (drm_debug != 0U) {
#line 815
    printk("<7>[drm:%s] load hws at %p\n", "i915_set_status_page", dev_priv->hw_status_page);
  } else {

  }
#line 816
  return (0);
}
}
#line 819 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
int i915_driver_load(struct drm_device *dev , unsigned long flags ) 
{ 
  struct drm_i915_private *dev_priv ;
  unsigned long base ;
  unsigned long size ;
  int ret ;
  int mmio_bar ;
  void *tmp ;
  struct lock_class_key __key ;

  {
#line 821
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 823
  ret = 0;
#line 823
  mmio_bar = (((((dev->pci_device != 9602 && dev->pci_device != 9610) && dev->pci_device != 9618) && dev->pci_device != 10098) && (dev->pci_device != 10146 && dev->pci_device != 10158)) && (((((((((dev->pci_device != 10610 && dev->pci_device != 10626) && dev->pci_device != 10642) && dev->pci_device != 10658) && dev->pci_device != 10754) && dev->pci_device != 10770) && dev->pci_device != 10818) && dev->pci_device != 11778) && dev->pci_device != 11794) && dev->pci_device != 11810)) && ((dev->pci_device != 10690 && dev->pci_device != 10674) && dev->pci_device != 10706);
#line 826
  dev->counters = dev->counters + 4UL;
#line 827
  dev->types[6] = _DRM_STAT_IRQ;
#line 828
  dev->types[7] = _DRM_STAT_PRIMARY;
#line 829
  dev->types[8] = _DRM_STAT_SECONDARY;
#line 830
  dev->types[9] = _DRM_STAT_DMA;
#line 832
  tmp = drm_alloc(4104UL, 2);
#line 832
  dev_priv = (struct drm_i915_private *)tmp;
#line 833
  if ((unsigned long )dev_priv == (unsigned long )((struct drm_i915_private *)0)) {
#line 834
    return (-12);
  } else {

  }
#line 836
  memset((void *)dev_priv, 0, 4104UL);
#line 838
  dev->dev_private = (void *)dev_priv;
#line 839
  dev_priv->dev = dev;
#line 842
  base = drm_get_resource_start(dev, (unsigned int )mmio_bar);
#line 843
  size = drm_get_resource_len(dev, (unsigned int )mmio_bar);
#line 845
  dev_priv->regs = ioremap((resource_size_t )base, size);
#line 847
  i915_gem_load(dev);
#line 850
  if ((((dev->pci_device != 10690 && dev->pci_device != 10674) && dev->pci_device != 10706) && dev->pci_device != 10818) && ((dev->pci_device != 11778 && dev->pci_device != 11794) && dev->pci_device != 11810)) {
#line 851
    ret = i915_init_phys_hws(dev);
#line 852
    if (ret != 0) {
#line 853
      return (ret);
    } else {

    }
  } else {

  }
#line 866
  if ((dev->pci_device != 10098 && (dev->pci_device != 10146 && dev->pci_device != 10158)) && dev->pci_device != 10754) {
#line 867
    pci_enable_msi(dev->pdev);
  } else {

  }
#line 869
  intel_opregion_init(dev);
#line 871
  __spin_lock_init(& dev_priv->user_irq_lock, "&dev_priv->user_irq_lock", & __key);
#line 873
  ret = drm_vblank_init(dev, 2);
#line 875
  if (ret != 0) {
#line 876
    i915_driver_unload(dev);
#line 877
    return (ret);
  } else {

  }
#line 880
  return (ret);
}
}
#line 883 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
int i915_driver_unload(struct drm_device *dev ) 
{ 
  struct drm_i915_private *dev_priv ;

  {
#line 885
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 887
  if ((unsigned int )*((unsigned char *)dev->pdev + 1808UL) != 0U) {
#line 888
    pci_disable_msi(dev->pdev);
  } else {

  }
#line 890
  i915_free_hws(dev);
#line 892
  if ((unsigned long )dev_priv->regs != (unsigned long )((void *)0)) {
#line 893
    iounmap((void volatile   *)dev_priv->regs);
  } else {

  }
#line 895
  intel_opregion_free(dev);
#line 897
  drm_free(dev->dev_private, 4104UL, 2);
#line 900
  return (0);
}
}
#line 903 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
int i915_driver_open(struct drm_device *dev , struct drm_file *file_priv ) 
{ 
  struct drm_i915_file_private *i915_file_priv ;
  void *tmp ;

  {
#line 907
  if (drm_debug != 0U) {
#line 907
    printk("<7>[drm:%s] \n", "i915_driver_open");
  } else {

  }
#line 908
  tmp = drm_alloc(8UL, 10);
#line 908
  i915_file_priv = (struct drm_i915_file_private *)tmp;
#line 911
  if ((unsigned long )i915_file_priv == (unsigned long )((struct drm_i915_file_private *)0)) {
#line 912
    return (-12);
  } else {

  }
#line 914
  file_priv->driver_priv = (void *)i915_file_priv;
#line 916
  i915_file_priv->mm.last_gem_seqno = 0U;
#line 917
  i915_file_priv->mm.last_gem_throttle_seqno = 0U;
#line 919
  return (0);
}
}
#line 922 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
void i915_driver_lastclose(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 924
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 926
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 927
    return;
  } else {

  }
#line 929
  i915_gem_lastclose(dev);
#line 931
  if ((unsigned long )dev_priv->agp_heap != (unsigned long )((struct mem_block *)0)) {
#line 932
    i915_mem_takedown(& dev_priv->agp_heap);
  } else {

  }
#line 934
  i915_dma_cleanup(dev);
#line 935
  return;
}
}
#line 937 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
void i915_driver_preclose(struct drm_device *dev , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 939
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 940
  i915_mem_release(dev, file_priv, dev_priv->agp_heap);
#line 941
  return;
}
}
#line 943 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
void i915_driver_postclose(struct drm_device *dev , struct drm_file *file_priv ) 
{ 
  struct drm_i915_file_private *i915_file_priv ;

  {
#line 945
  i915_file_priv = (struct drm_i915_file_private *)file_priv->driver_priv;
#line 947
  drm_free((void *)i915_file_priv, 8UL, 10);
#line 948
  return;
}
}
#line 950 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
struct drm_ioctl_desc i915_ioctls[36U]  = 
#line 950
  {      {0U, & i915_dma_init, 7}, 
        {1U, & i915_flush_ioctl, 1}, 
        {2U, & i915_flip_bufs, 1}, 
        {3U, & i915_batchbuffer, 1}, 
        {4U, & i915_irq_emit, 1}, 
        {5U, & i915_irq_wait, 1}, 
        {6U, & i915_getparam, 1}, 
        {7U, & i915_setparam, 7}, 
        {8U, & i915_mem_alloc, 1}, 
        {9U, & i915_mem_free, 1}, 
        {10U, & i915_mem_init_heap, 7}, 
        {11U, & i915_cmdbuffer, 1}, 
        {12U, & i915_mem_destroy_heap, 7}, 
        {13U, & i915_vblank_pipe_set, 7}, 
        {14U, & i915_vblank_pipe_get, 1}, 
        {15U, & i915_vblank_swap, 1}, 
        {0U, 0, 0}, 
        {17U, & i915_set_status_page, 7}, 
        {0U, 0, 0}, 
        {19U, & i915_gem_init_ioctl, 7}, 
        {20U, & i915_gem_execbuffer, 1}, 
        {21U, & i915_gem_pin_ioctl, 5}, 
        {22U, & i915_gem_unpin_ioctl, 5}, 
        {23U, & i915_gem_busy_ioctl, 1}, 
        {24U, & i915_gem_throttle_ioctl, 1}, 
        {25U, & i915_gem_entervt_ioctl, 7}, 
        {26U, & i915_gem_leavevt_ioctl, 7}, 
        {27U, & i915_gem_create_ioctl, 0}, 
        {28U, & i915_gem_pread_ioctl, 0}, 
        {29U, & i915_gem_pwrite_ioctl, 0}, 
        {30U, & i915_gem_mmap_ioctl, 0}, 
        {31U, & i915_gem_set_domain_ioctl, 0}, 
        {32U, & i915_gem_sw_finish_ioctl, 0}, 
        {33U, & i915_gem_set_tiling, 0}, 
        {34U, & i915_gem_get_tiling, 0}, 
        {35U, & i915_gem_get_aperture_ioctl, 0}};
#line 987 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
int i915_max_ioctl  =    36;
#line 1000 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
int i915_driver_device_is_agp(struct drm_device *dev ) 
{ 


  {
#line 1002
  return (1);
}
}
#line 1016 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
unsigned long ldv___get_free_pages_18(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 1022
  ldv_check_alloc_flags(ldv_func_arg1);
#line 1024
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 1024
  return (tmp);
}
}
#line 1027 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
__inline static void *kmalloc(size_t size , gfp_t flags ) 
{ 


  {
#line 1033
  ldv_check_alloc_flags(flags);
#line 1035
  ldv_kmalloc_19(size, flags);
#line 1036
  return ((void *)0);
}
}
#line 1038 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
void *ldv_kmem_cache_alloc_20(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 1044
  ldv_check_alloc_flags(ldv_func_arg2);
#line 1046
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 1047
  return ((void *)0);
}
}
#line 1082 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
void *ldv_kmem_cache_alloc_24(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 1088
  ldv_check_alloc_flags(ldv_func_arg2);
#line 1090
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 1091
  return ((void *)0);
}
}
#line 1125 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_dma.c.prepared"
struct page *ldv_alloc_page_vma_28(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 1132
  ldv_check_alloc_flags(ldv_func_arg1);
#line 1134
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 1134
  return (tmp);
}
}
#line 2 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void ldv_spin_lock(void) ;
#line 3
void ldv_spin_unlock(void) ;
#line 301 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/bitops.h"
__inline static int variable_test_bit(int nr , unsigned long const volatile   *addr ) 
{ 
  int oldbit ;

  {
#line 305
  __asm__  volatile   ("bt %2,%1\n\tsbb %0,%0": "=r" (oldbit): "m" (*((unsigned long *)addr)),
                       "Ir" (nr));
#line 310
  return (oldbit);
}
}
#line 23 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/current.h"
__inline static struct task_struct *get_current(void) 
{ 
  struct task_struct *ret__ ;

  {
#line 25
  switch (8UL) {
  case 2UL: 
#line 25
  __asm__  ("movw %%gs:%c1,%0": "=r" (ret__): "i" (0UL), "m" (_proxy_pda.pcurrent));
#line 25
  goto ldv_4238;
  case 4UL: 
#line 25
  __asm__  ("movl %%gs:%c1,%0": "=r" (ret__): "i" (0UL), "m" (_proxy_pda.pcurrent));
#line 25
  goto ldv_4238;
  case 8UL: 
#line 25
  __asm__  ("movq %%gs:%c1,%0": "=r" (ret__): "i" (0UL), "m" (_proxy_pda.pcurrent));
#line 25
  goto ldv_4238;
  default: 
#line 25
  __bad_pda_field();
  }
  ldv_4238: ;
#line 25
  return (ret__);
}
}
#line 84 "include/linux/thread_info.h"
__inline static int test_ti_thread_flag(struct thread_info *ti , int flag ) 
{ 
  int tmp ;

  {
#line 86
  tmp = variable_test_bit(flag, (unsigned long const volatile   *)(& ti->flags));
#line 86
  return (tmp);
}
}
#line 95 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic_64.h"
__inline static void atomic_inc(atomic_t *v ) 
{ 


  {
#line 97
  __asm__  volatile   (".section .smp_locks,\"a\"\n .balign 8 \n .quad 661f\n.previous\n661:\n\tlock; incl %0": "=m" (v->counter): "m" (v->counter));
#line 100
  return;
}
}
#line 30 "include/linux/wait.h"
extern int default_wake_function(wait_queue_t * , unsigned int  , int  , void * ) ;
#line 80
extern void init_waitqueue_head(wait_queue_head_t * ) ;
#line 111
extern void add_wait_queue(wait_queue_head_t * , wait_queue_t * ) ;
#line 113
extern void remove_wait_queue(wait_queue_head_t * , wait_queue_t * ) ;
#line 135
extern void __wake_up(wait_queue_head_t * , unsigned int  , int  , void * ) ;
#line 227 "include/linux/gfp.h"
struct page *ldv_alloc_page_vma_44(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) ;
#line 239
unsigned long ldv___get_free_pages_34(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 82 "include/linux/jiffies.h"
extern unsigned long volatile   jiffies ;
#line 207 "include/linux/slub_def.h"
void *ldv_kmem_cache_alloc_36(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_40(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 329 "include/linux/sched.h"
extern long schedule_timeout(long  ) ;
#line 2054 "include/linux/sched.h"
__inline static int test_tsk_thread_flag(struct task_struct *tsk , int flag ) 
{ 
  int tmp ;

  {
#line 2056
  tmp = test_ti_thread_flag((struct thread_info *)tsk->stack, flag);
#line 2056
  return (tmp);
}
}
#line 2074 "include/linux/sched.h"
__inline static int signal_pending(struct task_struct *p ) 
{ 
  int tmp ;
  long tmp___0 ;

  {
#line 2076
  tmp = test_tsk_thread_flag(p, 2);
#line 2076
  tmp___0 = __builtin_expect(tmp != 0, 0L);
#line 2076
  return ((int )tmp___0);
}
}
#line 1151 "include/drm/drmP.h"
extern void drm_handle_vblank(struct drm_device * , int  ) ;
#line 440 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
void i915_user_irq_get(struct drm_device *dev ) ;
#line 441
void i915_user_irq_put(struct drm_device *dev ) ;
#line 456
void i915_enable_irq(drm_i915_private_t *dev_priv , u32 mask ) ;
#line 459
void i915_enable_pipestat(drm_i915_private_t *dev_priv , int pipe , u32 mask ) ;
#line 462
void i915_disable_pipestat(drm_i915_private_t *dev_priv , int pipe , u32 mask ) ;
#line 520
uint32_t i915_get_gem_seqno(struct drm_device *dev ) ;
#line 553
void opregion_asle_intr(struct drm_device *dev ) ;
#line 554
void opregion_enable_asle(struct drm_device *dev ) ;
#line 69 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void i915_enable_irq(drm_i915_private_t *dev_priv , u32 mask ) 
{ 


  {
#line 71
  if ((dev_priv->irq_mask_reg & mask) != 0U) {
#line 72
    dev_priv->irq_mask_reg = dev_priv->irq_mask_reg & ~ mask;
#line 73
    writel(dev_priv->irq_mask_reg, (void volatile   *)dev_priv->regs + 8360U);
#line 74
    readl((void const volatile   *)dev_priv->regs + 8360U);
  } else {

  }
#line 76
  return;
}
}
#line 79 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
__inline static void i915_disable_irq(drm_i915_private_t *dev_priv , u32 mask ) 
{ 


  {
#line 81
  if ((dev_priv->irq_mask_reg & mask) != mask) {
#line 82
    dev_priv->irq_mask_reg = dev_priv->irq_mask_reg | mask;
#line 83
    writel(dev_priv->irq_mask_reg, (void volatile   *)dev_priv->regs + 8360U);
#line 84
    readl((void const volatile   *)dev_priv->regs + 8360U);
  } else {

  }
#line 86
  return;
}
}
#line 89 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
__inline static u32 i915_pipestat(int pipe ) 
{ 


  {
#line 91
  if (pipe == 0) {
#line 92
    return (458788U);
  } else {

  }
#line 93
  if (pipe == 1) {
#line 94
    return (462884U);
  } else {

  }
#line 95
  __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"),
                       "i" (95), "i" (24UL));
  ldv_23802: ;
#line 95
  goto ldv_23802;
}
}
#line 99 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void i915_enable_pipestat(drm_i915_private_t *dev_priv , int pipe , u32 mask ) 
{ 
  u32 reg ;
  u32 tmp ;

  {
#line 101
  if ((dev_priv->pipestat[pipe] & mask) != mask) {
#line 102
    tmp = i915_pipestat(pipe);
#line 102
    reg = tmp;
#line 104
    dev_priv->pipestat[pipe] = dev_priv->pipestat[pipe] | mask;
#line 106
    writel(dev_priv->pipestat[pipe] | (mask >> 16), (void volatile   *)dev_priv->regs + (unsigned long )reg);
#line 107
    readl((void const volatile   *)dev_priv->regs + (unsigned long )reg);
  } else {

  }
#line 109
  return;
}
}
#line 112 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void i915_disable_pipestat(drm_i915_private_t *dev_priv , int pipe , u32 mask ) 
{ 
  u32 reg ;
  u32 tmp ;

  {
#line 114
  if ((dev_priv->pipestat[pipe] & mask) != 0U) {
#line 115
    tmp = i915_pipestat(pipe);
#line 115
    reg = tmp;
#line 117
    dev_priv->pipestat[pipe] = dev_priv->pipestat[pipe] & ~ mask;
#line 118
    writel(dev_priv->pipestat[pipe], (void volatile   *)dev_priv->regs + (unsigned long )reg);
#line 119
    readl((void const volatile   *)dev_priv->regs + (unsigned long )reg);
  } else {

  }
#line 121
  return;
}
}
#line 133 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
static int i915_pipe_enabled(struct drm_device *dev , int pipe ) 
{ 
  drm_i915_private_t *dev_priv ;
  unsigned long pipeconf ;
  unsigned int tmp ;

  {
#line 135
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 136
  pipeconf = pipe != 0 ? 462856UL : 458760UL;
#line 138
  tmp = readl((void const volatile   *)(dev_priv->regs + pipeconf));
#line 138
  if ((int )tmp < 0) {
#line 139
    return (1);
  } else {

  }
#line 141
  return (0);
}
}
#line 147 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
u32 i915_get_vblank_counter(struct drm_device *dev , int pipe ) 
{ 
  drm_i915_private_t *dev_priv ;
  unsigned long high_frame ;
  unsigned long low_frame ;
  u32 high1 ;
  u32 high2 ;
  u32 low ;
  u32 count ;
  int tmp ;
  unsigned int tmp___0 ;
  unsigned int tmp___1 ;
  unsigned int tmp___2 ;

  {
#line 149
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 154
  high_frame = pipe != 0 ? 462912UL : 458816UL;
#line 155
  low_frame = pipe != 0 ? 462916UL : 458820UL;
#line 157
  tmp = i915_pipe_enabled(dev, pipe);
#line 157
  if (tmp == 0) {
#line 158
    printk("<3>[drm:%s] *ERROR* trying to get vblank count for disabled pipe %d\n",
           "i915_get_vblank_counter", pipe);
#line 159
    return (0U);
  } else {

  }
  ldv_23833: 
#line 168
  tmp___0 = readl((void const volatile   *)(dev_priv->regs + high_frame));
#line 168
  high1 = tmp___0 & 65535U;
#line 170
  tmp___1 = readl((void const volatile   *)(dev_priv->regs + low_frame));
#line 170
  low = tmp___1 >> 24;
#line 172
  tmp___2 = readl((void const volatile   *)(dev_priv->regs + high_frame));
#line 172
  high2 = tmp___2 & 65535U;
#line 174
  if (high1 != high2) {
#line 175
    goto ldv_23833;
  } else {

  }
#line 176
  count = (high1 << 8) | low;
#line 178
  return (count);
}
}
#line 181 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
irqreturn_t i915_driver_irq_handler(int irq , void *arg ) 
{ 
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  u32 iir ;
  u32 new_iir ;
  u32 pipea_stats ;
  u32 pipeb_stats ;
  u32 vblank_status ;
  u32 vblank_enable ;
  int vblank ;
  int irq_received ;
  int ret ;

  {
#line 183
  dev = (struct drm_device *)arg;
#line 184
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 189
  vblank = 0;
#line 192
  ret = 0;
#line 194
  atomic_inc(& dev_priv->irq_received);
#line 196
  iir = readl((void const volatile   *)dev_priv->regs + 8356U);
#line 198
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 199
    vblank_status = 4U;
#line 200
    vblank_enable = 262144U;
  } else {
#line 202
    vblank_status = 2U;
#line 203
    vblank_enable = 131072U;
  }
  ldv_23852: 
#line 207
  irq_received = iir != 0U;
#line 214
  ldv_spin_lock();
#line 215
  pipea_stats = readl((void const volatile   *)dev_priv->regs + 458788U);
#line 216
  pipeb_stats = readl((void const volatile   *)dev_priv->regs + 462884U);
#line 220
  if ((pipea_stats & 2147549183U) != 0U) {
#line 221
    writel(pipea_stats, (void volatile   *)dev_priv->regs + 458788U);
#line 222
    irq_received = 1;
  } else {

  }
#line 225
  if ((pipeb_stats & 2147549183U) != 0U) {
#line 226
    writel(pipeb_stats, (void volatile   *)dev_priv->regs + 462884U);
#line 227
    irq_received = 1;
  } else {

  }
#line 229
  ldv_spin_unlock();
#line 231
  if (irq_received == 0) {
#line 232
    goto ldv_23851;
  } else {

  }
#line 234
  ret = 1;
#line 236
  writel(iir, (void volatile   *)dev_priv->regs + 8356U);
#line 237
  new_iir = readl((void const volatile   *)dev_priv->regs + 8356U);
#line 239
  if ((unsigned long )dev_priv->sarea_priv != (unsigned long )((drm_i915_sarea_t *)0)) {
#line 240
    (dev_priv->sarea_priv)->last_dispatch = (int )*((u32 volatile   *)dev_priv->hw_status_page + 33UL);
  } else {

  }
#line 243
  if ((iir & 2U) != 0U) {
#line 244
    dev_priv->mm.irq_gem_seqno = i915_get_gem_seqno(dev);
#line 245
    __wake_up(& dev_priv->irq_queue, 1U, 1, 0);
  } else {

  }
#line 248
  if ((pipea_stats & vblank_status) != 0U) {
#line 249
    vblank = vblank + 1;
#line 250
    drm_handle_vblank(dev, 0);
  } else {

  }
#line 253
  if ((pipeb_stats & vblank_status) != 0U) {
#line 254
    vblank = vblank + 1;
#line 255
    drm_handle_vblank(dev, 1);
  } else {

  }
#line 258
  if (((unsigned long )pipeb_stats & 64UL) != 0UL || (int )iir & 1) {
#line 260
    opregion_asle_intr(dev);
  } else {

  }
#line 277
  iir = new_iir;
#line 278
  goto ldv_23852;
  ldv_23851: ;
#line 280
  return (ret);
}
}
#line 283 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
static int i915_emit_irq(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  unsigned int outring ;
  unsigned int ringmask ;
  unsigned int outcount ;
  char volatile   *virt ;

  {
#line 285
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 288
  i915_kernel_lost_context(dev);
#line 290
  if (drm_debug != 0U) {
#line 290
    printk("<7>[drm:%s] \n", "i915_emit_irq");
  } else {

  }
#line 292
  dev_priv->counter = dev_priv->counter + (uint32_t )1;
#line 293
  if ((int )dev_priv->counter < 0) {
#line 294
    dev_priv->counter = 1U;
  } else {

  }
#line 295
  if ((unsigned long )dev_priv->sarea_priv != (unsigned long )((drm_i915_sarea_t *)0)) {
#line 296
    (dev_priv->sarea_priv)->last_enqueue = (int )dev_priv->counter;
  } else {

  }
#line 298
  if (dev_priv->ring.space <= 15) {
#line 298
    i915_wait_ring(dev, 16, "i915_emit_irq");
  } else {

  }
#line 298
  outcount = 0U;
#line 298
  outring = (unsigned int )dev_priv->ring.tail;
#line 298
  ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 298
  virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 299
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 276824065U;
#line 299
  outcount = outcount + 1U;
#line 299
  outring = outring + 4U;
#line 299
  outring = outring & ringmask;
#line 300
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 132U;
#line 300
  outcount = outcount + 1U;
#line 300
  outring = outring + 4U;
#line 300
  outring = outring & ringmask;
#line 301
  *((unsigned int volatile   *)virt + (unsigned long )outring) = dev_priv->counter;
#line 301
  outcount = outcount + 1U;
#line 301
  outring = outring + 4U;
#line 301
  outring = outring & ringmask;
#line 302
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 16777216U;
#line 302
  outcount = outcount + 1U;
#line 302
  outring = outring + 4U;
#line 302
  outring = outring & ringmask;
#line 303
  dev_priv->ring.tail = (int )outring;
#line 303
  dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 303
  writel(outring, (void volatile   *)dev_priv->regs + 8240U);
#line 305
  return ((int )dev_priv->counter);
}
}
#line 308 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void i915_user_irq_get(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 310
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 313
  ldv_spin_lock();
#line 314
  if (dev->irq_enabled != 0) {
#line 314
    dev_priv->user_irq_refcount = dev_priv->user_irq_refcount + 1;
#line 314
    if (dev_priv->user_irq_refcount == 1) {
#line 315
      i915_enable_irq(dev_priv, 2U);
    } else {

    }
  } else {

  }
#line 316
  ldv_spin_unlock();
#line 317
  return;
}
}
#line 319 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void i915_user_irq_put(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  long tmp ;
  long tmp___0 ;

  {
#line 321
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 324
  ldv_spin_lock();
#line 325
  tmp = __builtin_expect(dev->irq_enabled != 0, 0L);
#line 325
  if (tmp != 0L) {
#line 325
    tmp___0 = __builtin_expect(dev_priv->user_irq_refcount <= 0, 0L);
#line 325
    if (tmp___0 != 0L) {
#line 325
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"),
                           "i" (325), "i" (24UL));
      ldv_23872: ;
#line 325
      goto ldv_23872;
    } else {

    }
  } else {

  }
#line 326
  if (dev->irq_enabled != 0) {
#line 326
    dev_priv->user_irq_refcount = dev_priv->user_irq_refcount - 1;
#line 326
    if (dev_priv->user_irq_refcount == 0) {
#line 327
      i915_disable_irq(dev_priv, 2U);
    } else {

    }
  } else {

  }
#line 328
  ldv_spin_unlock();
#line 329
  return;
}
}
#line 331 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
static int i915_wait_irq(struct drm_device *dev , int irq_nr ) 
{ 
  drm_i915_private_t *dev_priv ;
  int ret ;
  wait_queue_t entry ;
  struct task_struct *tmp ;
  unsigned long end ;
  struct task_struct *tmp___0 ;
  struct task_struct *tmp___1 ;
  int tmp___2 ;
  struct task_struct *tmp___3 ;

  {
#line 333
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 334
  ret = 0;
#line 336
  if (drm_debug != 0U) {
#line 336
    printk("<7>[drm:%s] irq_nr=%d breadcrumb=%d\n", "i915_wait_irq", irq_nr, *((u32 volatile   *)dev_priv->hw_status_page + 33UL));
  } else {

  }
#line 339
  if ((unsigned int )*((u32 volatile   *)dev_priv->hw_status_page + 33UL) >= (unsigned int )irq_nr) {
#line 340
    if ((unsigned long )dev_priv->sarea_priv != (unsigned long )((drm_i915_sarea_t *)0)) {
#line 341
      (dev_priv->sarea_priv)->last_dispatch = (int )*((u32 volatile   *)dev_priv->hw_status_page + 33UL);
    } else {

    }
#line 344
    return (0);
  } else {

  }
#line 347
  if ((unsigned long )dev_priv->sarea_priv != (unsigned long )((drm_i915_sarea_t *)0)) {
#line 348
    (dev_priv->sarea_priv)->perf_boxes = (dev_priv->sarea_priv)->perf_boxes | 4;
  } else {

  }
#line 350
  i915_user_irq_get(dev);
#line 351
  tmp = get_current();
#line 351
  entry.flags = 0U;
#line 351
  entry.private = (void *)tmp;
#line 351
  entry.func = & default_wake_function;
#line 351
  entry.task_list.next = 0;
#line 351
  entry.task_list.prev = 0;
#line 351
  end = (unsigned long )jiffies + 750UL;
#line 351
  add_wait_queue(& dev_priv->irq_queue, & entry);
  ldv_23889: 
#line 351
  tmp___0 = get_current();
#line 351
  tmp___0->state = 1L;
#line 351
  if ((unsigned int )*((u32 volatile   *)dev_priv->hw_status_page + 33UL) >= (unsigned int )irq_nr) {
#line 351
    goto ldv_23882;
  } else {

  }
#line 351
  if ((1 != 0 && 1 != 0) && (long )jiffies - (long )end >= 0L) {
#line 351
    ret = -16;
#line 351
    goto ldv_23882;
  } else {

  }
#line 351
  schedule_timeout(2L);
#line 351
  tmp___1 = get_current();
#line 351
  tmp___2 = signal_pending(tmp___1);
#line 351
  if (tmp___2 != 0) {
#line 351
    ret = -4;
#line 351
    goto ldv_23882;
  } else {

  }
#line 351
  goto ldv_23889;
  ldv_23882: 
#line 351
  tmp___3 = get_current();
#line 351
  tmp___3->state = 0L;
#line 351
  remove_wait_queue(& dev_priv->irq_queue, & entry);
#line 353
  i915_user_irq_put(dev);
#line 355
  if (ret == -16) {
#line 356
    printk("<3>[drm:%s] *ERROR* EBUSY -- rec: %d emitted: %d\n", "i915_wait_irq",
           *((u32 volatile   *)dev_priv->hw_status_page + 33UL), (int )dev_priv->counter);
  } else {

  }
#line 360
  if ((unsigned long )dev_priv->sarea_priv != (unsigned long )((drm_i915_sarea_t *)0)) {
#line 361
    (dev_priv->sarea_priv)->last_dispatch = (int )*((u32 volatile   *)dev_priv->hw_status_page + 33UL);
  } else {

  }
#line 364
  return (ret);
}
}
#line 369 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
int i915_irq_emit(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_irq_emit_t *emit ;
  int result ;
  unsigned long tmp ;

  {
#line 372
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 373
  emit = (drm_i915_irq_emit_t *)data;
#line 376
  if ((unsigned long )((drm_i915_private_t *)dev->dev_private)->ring.ring_obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 376
    if ((int )(dev->lock.hw_lock)->lock >= 0 || (unsigned long )dev->lock.file_priv != (unsigned long )file_priv) {
#line 376
      printk("<3>[drm:%s] *ERROR* %s called without lock held, held  %d owner %p %p\n",
             "i915_irq_emit", "i915_irq_emit", (unsigned int )(dev->lock.hw_lock)->lock & 2147483648U,
             dev->lock.file_priv, file_priv);
#line 376
      return (-22);
    } else {

    }
  } else {

  }
#line 378
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 379
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_irq_emit");
#line 380
    return (-22);
  } else {

  }
#line 382
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 383
  result = i915_emit_irq(dev);
#line 384
  mutex_unlock(& dev->struct_mutex);
#line 386
  tmp = copy_to_user((void *)emit->irq_seq, (void const   *)(& result), 4U);
#line 386
  if (tmp != 0UL) {
#line 387
    printk("<3>[drm:%s] *ERROR* copy_to_user\n", "i915_irq_emit");
#line 388
    return (-14);
  } else {

  }
#line 391
  return (0);
}
}
#line 396 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
int i915_irq_wait(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_irq_wait_t *irqwait ;
  int tmp ;

  {
#line 399
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 400
  irqwait = (drm_i915_irq_wait_t *)data;
#line 402
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 403
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_irq_wait");
#line 404
    return (-22);
  } else {

  }
#line 407
  tmp = i915_wait_irq(dev, irqwait->irq_seq);
#line 407
  return (tmp);
}
}
#line 413 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
int i915_enable_vblank(struct drm_device *dev , int pipe ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 415
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 418
  ldv_spin_lock();
#line 419
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 420
    i915_enable_pipestat(dev_priv, pipe, 262144U);
  } else {
#line 423
    i915_enable_pipestat(dev_priv, pipe, 131072U);
  }
#line 425
  ldv_spin_unlock();
#line 426
  return (0);
}
}
#line 432 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void i915_disable_vblank(struct drm_device *dev , int pipe ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 434
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 437
  ldv_spin_lock();
#line 438
  i915_disable_pipestat(dev_priv, pipe, 393216U);
#line 441
  ldv_spin_unlock();
#line 442
  return;
}
}
#line 446 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
int i915_vblank_pipe_set(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 449
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 451
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 452
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_vblank_pipe_set");
#line 453
    return (-22);
  } else {

  }
#line 456
  return (0);
}
}
#line 459 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
int i915_vblank_pipe_get(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_vblank_pipe_t *pipe ;

  {
#line 462
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 463
  pipe = (drm_i915_vblank_pipe_t *)data;
#line 465
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 466
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_vblank_pipe_get");
#line 467
    return (-22);
  } else {

  }
#line 470
  pipe->pipe = 3;
#line 472
  return (0);
}
}
#line 478 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
int i915_vblank_swap(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 


  {
#line 495
  return (-22);
}
}
#line 500 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void i915_driver_irq_preinstall(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 502
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 504
  writel(61438U, (void volatile   *)dev_priv->regs + 8344U);
#line 505
  writel(0U, (void volatile   *)dev_priv->regs + 458788U);
#line 506
  writel(0U, (void volatile   *)dev_priv->regs + 462884U);
#line 507
  writel(4294967295U, (void volatile   *)dev_priv->regs + 8360U);
#line 508
  writel(0U, (void volatile   *)dev_priv->regs + 8352U);
#line 509
  readl((void const volatile   *)dev_priv->regs + 8352U);
#line 510
  return;
}
}
#line 512 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
int i915_driver_irq_postinstall(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  unsigned int tmp___1 ;

  {
#line 514
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 516
  dev_priv->vblank_pipe = 3;
#line 518
  dev->max_vblank_count = 16777215U;
#line 521
  dev_priv->irq_mask_reg = 4294967214U;
#line 523
  dev_priv->pipestat[0] = 0U;
#line 524
  dev_priv->pipestat[1] = 0U;
#line 527
  tmp = readl((void const volatile   *)dev_priv->regs + 458788U);
#line 527
  writel(tmp & 2147549183U, (void volatile   *)dev_priv->regs + 458788U);
#line 528
  tmp___0 = readl((void const volatile   *)dev_priv->regs + 462884U);
#line 528
  writel(tmp___0 & 2147549183U, (void volatile   *)dev_priv->regs + 462884U);
#line 530
  tmp___1 = readl((void const volatile   *)dev_priv->regs + 8356U);
#line 530
  writel(tmp___1, (void volatile   *)dev_priv->regs + 8356U);
#line 532
  writel(83U, (void volatile   *)dev_priv->regs + 8352U);
#line 533
  writel(dev_priv->irq_mask_reg, (void volatile   *)dev_priv->regs + 8360U);
#line 534
  readl((void const volatile   *)dev_priv->regs + 8352U);
#line 536
  opregion_enable_asle(dev);
#line 537
  init_waitqueue_head(& dev_priv->irq_queue);
#line 539
  return (0);
}
}
#line 542 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void i915_driver_irq_uninstall(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  unsigned int tmp___1 ;

  {
#line 544
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 546
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 547
    return;
  } else {

  }
#line 549
  dev_priv->vblank_pipe = 0;
#line 551
  writel(4294967295U, (void volatile   *)dev_priv->regs + 8344U);
#line 552
  writel(0U, (void volatile   *)dev_priv->regs + 458788U);
#line 553
  writel(0U, (void volatile   *)dev_priv->regs + 462884U);
#line 554
  writel(4294967295U, (void volatile   *)dev_priv->regs + 8360U);
#line 555
  writel(0U, (void volatile   *)dev_priv->regs + 8352U);
#line 557
  tmp = readl((void const volatile   *)dev_priv->regs + 458788U);
#line 557
  writel(tmp & 2147549183U, (void volatile   *)dev_priv->regs + 458788U);
#line 558
  tmp___0 = readl((void const volatile   *)dev_priv->regs + 462884U);
#line 558
  writel(tmp___0 & 2147549183U, (void volatile   *)dev_priv->regs + 462884U);
#line 559
  tmp___1 = readl((void const volatile   *)dev_priv->regs + 8356U);
#line 559
  writel(tmp___1, (void volatile   *)dev_priv->regs + 8356U);
#line 560
  return;
}
}
#line 573 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
unsigned long ldv___get_free_pages_34(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 579
  ldv_check_alloc_flags(ldv_func_arg1);
#line 581
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 581
  return (tmp);
}
}
#line 595 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void *ldv_kmem_cache_alloc_36(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 601
  ldv_check_alloc_flags(ldv_func_arg2);
#line 603
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 604
  return ((void *)0);
}
}
#line 639 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
void *ldv_kmem_cache_alloc_40(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 645
  ldv_check_alloc_flags(ldv_func_arg2);
#line 647
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 648
  return ((void *)0);
}
}
#line 682 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_irq.c.prepared"
struct page *ldv_alloc_page_vma_44(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 689
  ldv_check_alloc_flags(ldv_func_arg1);
#line 691
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 691
  return (tmp);
}
}
#line 227 "include/linux/gfp.h"
struct page *ldv_alloc_page_vma_60(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) ;
#line 239
unsigned long ldv___get_free_pages_50(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 207 "include/linux/slub_def.h"
void *ldv_kmem_cache_alloc_52(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_56(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 220
__inline static void *kmalloc(size_t size , gfp_t flags ) ;
#line 1350 "include/drm/drmP.h"
__inline static void *drm_alloc___0(size_t size , int area ) 
{ 
  void *tmp ;

  {
#line 1352
  tmp = kmalloc(size, 208U);
#line 1352
  return (tmp);
}
}
#line 60 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
static void mark_block(struct drm_device *dev , struct mem_block *p , int in_use ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_sarea_t *sarea_priv ;
  struct drm_tex_region *list ;
  unsigned int shift ;
  unsigned int nr ;
  unsigned int start ;
  unsigned int end ;
  unsigned int i ;
  int age ;

  {
#line 62
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 63
  sarea_priv = dev_priv->sarea_priv;
#line 71
  shift = (unsigned int )dev_priv->tex_lru_log_granularity;
#line 72
  nr = 255U;
#line 74
  start = (unsigned int )(p->start >> (int )shift);
#line 75
  end = (unsigned int )(((p->start + p->size) + -1) >> (int )shift);
#line 77
  sarea_priv->texAge = sarea_priv->texAge + 1;
#line 77
  age = sarea_priv->texAge;
#line 78
  list = (struct drm_tex_region *)(& sarea_priv->texList);
#line 83
  i = start;
#line 83
  goto ldv_23806;
  ldv_23805: 
#line 84
  (list + (unsigned long )i)->in_use = (unsigned char )in_use;
#line 85
  (list + (unsigned long )i)->age = (unsigned int )age;
#line 89
  (list + (unsigned long )(list + (unsigned long )i)->next)->prev = (list + (unsigned long )i)->prev;
#line 90
  (list + (unsigned long )(list + (unsigned long )i)->prev)->next = (list + (unsigned long )i)->next;
#line 94
  (list + (unsigned long )i)->prev = (unsigned char )nr;
#line 95
  (list + (unsigned long )i)->next = (list + (unsigned long )nr)->next;
#line 96
  (list + (unsigned long )(list + (unsigned long )nr)->next)->prev = (unsigned char )i;
#line 97
  (list + (unsigned long )nr)->next = (unsigned char )i;
#line 83
  i = i + 1U;
  ldv_23806: ;
#line 83
  if (i <= end) {
#line 84
    goto ldv_23805;
  } else {

  }

#line 88
  return;
}
}
#line 105 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
static struct mem_block *split_block(struct mem_block *p , int start , int size ,
                                     struct drm_file *file_priv ) 
{ 
  struct mem_block *newblock ;
  void *tmp ;
  struct mem_block *newblock___0 ;
  void *tmp___0 ;

  {
#line 109
  if (p->start < start) {
#line 110
    tmp = drm_alloc___0(32UL, 14);
#line 110
    newblock = (struct mem_block *)tmp;
#line 112
    if ((unsigned long )newblock == (unsigned long )((struct mem_block *)0)) {
#line 113
      goto out;
    } else {

    }
#line 114
    newblock->start = start;
#line 115
    newblock->size = p->size + (p->start - start);
#line 116
    newblock->file_priv = 0;
#line 117
    newblock->next = p->next;
#line 118
    newblock->prev = p;
#line 119
    (p->next)->prev = newblock;
#line 120
    p->next = newblock;
#line 121
    p->size = p->size - newblock->size;
#line 122
    p = newblock;
  } else {

  }
#line 126
  if (p->size > size) {
#line 127
    tmp___0 = drm_alloc___0(32UL, 14);
#line 127
    newblock___0 = (struct mem_block *)tmp___0;
#line 129
    if ((unsigned long )newblock___0 == (unsigned long )((struct mem_block *)0)) {
#line 130
      goto out;
    } else {

    }
#line 131
    newblock___0->start = start + size;
#line 132
    newblock___0->size = p->size - size;
#line 133
    newblock___0->file_priv = 0;
#line 134
    newblock___0->next = p->next;
#line 135
    newblock___0->prev = p;
#line 136
    (p->next)->prev = newblock___0;
#line 137
    p->next = newblock___0;
#line 138
    p->size = size;
  } else {

  }
  out: 
#line 143
  p->file_priv = file_priv;
#line 144
  return (p);
}
}
#line 147 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
static struct mem_block *alloc_block(struct mem_block *heap , int size , int align2 ,
                                     struct drm_file *file_priv ) 
{ 
  struct mem_block *p ;
  int mask ;
  int start ;
  struct mem_block *tmp ;

  {
#line 151
  mask = (1 << align2) + -1;
#line 153
  p = heap->next;
#line 153
  goto ldv_23827;
  ldv_23826: 
#line 154
  start = (p->start + mask) & ~ mask;
#line 155
  if ((unsigned long )p->file_priv == (unsigned long )((struct drm_file *)0) && start + size <= p->start + p->size) {
#line 156
    tmp = split_block(p, start, size, file_priv);
#line 156
    return (tmp);
  } else {

  }
#line 153
  p = p->next;
  ldv_23827: ;
#line 153
  if ((unsigned long )p != (unsigned long )heap) {
#line 154
    goto ldv_23826;
  } else {

  }

#line 159
  return (0);
}
}
#line 162 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
static struct mem_block *find_block(struct mem_block *heap , int start ) 
{ 
  struct mem_block *p ;

  {
#line 166
  p = heap->next;
#line 166
  goto ldv_23835;
  ldv_23834: ;
#line 167
  if (p->start == start) {
#line 168
    return (p);
  } else {

  }
#line 166
  p = p->next;
  ldv_23835: ;
#line 166
  if ((unsigned long )p != (unsigned long )heap) {
#line 167
    goto ldv_23834;
  } else {

  }

#line 170
  return (0);
}
}
#line 173 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
static void free_block(struct mem_block *p ) 
{ 
  struct mem_block *q ;
  struct mem_block *q___0 ;

  {
#line 175
  p->file_priv = 0;
#line 180
  if ((unsigned long )(p->next)->file_priv == (unsigned long )((struct drm_file *)0)) {
#line 181
    q = p->next;
#line 182
    p->size = p->size + q->size;
#line 183
    p->next = q->next;
#line 184
    (p->next)->prev = p;
#line 185
    drm_free((void *)q, 32UL, 14);
  } else {

  }
#line 188
  if ((unsigned long )(p->prev)->file_priv == (unsigned long )((struct drm_file *)0)) {
#line 189
    q___0 = p->prev;
#line 190
    q___0->size = q___0->size + p->size;
#line 191
    q___0->next = p->next;
#line 192
    (q___0->next)->prev = q___0;
#line 193
    drm_free((void *)p, 32UL, 14);
  } else {

  }
#line 195
  return;
}
}
#line 199 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
static int init_heap(struct mem_block **heap , int start , int size ) 
{ 
  struct mem_block *blocks ;
  void *tmp ;
  void *tmp___0 ;
  struct mem_block *tmp___1 ;
  struct mem_block *tmp___2 ;

  {
#line 201
  tmp = drm_alloc___0(32UL, 14);
#line 201
  blocks = (struct mem_block *)tmp;
#line 203
  if ((unsigned long )blocks == (unsigned long )((struct mem_block *)0)) {
#line 204
    return (-12);
  } else {

  }
#line 206
  tmp___0 = drm_alloc___0(32UL, 14);
#line 206
  *heap = (struct mem_block *)tmp___0;
#line 207
  if ((unsigned long )*heap == (unsigned long )((struct mem_block *)0)) {
#line 208
    drm_free((void *)blocks, 32UL, 14);
#line 209
    return (-12);
  } else {

  }
#line 212
  blocks->start = start;
#line 213
  blocks->size = size;
#line 214
  blocks->file_priv = 0;
#line 215
  tmp___1 = *heap;
#line 215
  blocks->prev = tmp___1;
#line 215
  blocks->next = tmp___1;
#line 217
  memset((void *)*heap, 0, 32UL);
#line 218
  (*heap)->file_priv = 0xffffffffffffffffUL;
#line 219
  tmp___2 = blocks;
#line 219
  (*heap)->prev = tmp___2;
#line 219
  (*heap)->next = tmp___2;
#line 220
  return (0);
}
}
#line 225 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
void i915_mem_release(struct drm_device *dev , struct drm_file *file_priv , struct mem_block *heap ) 
{ 
  struct mem_block *p ;
  struct mem_block *q ;

  {
#line 230
  if ((unsigned long )heap == (unsigned long )((struct mem_block *)0) || (unsigned long )heap->next == (unsigned long )((struct mem_block *)0)) {
#line 231
    return;
  } else {

  }
#line 233
  p = heap->next;
#line 233
  goto ldv_23855;
  ldv_23854: ;
#line 234
  if ((unsigned long )p->file_priv == (unsigned long )file_priv) {
#line 235
    p->file_priv = 0;
#line 236
    mark_block(dev, p, 0);
  } else {

  }
#line 233
  p = p->next;
  ldv_23855: ;
#line 233
  if ((unsigned long )p != (unsigned long )heap) {
#line 234
    goto ldv_23854;
  } else {

  }
#line 243
  p = heap->next;
#line 243
  goto ldv_23862;
  ldv_23861: ;
#line 244
  goto ldv_23859;
  ldv_23858: 
#line 245
  q = p->next;
#line 246
  p->size = p->size + q->size;
#line 247
  p->next = q->next;
#line 248
  (p->next)->prev = p;
#line 249
  drm_free((void *)q, 32UL, 14);
  ldv_23859: ;
#line 244
  if ((unsigned long )p->file_priv == (unsigned long )((struct drm_file *)0) && (unsigned long )(p->next)->file_priv == (unsigned long )((struct drm_file *)0)) {
#line 245
    goto ldv_23858;
  } else {

  }
#line 243
  p = p->next;
  ldv_23862: ;
#line 243
  if ((unsigned long )p != (unsigned long )heap) {
#line 244
    goto ldv_23861;
  } else {

  }

#line 248
  return;
}
}
#line 256 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
void i915_mem_takedown(struct mem_block **heap ) 
{ 
  struct mem_block *p ;
  struct mem_block *q ;

  {
#line 260
  if ((unsigned long )*heap == (unsigned long )((struct mem_block *)0)) {
#line 261
    return;
  } else {

  }
#line 263
  p = (*heap)->next;
#line 263
  goto ldv_23870;
  ldv_23869: 
#line 264
  q = p;
#line 265
  p = p->next;
#line 266
  drm_free((void *)q, 32UL, 14);
  ldv_23870: ;
#line 263
  if ((unsigned long )*heap != (unsigned long )p) {
#line 264
    goto ldv_23869;
  } else {

  }
#line 269
  drm_free((void *)*heap, 32UL, 14);
#line 270
  *heap = 0;
#line 271
  return;
}
}
#line 273 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
static struct mem_block **get_heap(drm_i915_private_t *dev_priv , int region ) 
{ 


  {
#line 275
  switch (region) {
  case 1: ;
#line 277
  return (& dev_priv->agp_heap);
  default: ;
#line 279
  return (0);
  }
}
}
#line 285 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
int i915_mem_alloc(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_mem_alloc_t *alloc ;
  struct mem_block *block ;
  struct mem_block **heap ;
  unsigned long tmp ;

  {
#line 288
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 289
  alloc = (drm_i915_mem_alloc_t *)data;
#line 292
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 293
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_mem_alloc");
#line 294
    return (-22);
  } else {

  }
#line 297
  heap = get_heap(dev_priv, alloc->region);
#line 298
  if ((unsigned long )heap == (unsigned long )((struct mem_block **)0) || (unsigned long )*heap == (unsigned long )((struct mem_block *)0)) {
#line 299
    return (-14);
  } else {

  }
#line 304
  if (alloc->alignment <= 11) {
#line 305
    alloc->alignment = 12;
  } else {

  }
#line 307
  block = alloc_block(*heap, alloc->size, alloc->alignment, file_priv);
#line 309
  if ((unsigned long )block == (unsigned long )((struct mem_block *)0)) {
#line 310
    return (-12);
  } else {

  }
#line 312
  mark_block(dev, block, 1);
#line 314
  tmp = copy_to_user((void *)alloc->region_offset, (void const   *)(& block->start),
                     4U);
#line 314
  if (tmp != 0UL) {
#line 316
    printk("<3>[drm:%s] *ERROR* copy_to_user\n", "i915_mem_alloc");
#line 317
    return (-14);
  } else {

  }
#line 320
  return (0);
}
}
#line 323 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
int i915_mem_free(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_mem_free_t *memfree ;
  struct mem_block *block ;
  struct mem_block **heap ;

  {
#line 326
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 327
  memfree = (drm_i915_mem_free_t *)data;
#line 330
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 331
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_mem_free");
#line 332
    return (-22);
  } else {

  }
#line 335
  heap = get_heap(dev_priv, memfree->region);
#line 336
  if ((unsigned long )heap == (unsigned long )((struct mem_block **)0) || (unsigned long )*heap == (unsigned long )((struct mem_block *)0)) {
#line 337
    return (-14);
  } else {

  }
#line 339
  block = find_block(*heap, memfree->region_offset);
#line 340
  if ((unsigned long )block == (unsigned long )((struct mem_block *)0)) {
#line 341
    return (-14);
  } else {

  }
#line 343
  if ((unsigned long )block->file_priv != (unsigned long )file_priv) {
#line 344
    return (-1);
  } else {

  }
#line 346
  mark_block(dev, block, 0);
#line 347
  free_block(block);
#line 348
  return (0);
}
}
#line 351 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
int i915_mem_init_heap(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_mem_init_heap_t *initheap ;
  struct mem_block **heap ;
  int tmp ;

  {
#line 354
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 355
  initheap = (drm_i915_mem_init_heap_t *)data;
#line 358
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 359
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_mem_init_heap");
#line 360
    return (-22);
  } else {

  }
#line 363
  heap = get_heap(dev_priv, initheap->region);
#line 364
  if ((unsigned long )heap == (unsigned long )((struct mem_block **)0)) {
#line 365
    return (-14);
  } else {

  }
#line 367
  if ((unsigned long )*heap != (unsigned long )((struct mem_block *)0)) {
#line 368
    printk("<3>[drm:%s] *ERROR* heap already initialized?", "i915_mem_init_heap");
#line 369
    return (-14);
  } else {

  }
#line 372
  tmp = init_heap(heap, initheap->start, initheap->size);
#line 372
  return (tmp);
}
}
#line 375 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
int i915_mem_destroy_heap(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  drm_i915_mem_destroy_heap_t *destroyheap ;
  struct mem_block **heap ;

  {
#line 378
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 379
  destroyheap = (drm_i915_mem_destroy_heap_t *)data;
#line 382
  if ((unsigned long )dev_priv == (unsigned long )((drm_i915_private_t *)0)) {
#line 383
    printk("<3>[drm:%s] *ERROR* called with no initialization\n", "i915_mem_destroy_heap");
#line 384
    return (-22);
  } else {

  }
#line 387
  heap = get_heap(dev_priv, destroyheap->region);
#line 388
  if ((unsigned long )heap == (unsigned long )((struct mem_block **)0)) {
#line 389
    printk("<3>[drm:%s] *ERROR* get_heap failed", "i915_mem_destroy_heap");
#line 390
    return (-14);
  } else {

  }
#line 393
  if ((unsigned long )*heap == (unsigned long )((struct mem_block *)0)) {
#line 394
    printk("<3>[drm:%s] *ERROR* heap not initialized?", "i915_mem_destroy_heap");
#line 395
    return (-14);
  } else {

  }
#line 398
  i915_mem_takedown(heap);
#line 399
  return (0);
}
}
#line 413 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
unsigned long ldv___get_free_pages_50(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 419
  ldv_check_alloc_flags(ldv_func_arg1);
#line 421
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 421
  return (tmp);
}
}
#line 435 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
void *ldv_kmem_cache_alloc_52(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 441
  ldv_check_alloc_flags(ldv_func_arg2);
#line 443
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 444
  return ((void *)0);
}
}
#line 479 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
void *ldv_kmem_cache_alloc_56(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 485
  ldv_check_alloc_flags(ldv_func_arg2);
#line 487
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 488
  return ((void *)0);
}
}
#line 522 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_mem.c.prepared"
struct page *ldv_alloc_page_vma_60(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 529
  ldv_check_alloc_flags(ldv_func_arg1);
#line 531
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 531
  return (tmp);
}
}
#line 16 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/delay.h"
extern void __const_udelay(unsigned long  ) ;
#line 227 "include/linux/gfp.h"
struct page *ldv_alloc_page_vma_76(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) ;
#line 239
unsigned long ldv___get_free_pages_66(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 207 "include/linux/slub_def.h"
void *ldv_kmem_cache_alloc_68(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_72(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 18 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/io.h"
__inline static unsigned char readb(void const volatile   *addr ) 
{ 
  unsigned char ret ;

  {
#line 18
  __asm__  volatile   ("movb %1,%0": "=q" (ret): "m" (*((unsigned char volatile   *)addr)): "memory");
#line 18
  return (ret);
}
}
#line 26 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/io.h"
__inline static void writeb(unsigned char val , void volatile   *addr ) 
{ 


  {
#line 26
  __asm__  volatile   ("movb %0,%1": : "q" (val), "m" (*((unsigned char volatile   *)addr)): "memory");
#line 27
  return;
}
}
#line 573 "include/linux/pci.h"
extern int pci_bus_read_config_byte(struct pci_bus * , unsigned int  , int  , u8 * ) ;
#line 579
extern int pci_bus_write_config_byte(struct pci_bus * , unsigned int  , int  , u8  ) ;
#line 586 "include/linux/pci.h"
__inline static int pci_read_config_byte(struct pci_dev *dev , int where , u8 *val ) 
{ 
  int tmp ;

  {
#line 588
  tmp = pci_bus_read_config_byte(dev->bus, dev->devfn, where, val);
#line 588
  return (tmp);
}
}
#line 599 "include/linux/pci.h"
__inline static int pci_write_config_byte(struct pci_dev *dev , int where , u8 val ) 
{ 
  int tmp ;

  {
#line 601
  tmp = pci_bus_write_config_byte(dev->bus, dev->devfn, where, (int )val);
#line 601
  return (tmp);
}
}
#line 46 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
static bool i915_pipe_enabled___0(struct drm_device *dev , enum pipe pipe ) 
{ 
  struct drm_i915_private *dev_priv ;
  unsigned int tmp ;
  unsigned int tmp___0 ;

  {
#line 48
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 50
  if ((unsigned int )pipe == 0U) {
#line 51
    tmp = readl((void const volatile   *)dev_priv->regs + 24596U);
#line 51
    return ((tmp & 2147483648U) != 0U);
  } else {
#line 53
    tmp___0 = readl((void const volatile   *)dev_priv->regs + 24600U);
#line 53
    return ((tmp___0 & 2147483648U) != 0U);
  }
}
}
#line 56 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
static void i915_save_palette(struct drm_device *dev , enum pipe pipe ) 
{ 
  struct drm_i915_private *dev_priv ;
  unsigned long reg ;
  u32 *array ;
  int i ;
  bool tmp ;
  int tmp___0 ;

  {
#line 58
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 59
  reg = (unsigned int )pipe == 0U ? 40960UL : 43008UL;
#line 63
  tmp = i915_pipe_enabled___0(dev, pipe);
#line 63
  if (tmp) {
#line 63
    tmp___0 = 0;
  } else {
#line 63
    tmp___0 = 1;
  }
#line 63
  if (tmp___0) {
#line 64
    return;
  } else {

  }
#line 66
  if ((unsigned int )pipe == 0U) {
#line 67
    array = (u32 *)(& dev_priv->save_palette_a);
  } else {
#line 69
    array = (u32 *)(& dev_priv->save_palette_b);
  }
#line 71
  i = 0;
#line 71
  goto ldv_23805;
  ldv_23804: 
#line 72
  *(array + (unsigned long )i) = readl((void const volatile   *)(dev_priv->regs + ((unsigned long )(i << 2) + reg)));
#line 71
  i = i + 1;
  ldv_23805: ;
#line 71
  if (i <= 255) {
#line 72
    goto ldv_23804;
  } else {

  }

#line 76
  return;
}
}
#line 75 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
static void i915_restore_palette(struct drm_device *dev , enum pipe pipe ) 
{ 
  struct drm_i915_private *dev_priv ;
  unsigned long reg ;
  u32 *array ;
  int i ;
  bool tmp ;
  int tmp___0 ;

  {
#line 77
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 78
  reg = (unsigned int )pipe == 0U ? 40960UL : 43008UL;
#line 82
  tmp = i915_pipe_enabled___0(dev, pipe);
#line 82
  if (tmp) {
#line 82
    tmp___0 = 0;
  } else {
#line 82
    tmp___0 = 1;
  }
#line 82
  if (tmp___0) {
#line 83
    return;
  } else {

  }
#line 85
  if ((unsigned int )pipe == 0U) {
#line 86
    array = (u32 *)(& dev_priv->save_palette_a);
  } else {
#line 88
    array = (u32 *)(& dev_priv->save_palette_b);
  }
#line 90
  i = 0;
#line 90
  goto ldv_23816;
  ldv_23815: 
#line 91
  writel(*(array + (unsigned long )i), (void volatile   *)(dev_priv->regs + ((unsigned long )(i << 2) + reg)));
#line 90
  i = i + 1;
  ldv_23816: ;
#line 90
  if (i <= 255) {
#line 91
    goto ldv_23815;
  } else {

  }

#line 95
  return;
}
}
#line 94 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
static u8 i915_read_indexed(struct drm_device *dev , u16 index_port , u16 data_port ,
                            u8 reg ) 
{ 
  struct drm_i915_private *dev_priv ;
  unsigned char tmp ;

  {
#line 96
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 98
  writeb((int )reg, (void volatile   *)dev_priv->regs + (unsigned long )index_port);
#line 99
  tmp = readb((void const volatile   *)dev_priv->regs + (unsigned long )data_port);
#line 99
  return (tmp);
}
}
#line 102 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
static u8 i915_read_ar(struct drm_device *dev , u16 st01 , u8 reg , u16 palette_enable ) 
{ 
  struct drm_i915_private *dev_priv ;
  unsigned char tmp ;

  {
#line 104
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 106
  readb((void const volatile   *)dev_priv->regs + (unsigned long )st01);
#line 107
  writeb((int )((unsigned char )palette_enable) | (int )reg, (void volatile   *)dev_priv->regs + 960U);
#line 108
  tmp = readb((void const volatile   *)dev_priv->regs + 961U);
#line 108
  return (tmp);
}
}
#line 111 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
static void i915_write_ar(struct drm_device *dev , u16 st01 , u8 reg , u8 val , u16 palette_enable ) 
{ 
  struct drm_i915_private *dev_priv ;

  {
#line 113
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 115
  readb((void const volatile   *)dev_priv->regs + (unsigned long )st01);
#line 116
  writeb((int )((unsigned char )palette_enable) | (int )reg, (void volatile   *)dev_priv->regs + 960U);
#line 117
  writeb((int )val, (void volatile   *)dev_priv->regs + 960U);
#line 118
  return;
}
}
#line 120 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
static void i915_write_indexed(struct drm_device *dev , u16 index_port , u16 data_port ,
                               u8 reg , u8 val ) 
{ 
  struct drm_i915_private *dev_priv ;

  {
#line 122
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 124
  writeb((int )reg, (void volatile   *)dev_priv->regs + (unsigned long )index_port);
#line 125
  writeb((int )val, (void volatile   *)dev_priv->regs + (unsigned long )data_port);
#line 126
  return;
}
}
#line 128 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
static void i915_save_vga(struct drm_device *dev ) 
{ 
  struct drm_i915_private *dev_priv ;
  int i ;
  u16 cr_index ;
  u16 cr_data ;
  u16 st01 ;
  u8 tmp ;

  {
#line 130
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 135
  dev_priv->saveDACMASK = readb((void const volatile   *)dev_priv->regs + 966U);
#line 137
  writeb(0, (void volatile   *)dev_priv->regs + 967U);
#line 139
  i = 0;
#line 139
  goto ldv_23857;
  ldv_23856: 
#line 140
  dev_priv->saveDACDATA[i] = readb((void const volatile   *)dev_priv->regs + 969U);
#line 139
  i = i + 1;
  ldv_23857: ;
#line 139
  if (i <= 767) {
#line 140
    goto ldv_23856;
  } else {

  }
#line 143
  dev_priv->saveMSR = readb((void const volatile   *)dev_priv->regs + 972U);
#line 144
  if ((int )dev_priv->saveMSR & 1) {
#line 145
    cr_index = 980U;
#line 146
    cr_data = 981U;
#line 147
    st01 = 986U;
  } else {
#line 149
    cr_index = 948U;
#line 150
    cr_data = 949U;
#line 151
    st01 = 954U;
  }
#line 155
  tmp = i915_read_indexed(dev, (int )cr_index, (int )cr_data, 17);
#line 155
  i915_write_indexed(dev, (int )cr_index, (int )cr_data, 17, (int )tmp & 127);
#line 158
  i = 0;
#line 158
  goto ldv_23860;
  ldv_23859: 
#line 159
  dev_priv->saveCR[i] = i915_read_indexed(dev, (int )cr_index, (int )cr_data, (int )((u8 )i));
#line 158
  i = i + 1;
  ldv_23860: ;
#line 158
  if (i <= 36) {
#line 159
    goto ldv_23859;
  } else {

  }
#line 162
  dev_priv->saveCR[17] = (unsigned int )dev_priv->saveCR[17] & 127U;
#line 165
  readb((void const volatile   *)dev_priv->regs + (unsigned long )st01);
#line 166
  dev_priv->saveAR_INDEX = readb((void const volatile   *)dev_priv->regs + 960U);
#line 167
  i = 0;
#line 167
  goto ldv_23863;
  ldv_23862: 
#line 168
  dev_priv->saveAR[i] = i915_read_ar(dev, (int )st01, (int )((u8 )i), 0);
#line 167
  i = i + 1;
  ldv_23863: ;
#line 167
  if (i <= 20) {
#line 168
    goto ldv_23862;
  } else {

  }
#line 169
  readb((void const volatile   *)dev_priv->regs + (unsigned long )st01);
#line 170
  writeb((int )dev_priv->saveAR_INDEX, (void volatile   *)dev_priv->regs + 960U);
#line 171
  readb((void const volatile   *)dev_priv->regs + (unsigned long )st01);
#line 174
  i = 0;
#line 174
  goto ldv_23866;
  ldv_23865: 
#line 175
  dev_priv->saveGR[i] = i915_read_indexed(dev, 974, 975, (int )((u8 )i));
#line 174
  i = i + 1;
  ldv_23866: ;
#line 174
  if (i <= 8) {
#line 175
    goto ldv_23865;
  } else {

  }
#line 178
  dev_priv->saveGR[16] = i915_read_indexed(dev, 974, 975, 16);
#line 180
  dev_priv->saveGR[17] = i915_read_indexed(dev, 974, 975, 17);
#line 182
  dev_priv->saveGR[24] = i915_read_indexed(dev, 974, 975, 24);
#line 186
  i = 0;
#line 186
  goto ldv_23869;
  ldv_23868: 
#line 187
  dev_priv->saveSR[i] = i915_read_indexed(dev, 964, 965, (int )((u8 )i));
#line 186
  i = i + 1;
  ldv_23869: ;
#line 186
  if (i <= 7) {
#line 187
    goto ldv_23868;
  } else {

  }

#line 191
  return;
}
}
#line 191 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
static void i915_restore_vga(struct drm_device *dev ) 
{ 
  struct drm_i915_private *dev_priv ;
  int i ;
  u16 cr_index ;
  u16 cr_data ;
  u16 st01 ;

  {
#line 193
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 198
  writeb((int )dev_priv->saveMSR, (void volatile   *)dev_priv->regs + 962U);
#line 199
  if ((int )dev_priv->saveMSR & 1) {
#line 200
    cr_index = 980U;
#line 201
    cr_data = 981U;
#line 202
    st01 = 986U;
  } else {
#line 204
    cr_index = 948U;
#line 205
    cr_data = 949U;
#line 206
    st01 = 954U;
  }
#line 210
  i = 0;
#line 210
  goto ldv_23880;
  ldv_23879: 
#line 211
  i915_write_indexed(dev, 964, 965, (int )((u8 )i), (int )dev_priv->saveSR[i]);
#line 210
  i = i + 1;
  ldv_23880: ;
#line 210
  if (i <= 6) {
#line 211
    goto ldv_23879;
  } else {

  }
#line 216
  i915_write_indexed(dev, (int )cr_index, (int )cr_data, 17, (int )dev_priv->saveCR[17]);
#line 217
  i = 0;
#line 217
  goto ldv_23883;
  ldv_23882: 
#line 218
  i915_write_indexed(dev, (int )cr_index, (int )cr_data, (int )((u8 )i), (int )dev_priv->saveCR[i]);
#line 217
  i = i + 1;
  ldv_23883: ;
#line 217
  if (i <= 36) {
#line 218
    goto ldv_23882;
  } else {

  }
#line 221
  i = 0;
#line 221
  goto ldv_23886;
  ldv_23885: 
#line 222
  i915_write_indexed(dev, 974, 975, (int )((u8 )i), (int )dev_priv->saveGR[i]);
#line 221
  i = i + 1;
  ldv_23886: ;
#line 221
  if (i <= 8) {
#line 222
    goto ldv_23885;
  } else {

  }
#line 225
  i915_write_indexed(dev, 974, 975, 16, (int )dev_priv->saveGR[16]);
#line 227
  i915_write_indexed(dev, 974, 975, 17, (int )dev_priv->saveGR[17]);
#line 229
  i915_write_indexed(dev, 974, 975, 24, (int )dev_priv->saveGR[24]);
#line 233
  readb((void const volatile   *)dev_priv->regs + (unsigned long )st01);
#line 234
  i = 0;
#line 234
  goto ldv_23889;
  ldv_23888: 
#line 235
  i915_write_ar(dev, (int )st01, (int )((u8 )i), (int )dev_priv->saveAR[i], 0);
#line 234
  i = i + 1;
  ldv_23889: ;
#line 234
  if (i <= 20) {
#line 235
    goto ldv_23888;
  } else {

  }
#line 236
  readb((void const volatile   *)dev_priv->regs + (unsigned long )st01);
#line 237
  writeb((int )((unsigned int )dev_priv->saveAR_INDEX | 32U), (void volatile   *)dev_priv->regs + 960U);
#line 238
  readb((void const volatile   *)dev_priv->regs + (unsigned long )st01);
#line 241
  writeb((int )dev_priv->saveDACMASK, (void volatile   *)dev_priv->regs + 966U);
#line 243
  writeb(0, (void volatile   *)dev_priv->regs + 968U);
#line 245
  i = 0;
#line 245
  goto ldv_23892;
  ldv_23891: 
#line 246
  writeb((int )dev_priv->saveDACDATA[i], (void volatile   *)dev_priv->regs + 969U);
#line 245
  i = i + 1;
  ldv_23892: ;
#line 245
  if (i <= 767) {
#line 246
    goto ldv_23891;
  } else {

  }

#line 250
  return;
}
}
#line 250 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
int i915_save_state(struct drm_device *dev ) 
{ 
  struct drm_i915_private *dev_priv ;
  int i ;

  {
#line 252
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 255
  pci_read_config_byte(dev->pdev, 244, & dev_priv->saveLBB);
#line 258
  if ((((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) && (((((dev->pci_device == 13687 || dev->pci_device == 13698) || dev->pci_device == 9618) || (dev->pci_device == 10146 || dev->pci_device == 10158)) || dev->pci_device == 10754) || dev->pci_device == 10818)) {
#line 259
    dev_priv->saveRENDERSTANDBY = readl((void const volatile   *)dev_priv->regs + 70072U);
  } else {

  }
#line 262
  dev_priv->saveHWS = readl((void const volatile   *)dev_priv->regs + 8320U);
#line 265
  dev_priv->saveDSPARB = readl((void const volatile   *)dev_priv->regs + 458800U);
#line 268
  dev_priv->savePIPEACONF = readl((void const volatile   *)dev_priv->regs + 458760U);
#line 269
  dev_priv->savePIPEASRC = readl((void const volatile   *)dev_priv->regs + 393244U);
#line 270
  dev_priv->saveFPA0 = readl((void const volatile   *)dev_priv->regs + 24640U);
#line 271
  dev_priv->saveFPA1 = readl((void const volatile   *)dev_priv->regs + 24644U);
#line 272
  dev_priv->saveDPLL_A = readl((void const volatile   *)dev_priv->regs + 24596U);
#line 273
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 274
    dev_priv->saveDPLL_A_MD = readl((void const volatile   *)dev_priv->regs + 24604U);
  } else {

  }
#line 275
  dev_priv->saveHTOTAL_A = readl((void const volatile   *)dev_priv->regs + 393216U);
#line 276
  dev_priv->saveHBLANK_A = readl((void const volatile   *)dev_priv->regs + 393220U);
#line 277
  dev_priv->saveHSYNC_A = readl((void const volatile   *)dev_priv->regs + 393224U);
#line 278
  dev_priv->saveVTOTAL_A = readl((void const volatile   *)dev_priv->regs + 393228U);
#line 279
  dev_priv->saveVBLANK_A = readl((void const volatile   *)dev_priv->regs + 393232U);
#line 280
  dev_priv->saveVSYNC_A = readl((void const volatile   *)dev_priv->regs + 393236U);
#line 281
  dev_priv->saveBCLRPAT_A = readl((void const volatile   *)dev_priv->regs + 393248U);
#line 283
  dev_priv->saveDSPACNTR = readl((void const volatile   *)dev_priv->regs + 459136U);
#line 284
  dev_priv->saveDSPASTRIDE = readl((void const volatile   *)dev_priv->regs + 459144U);
#line 285
  dev_priv->saveDSPASIZE = readl((void const volatile   *)dev_priv->regs + 459152U);
#line 286
  dev_priv->saveDSPAPOS = readl((void const volatile   *)dev_priv->regs + 459148U);
#line 287
  dev_priv->saveDSPAADDR = readl((void const volatile   *)dev_priv->regs + 459140U);
#line 288
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 289
    dev_priv->saveDSPASURF = readl((void const volatile   *)dev_priv->regs + 459164U);
#line 290
    dev_priv->saveDSPATILEOFF = readl((void const volatile   *)dev_priv->regs + 459172U);
  } else {

  }
#line 292
  i915_save_palette(dev, PIPE_A);
#line 293
  dev_priv->savePIPEASTAT = readl((void const volatile   *)dev_priv->regs + 458788U);
#line 296
  dev_priv->savePIPEBCONF = readl((void const volatile   *)dev_priv->regs + 462856U);
#line 297
  dev_priv->savePIPEBSRC = readl((void const volatile   *)dev_priv->regs + 397340U);
#line 298
  dev_priv->saveFPB0 = readl((void const volatile   *)dev_priv->regs + 24648U);
#line 299
  dev_priv->saveFPB1 = readl((void const volatile   *)dev_priv->regs + 24652U);
#line 300
  dev_priv->saveDPLL_B = readl((void const volatile   *)dev_priv->regs + 24600U);
#line 301
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 302
    dev_priv->saveDPLL_B_MD = readl((void const volatile   *)dev_priv->regs + 24608U);
  } else {

  }
#line 303
  dev_priv->saveHTOTAL_B = readl((void const volatile   *)dev_priv->regs + 397312U);
#line 304
  dev_priv->saveHBLANK_B = readl((void const volatile   *)dev_priv->regs + 397316U);
#line 305
  dev_priv->saveHSYNC_B = readl((void const volatile   *)dev_priv->regs + 397320U);
#line 306
  dev_priv->saveVTOTAL_B = readl((void const volatile   *)dev_priv->regs + 397324U);
#line 307
  dev_priv->saveVBLANK_B = readl((void const volatile   *)dev_priv->regs + 397328U);
#line 308
  dev_priv->saveVSYNC_B = readl((void const volatile   *)dev_priv->regs + 397332U);
#line 309
  dev_priv->saveBCLRPAT_A = readl((void const volatile   *)dev_priv->regs + 393248U);
#line 311
  dev_priv->saveDSPBCNTR = readl((void const volatile   *)dev_priv->regs + 463232U);
#line 312
  dev_priv->saveDSPBSTRIDE = readl((void const volatile   *)dev_priv->regs + 463240U);
#line 313
  dev_priv->saveDSPBSIZE = readl((void const volatile   *)dev_priv->regs + 463248U);
#line 314
  dev_priv->saveDSPBPOS = readl((void const volatile   *)dev_priv->regs + 463244U);
#line 315
  dev_priv->saveDSPBADDR = readl((void const volatile   *)dev_priv->regs + 463236U);
#line 316
  if (dev->pci_device == 10754 || dev->pci_device == 10818) {
#line 317
    dev_priv->saveDSPBSURF = readl((void const volatile   *)dev_priv->regs + 463260U);
#line 318
    dev_priv->saveDSPBTILEOFF = readl((void const volatile   *)dev_priv->regs + 463268U);
  } else {

  }
#line 320
  i915_save_palette(dev, PIPE_B);
#line 321
  dev_priv->savePIPEBSTAT = readl((void const volatile   *)dev_priv->regs + 462884U);
#line 324
  dev_priv->saveADPA = readl((void const volatile   *)dev_priv->regs + 397568U);
#line 327
  dev_priv->savePP_CONTROL = readl((void const volatile   *)dev_priv->regs + 397828U);
#line 328
  dev_priv->savePFIT_PGM_RATIOS = readl((void const volatile   *)dev_priv->regs + 397876U);
#line 329
  dev_priv->saveBLC_PWM_CTL = readl((void const volatile   *)dev_priv->regs + 397908U);
#line 330
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 331
    dev_priv->saveBLC_PWM_CTL2 = readl((void const volatile   *)dev_priv->regs + 397904U);
  } else {

  }
#line 332
  if ((((((dev->pci_device == 13687 || dev->pci_device == 13698) || dev->pci_device == 9618) || (dev->pci_device == 10146 || dev->pci_device == 10158)) || dev->pci_device == 10754) || dev->pci_device == 10818) && dev->pci_device != 13687) {
#line 333
    dev_priv->saveLVDS = readl((void const volatile   *)dev_priv->regs + 397696U);
  } else {

  }
#line 334
  if (dev->pci_device != 13687 && dev->pci_device != 9570) {
#line 335
    dev_priv->savePFIT_CONTROL = readl((void const volatile   *)dev_priv->regs + 397872U);
  } else {

  }
#line 336
  dev_priv->savePP_ON_DELAYS = readl((void const volatile   *)dev_priv->regs + 397832U);
#line 337
  dev_priv->savePP_OFF_DELAYS = readl((void const volatile   *)dev_priv->regs + 397836U);
#line 338
  dev_priv->savePP_DIVISOR = readl((void const volatile   *)dev_priv->regs + 397840U);
#line 343
  dev_priv->saveFBC_CFB_BASE = readl((void const volatile   *)dev_priv->regs + 12800U);
#line 344
  dev_priv->saveFBC_LL_BASE = readl((void const volatile   *)dev_priv->regs + 12804U);
#line 345
  dev_priv->saveFBC_CONTROL2 = readl((void const volatile   *)dev_priv->regs + 12820U);
#line 346
  dev_priv->saveFBC_CONTROL = readl((void const volatile   *)dev_priv->regs + 12808U);
#line 349
  dev_priv->saveIIR = readl((void const volatile   *)dev_priv->regs + 8356U);
#line 350
  dev_priv->saveIER = readl((void const volatile   *)dev_priv->regs + 8352U);
#line 351
  dev_priv->saveIMR = readl((void const volatile   *)dev_priv->regs + 8360U);
#line 354
  dev_priv->saveVGA0 = readl((void const volatile   *)dev_priv->regs + 24576U);
#line 355
  dev_priv->saveVGA1 = readl((void const volatile   *)dev_priv->regs + 24580U);
#line 356
  dev_priv->saveVGA_PD = readl((void const volatile   *)dev_priv->regs + 24592U);
#line 357
  dev_priv->saveVGACNTRL = readl((void const volatile   *)dev_priv->regs + 463872U);
#line 360
  dev_priv->saveD_STATE = readl((void const volatile   *)dev_priv->regs + 24836U);
#line 361
  dev_priv->saveCG_2D_DIS = readl((void const volatile   *)dev_priv->regs + 25088U);
#line 364
  dev_priv->saveCACHE_MODE_0 = readl((void const volatile   *)dev_priv->regs + 8480U);
#line 367
  dev_priv->saveMI_ARB_STATE = readl((void const volatile   *)dev_priv->regs + 8420U);
#line 370
  i = 0;
#line 370
  goto ldv_23900;
  ldv_23899: 
#line 371
  dev_priv->saveSWF0[i] = readl((void const volatile   *)dev_priv->regs + (unsigned long )((i << 2) + 463888));
#line 372
  dev_priv->saveSWF1[i] = readl((void const volatile   *)dev_priv->regs + (unsigned long )((i << 2) + 459792));
#line 370
  i = i + 1;
  ldv_23900: ;
#line 370
  if (i <= 15) {
#line 371
    goto ldv_23899;
  } else {

  }
#line 374
  i = 0;
#line 374
  goto ldv_23903;
  ldv_23902: 
#line 375
  dev_priv->saveSWF2[i] = readl((void const volatile   *)dev_priv->regs + (unsigned long )((i << 2) + 467988));
#line 374
  i = i + 1;
  ldv_23903: ;
#line 374
  if (i <= 2) {
#line 375
    goto ldv_23902;
  } else {

  }
#line 377
  i915_save_vga(dev);
#line 379
  return (0);
}
}
#line 382 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
int i915_restore_state(struct drm_device *dev ) 
{ 
  struct drm_i915_private *dev_priv ;
  int i ;
  unsigned int tmp ;
  unsigned int tmp___0 ;

  {
#line 384
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 387
  pci_write_config_byte(dev->pdev, 244, (int )dev_priv->saveLBB);
#line 390
  if ((((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) && (((((dev->pci_device == 13687 || dev->pci_device == 13698) || dev->pci_device == 9618) || (dev->pci_device == 10146 || dev->pci_device == 10158)) || dev->pci_device == 10754) || dev->pci_device == 10818)) {
#line 391
    writel(dev_priv->saveRENDERSTANDBY, (void volatile   *)dev_priv->regs + 70072U);
  } else {

  }
#line 394
  writel(dev_priv->saveHWS, (void volatile   *)dev_priv->regs + 8320U);
#line 397
  writel(dev_priv->saveDSPARB, (void volatile   *)dev_priv->regs + 458800U);
#line 401
  if ((int )dev_priv->saveDPLL_A < 0) {
#line 402
    writel(dev_priv->saveDPLL_A & 2147483647U, (void volatile   *)dev_priv->regs + 24596U);
#line 404
    __const_udelay(644250UL);
  } else {

  }
#line 406
  writel(dev_priv->saveFPA0, (void volatile   *)dev_priv->regs + 24640U);
#line 407
  writel(dev_priv->saveFPA1, (void volatile   *)dev_priv->regs + 24644U);
#line 409
  writel(dev_priv->saveDPLL_A, (void volatile   *)dev_priv->regs + 24596U);
#line 410
  __const_udelay(644250UL);
#line 411
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 412
    writel(dev_priv->saveDPLL_A_MD, (void volatile   *)dev_priv->regs + 24604U);
  } else {

  }
#line 413
  __const_udelay(644250UL);
#line 416
  writel(dev_priv->saveHTOTAL_A, (void volatile   *)dev_priv->regs + 393216U);
#line 417
  writel(dev_priv->saveHBLANK_A, (void volatile   *)dev_priv->regs + 393220U);
#line 418
  writel(dev_priv->saveHSYNC_A, (void volatile   *)dev_priv->regs + 393224U);
#line 419
  writel(dev_priv->saveVTOTAL_A, (void volatile   *)dev_priv->regs + 393228U);
#line 420
  writel(dev_priv->saveVBLANK_A, (void volatile   *)dev_priv->regs + 393232U);
#line 421
  writel(dev_priv->saveVSYNC_A, (void volatile   *)dev_priv->regs + 393236U);
#line 422
  writel(dev_priv->saveBCLRPAT_A, (void volatile   *)dev_priv->regs + 393248U);
#line 425
  writel(dev_priv->saveDSPASIZE, (void volatile   *)dev_priv->regs + 459152U);
#line 426
  writel(dev_priv->saveDSPAPOS, (void volatile   *)dev_priv->regs + 459148U);
#line 427
  writel(dev_priv->savePIPEASRC, (void volatile   *)dev_priv->regs + 393244U);
#line 428
  writel(dev_priv->saveDSPAADDR, (void volatile   *)dev_priv->regs + 459140U);
#line 429
  writel(dev_priv->saveDSPASTRIDE, (void volatile   *)dev_priv->regs + 459144U);
#line 430
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 431
    writel(dev_priv->saveDSPASURF, (void volatile   *)dev_priv->regs + 459164U);
#line 432
    writel(dev_priv->saveDSPATILEOFF, (void volatile   *)dev_priv->regs + 459172U);
  } else {

  }
#line 435
  writel(dev_priv->savePIPEACONF, (void volatile   *)dev_priv->regs + 458760U);
#line 437
  i915_restore_palette(dev, PIPE_A);
#line 439
  writel(dev_priv->saveDSPACNTR, (void volatile   *)dev_priv->regs + 459136U);
#line 440
  tmp = readl((void const volatile   *)dev_priv->regs + 459140U);
#line 440
  writel(tmp, (void volatile   *)dev_priv->regs + 459140U);
#line 443
  if ((int )dev_priv->saveDPLL_B < 0) {
#line 444
    writel(dev_priv->saveDPLL_B & 2147483647U, (void volatile   *)dev_priv->regs + 24600U);
#line 446
    __const_udelay(644250UL);
  } else {

  }
#line 448
  writel(dev_priv->saveFPB0, (void volatile   *)dev_priv->regs + 24648U);
#line 449
  writel(dev_priv->saveFPB1, (void volatile   *)dev_priv->regs + 24652U);
#line 451
  writel(dev_priv->saveDPLL_B, (void volatile   *)dev_priv->regs + 24600U);
#line 452
  __const_udelay(644250UL);
#line 453
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 454
    writel(dev_priv->saveDPLL_B_MD, (void volatile   *)dev_priv->regs + 24608U);
  } else {

  }
#line 455
  __const_udelay(644250UL);
#line 458
  writel(dev_priv->saveHTOTAL_B, (void volatile   *)dev_priv->regs + 397312U);
#line 459
  writel(dev_priv->saveHBLANK_B, (void volatile   *)dev_priv->regs + 397316U);
#line 460
  writel(dev_priv->saveHSYNC_B, (void volatile   *)dev_priv->regs + 397320U);
#line 461
  writel(dev_priv->saveVTOTAL_B, (void volatile   *)dev_priv->regs + 397324U);
#line 462
  writel(dev_priv->saveVBLANK_B, (void volatile   *)dev_priv->regs + 397328U);
#line 463
  writel(dev_priv->saveVSYNC_B, (void volatile   *)dev_priv->regs + 397332U);
#line 464
  writel(dev_priv->saveBCLRPAT_B, (void volatile   *)dev_priv->regs + 397344U);
#line 467
  writel(dev_priv->saveDSPBSIZE, (void volatile   *)dev_priv->regs + 463248U);
#line 468
  writel(dev_priv->saveDSPBPOS, (void volatile   *)dev_priv->regs + 463244U);
#line 469
  writel(dev_priv->savePIPEBSRC, (void volatile   *)dev_priv->regs + 397340U);
#line 470
  writel(dev_priv->saveDSPBADDR, (void volatile   *)dev_priv->regs + 463236U);
#line 471
  writel(dev_priv->saveDSPBSTRIDE, (void volatile   *)dev_priv->regs + 463240U);
#line 472
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 473
    writel(dev_priv->saveDSPBSURF, (void volatile   *)dev_priv->regs + 463260U);
#line 474
    writel(dev_priv->saveDSPBTILEOFF, (void volatile   *)dev_priv->regs + 463268U);
  } else {

  }
#line 477
  writel(dev_priv->savePIPEBCONF, (void volatile   *)dev_priv->regs + 462856U);
#line 479
  i915_restore_palette(dev, PIPE_B);
#line 481
  writel(dev_priv->saveDSPBCNTR, (void volatile   *)dev_priv->regs + 463232U);
#line 482
  tmp___0 = readl((void const volatile   *)dev_priv->regs + 463236U);
#line 482
  writel(tmp___0, (void volatile   *)dev_priv->regs + 463236U);
#line 485
  writel(dev_priv->saveADPA, (void volatile   *)dev_priv->regs + 397568U);
#line 488
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 489
    writel(dev_priv->saveBLC_PWM_CTL2, (void volatile   *)dev_priv->regs + 397904U);
  } else {

  }
#line 490
  if ((((((dev->pci_device == 13687 || dev->pci_device == 13698) || dev->pci_device == 9618) || (dev->pci_device == 10146 || dev->pci_device == 10158)) || dev->pci_device == 10754) || dev->pci_device == 10818) && dev->pci_device != 13687) {
#line 491
    writel(dev_priv->saveLVDS, (void volatile   *)dev_priv->regs + 397696U);
  } else {

  }
#line 492
  if (dev->pci_device != 13687 && dev->pci_device != 9570) {
#line 493
    writel(dev_priv->savePFIT_CONTROL, (void volatile   *)dev_priv->regs + 397872U);
  } else {

  }
#line 495
  writel(dev_priv->savePFIT_PGM_RATIOS, (void volatile   *)dev_priv->regs + 397876U);
#line 496
  writel(dev_priv->saveBLC_PWM_CTL, (void volatile   *)dev_priv->regs + 397908U);
#line 497
  writel(dev_priv->savePP_ON_DELAYS, (void volatile   *)dev_priv->regs + 397832U);
#line 498
  writel(dev_priv->savePP_OFF_DELAYS, (void volatile   *)dev_priv->regs + 397836U);
#line 499
  writel(dev_priv->savePP_DIVISOR, (void volatile   *)dev_priv->regs + 397840U);
#line 500
  writel(dev_priv->savePP_CONTROL, (void volatile   *)dev_priv->regs + 397828U);
#line 505
  writel(dev_priv->saveFBC_CFB_BASE, (void volatile   *)dev_priv->regs + 12800U);
#line 506
  writel(dev_priv->saveFBC_LL_BASE, (void volatile   *)dev_priv->regs + 12804U);
#line 507
  writel(dev_priv->saveFBC_CONTROL2, (void volatile   *)dev_priv->regs + 12820U);
#line 508
  writel(dev_priv->saveFBC_CONTROL, (void volatile   *)dev_priv->regs + 12808U);
#line 511
  writel(dev_priv->saveVGACNTRL, (void volatile   *)dev_priv->regs + 463872U);
#line 512
  writel(dev_priv->saveVGA0, (void volatile   *)dev_priv->regs + 24576U);
#line 513
  writel(dev_priv->saveVGA1, (void volatile   *)dev_priv->regs + 24580U);
#line 514
  writel(dev_priv->saveVGA_PD, (void volatile   *)dev_priv->regs + 24592U);
#line 515
  __const_udelay(644250UL);
#line 518
  writel(dev_priv->saveD_STATE, (void volatile   *)dev_priv->regs + 24836U);
#line 519
  writel(dev_priv->saveCG_2D_DIS, (void volatile   *)dev_priv->regs + 25088U);
#line 522
  writel(dev_priv->saveCACHE_MODE_0 | 4294901760U, (void volatile   *)dev_priv->regs + 8480U);
#line 525
  writel(dev_priv->saveMI_ARB_STATE | 4294901760U, (void volatile   *)dev_priv->regs + 8420U);
#line 527
  i = 0;
#line 527
  goto ldv_23911;
  ldv_23910: 
#line 528
  writel(dev_priv->saveSWF0[i], (void volatile   *)dev_priv->regs + (unsigned long )((i << 2) + 463888));
#line 529
  writel(dev_priv->saveSWF1[i + 7], (void volatile   *)dev_priv->regs + (unsigned long )((i << 2) + 459792));
#line 527
  i = i + 1;
  ldv_23911: ;
#line 527
  if (i <= 15) {
#line 528
    goto ldv_23910;
  } else {

  }
#line 531
  i = 0;
#line 531
  goto ldv_23914;
  ldv_23913: 
#line 532
  writel(dev_priv->saveSWF2[i], (void volatile   *)dev_priv->regs + (unsigned long )((i << 2) + 467988));
#line 531
  i = i + 1;
  ldv_23914: ;
#line 531
  if (i <= 2) {
#line 532
    goto ldv_23913;
  } else {

  }
#line 534
  i915_restore_vga(dev);
#line 536
  return (0);
}
}
#line 550 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
unsigned long ldv___get_free_pages_66(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 556
  ldv_check_alloc_flags(ldv_func_arg1);
#line 558
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 558
  return (tmp);
}
}
#line 572 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
void *ldv_kmem_cache_alloc_68(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 578
  ldv_check_alloc_flags(ldv_func_arg2);
#line 580
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 581
  return ((void *)0);
}
}
#line 616 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
void *ldv_kmem_cache_alloc_72(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 622
  ldv_check_alloc_flags(ldv_func_arg2);
#line 624
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 625
  return ((void *)0);
}
}
#line 659 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_suspend.c.prepared"
struct page *ldv_alloc_page_vma_76(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 666
  ldv_check_alloc_flags(ldv_func_arg1);
#line 668
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 668
  return (tmp);
}
}
#line 36 "include/asm-generic/bug.h"
extern void warn_on_slowpath(char const   * , int const    ) ;
#line 120 "include/linux/kernel.h"
extern void __might_sleep(char * , int  ) ;
#line 28 "include/linux/list.h"
__inline static void INIT_LIST_HEAD(struct list_head *list ) 
{ 


  {
#line 30
  list->next = list;
#line 31
  list->prev = list;
#line 32
  return;
}
}
#line 51
extern void __list_add(struct list_head * , struct list_head * , struct list_head * ) ;
#line 78 "include/linux/list.h"
__inline static void list_add_tail(struct list_head *new , struct list_head *head ) 
{ 


  {
#line 80
  __list_add(new, head->prev, head);
#line 81
  return;
}
}
#line 90 "include/linux/list.h"
__inline static void __list_del(struct list_head *prev , struct list_head *next ) 
{ 


  {
#line 92
  next->prev = prev;
#line 93
  prev->next = next;
#line 94
  return;
}
}
#line 110
extern void list_del(struct list_head * ) ;
#line 140 "include/linux/list.h"
__inline static void list_del_init(struct list_head *entry ) 
{ 


  {
#line 142
  __list_del(entry->prev, entry->next);
#line 143
  INIT_LIST_HEAD(entry);
#line 144
  return;
}
}
#line 162 "include/linux/list.h"
__inline static void list_move_tail(struct list_head *list , struct list_head *head ) 
{ 


  {
#line 165
  __list_del(list->prev, list->next);
#line 166
  list_add_tail(list, head);
#line 167
  return;
}
}
#line 184 "include/linux/list.h"
__inline static int list_empty(struct list_head  const  *head ) 
{ 


  {
#line 186
  return ((unsigned long )((struct list_head  const  *)head->next) == (unsigned long )head);
}
}
#line 264 "include/linux/lockdep.h"
extern void lockdep_init_map(struct lockdep_map * , char const   * , struct lock_class_key * ,
                             int  ) ;
#line 49 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic_64.h"
__inline static void atomic_add(int i , atomic_t *v ) 
{ 


  {
#line 51
  __asm__  volatile   (".section .smp_locks,\"a\"\n .balign 8 \n .quad 661f\n.previous\n661:\n\tlock; addl %1,%0": "=m" (v->counter): "ir" (i),
                       "m" (v->counter));
#line 54
  return;
}
}
#line 63 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic_64.h"
__inline static void atomic_sub(int i , atomic_t *v ) 
{ 


  {
#line 65
  __asm__  volatile   (".section .smp_locks,\"a\"\n .balign 8 \n .quad 661f\n.previous\n661:\n\tlock; subl %1,%0": "=m" (v->counter): "ir" (i),
                       "m" (v->counter));
#line 68
  return;
}
}
#line 108 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/atomic_64.h"
__inline static void atomic_dec(atomic_t *v ) 
{ 


  {
#line 110
  __asm__  volatile   (".section .smp_locks,\"a\"\n .balign 8 \n .quad 661f\n.previous\n661:\n\tlock; decl %0": "=m" (v->counter): "m" (v->counter));
#line 113
  return;
}
}
#line 431 "include/linux/wait.h"
extern void prepare_to_wait(wait_queue_head_t * , wait_queue_t * , int  ) ;
#line 433
extern void finish_wait(wait_queue_head_t * , wait_queue_t * ) ;
#line 434
extern int autoremove_wake_function(wait_queue_t * , unsigned int  , int  , void * ) ;
#line 38 "include/linux/rwsem.h"
extern void down_write(struct rw_semaphore * ) ;
#line 53
extern void up_write(struct rw_semaphore * ) ;
#line 46 "include/linux/delay.h"
extern void msleep(unsigned int  ) ;
#line 227 "include/linux/gfp.h"
struct page *ldv_alloc_page_vma_92(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) ;
#line 239
unsigned long ldv___get_free_pages_82(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 27 "include/linux/kref.h"
extern void kref_get(struct kref * ) ;
#line 28
extern int kref_put(struct kref * , void (*)(struct kref * ) ) ;
#line 40 "include/linux/timer.h"
extern void init_timer(struct timer_list * ) ;
#line 196 "include/linux/workqueue.h"
extern int schedule_delayed_work(struct delayed_work * , unsigned long  ) ;
#line 226
extern int cancel_delayed_work_sync(struct delayed_work * ) ;
#line 207 "include/linux/slub_def.h"
void *ldv_kmem_cache_alloc_84(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_88(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 210 "include/linux/slab.h"
__inline static void *ldv_kcalloc_86(size_t n , size_t size , gfp_t flags ) 
{ 
  void *tmp ;

  {
#line 212
  if (size != 0UL && 0xffffffffffffffffUL / size < n) {
#line 213
    return (0);
  } else {

  }
#line 214
  tmp = __kmalloc(n * size, flags | 32768U);
#line 214
  return (tmp);
}
}
#line 210
__inline static void *kcalloc(size_t n , size_t size , gfp_t flags ) ;
#line 1346 "include/linux/fs.h"
extern ssize_t vfs_read(struct file * , char * , size_t  , loff_t * ) ;
#line 1347
extern ssize_t vfs_write(struct file * , char const   * , size_t  , loff_t * ) ;
#line 27 "include/linux/err.h"
__inline static long PTR_ERR(void const   *ptr ) 
{ 


  {
#line 29
  return ((long )ptr);
}
}
#line 32 "include/linux/err.h"
__inline static long IS_ERR(void const   *ptr ) 
{ 
  long tmp ;

  {
#line 34
  tmp = __builtin_expect((unsigned long )ptr > 0xfffffffffffff000UL, 0L);
#line 34
  return (tmp);
}
}
#line 75 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/io.h"
extern void *ioremap_wc(unsigned long  , unsigned long  ) ;
#line 315 "include/linux/mm.h"
extern void put_page(struct page * ) ;
#line 589 "include/linux/mm.h"
__inline static void *lowmem_page_address(struct page *page ) 
{ 


  {
#line 591
  return ((void *)((unsigned long )(((long )page + 32985348833280L) / 96L << 12) + 0xffff880000000000UL));
}
}
#line 823
extern int set_page_dirty(struct page * ) ;
#line 1110
extern unsigned long do_mmap_pgoff(struct file * , unsigned long  , unsigned long  ,
                                   unsigned long  , unsigned long  , unsigned long  ) ;
#line 1118 "include/linux/mm.h"
__inline static unsigned long do_mmap(struct file *file , unsigned long addr , unsigned long len ,
                                      unsigned long prot , unsigned long flag , unsigned long offset ) 
{ 
  unsigned long ret ;

  {
#line 1122
  ret = 0xffffffffffffffeaUL;
#line 1123
  if (((len + 4095UL) & 0xfffffffffffff000UL) + offset < offset) {
#line 1124
    goto out;
  } else {

  }
#line 1125
  if ((offset & 4095UL) == 0UL) {
#line 1126
    ret = do_mmap_pgoff(file, addr, len, prot, flag, offset >> 12);
  } else {

  }
  out: ;
#line 1128
  return (ret);
}
}
#line 333 "include/linux/sched.h"
extern void schedule(void) ;
#line 24 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/uaccess_64.h"
extern unsigned long copy_from_user(void * , void const   * , unsigned int  ) ;
#line 182
extern long __copy_user_nocache(void * , void const   * , unsigned int  , int  ) ;
#line 192 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/uaccess_64.h"
__inline static int __copy_from_user_inatomic_nocache(void *dst , void const   *src ,
                                                      unsigned int size ) 
{ 
  long tmp ;

  {
#line 196
  tmp = __copy_user_nocache(dst, src, size, 0);
#line 196
  return ((int )tmp);
}
}
#line 39 "include/linux/highmem.h"
__inline static void *kmap(struct page *page ) 
{ 
  void *tmp ;

  {
#line 41
  __might_sleep((char *)"include/linux/highmem.h", 41);
#line 42
  tmp = lowmem_page_address(page);
#line 42
  return (tmp);
}
}
#line 260 "include/linux/pagemap.h"
extern struct page *read_cache_page(struct address_space * , unsigned long  , filler_t * ,
                                    void * ) ;
#line 274 "include/linux/pagemap.h"
__inline static struct page *read_mapping_page(struct address_space *mapping , unsigned long index ,
                                               void *data ) 
{ 
  filler_t *filler ;
  struct page *tmp ;

  {
#line 277
  filler = (filler_t *)(mapping->a_ops)->readpage;
#line 278
  tmp = read_cache_page(mapping, index, filler, data);
#line 278
  return (tmp);
}
}
#line 1012 "include/drm/drmP.h"
extern int drm_free_agp(struct agp_memory * , int  ) ;
#line 1014
extern struct agp_memory *drm_agp_bind_pages(struct drm_device * , struct page ** ,
                                             unsigned long  , uint32_t  , uint32_t  ) ;
#line 1019
extern int drm_unbind_agp(struct agp_memory * ) ;
#line 1082
extern void drm_clflush_pages(struct page ** , unsigned long  ) ;
#line 1140
extern int drm_irq_install(struct drm_device * ) ;
#line 1189
extern void drm_agp_chipset_flush(struct drm_device * ) ;
#line 1239
extern struct drm_mm_node *drm_mm_get_block(struct drm_mm_node * , unsigned long  ,
                                            unsigned int  ) ;
#line 1242
extern void drm_mm_put_block(struct drm_mm_node * ) ;
#line 1243
extern struct drm_mm_node *drm_mm_search_free(struct drm_mm  const  * , unsigned long  ,
                                              unsigned int  , int  ) ;
#line 1245
extern int drm_mm_init(struct drm_mm * , unsigned long  , unsigned long  ) ;
#line 1254
extern void drm_gem_object_free(struct kref * ) ;
#line 1255
extern struct drm_gem_object *drm_gem_object_alloc(struct drm_device * , size_t  ) ;
#line 1257
extern void drm_gem_object_handle_free(struct kref * ) ;
#line 1260 "include/drm/drmP.h"
__inline static void drm_gem_object_reference(struct drm_gem_object *obj ) 
{ 


  {
#line 1262
  kref_get(& obj->refcount);
#line 1263
  return;
}
}
#line 1266 "include/drm/drmP.h"
__inline static void drm_gem_object_unreference(struct drm_gem_object *obj ) 
{ 


  {
#line 1268
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 1269
    return;
  } else {

  }
#line 1271
  kref_put(& obj->refcount, & drm_gem_object_free);
#line 1272
  return;
}
}
#line 1274
extern int drm_gem_handle_create(struct drm_file * , struct drm_gem_object * , int * ) ;
#line 1286 "include/drm/drmP.h"
__inline static void drm_gem_object_handle_unreference(struct drm_gem_object *obj ) 
{ 


  {
#line 1288
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 1289
    return;
  } else {

  }
#line 1296
  kref_put(& obj->handlecount, & drm_gem_object_handle_free);
#line 1297
  drm_gem_object_unreference(obj);
#line 1298
  return;
}
}
#line 1300
extern struct drm_gem_object *drm_gem_object_lookup(struct drm_device * , struct drm_file * ,
                                                    int  ) ;
#line 1313
extern void drm_core_ioremap_wc(struct drm_map * , struct drm_device * ) ;
#line 1362 "include/drm/drmP.h"
__inline static void *drm_calloc(size_t nmemb , size_t size , int area ) 
{ 
  void *tmp ;

  {
#line 1364
  tmp = kcalloc(nmemb, size, 208U);
#line 1364
  return (tmp);
}
}
#line 88 "include/linux/io-mapping.h"
__inline static struct io_mapping *io_mapping_create_wc(unsigned long base , unsigned long size ) 
{ 
  void *tmp ;

  {
#line 90
  tmp = ioremap_wc(base, size);
#line 90
  return ((struct io_mapping *)tmp);
}
}
#line 94 "include/linux/io-mapping.h"
__inline static void io_mapping_free(struct io_mapping *mapping ) 
{ 


  {
#line 96
  iounmap((void volatile   *)mapping);
#line 97
  return;
}
}
#line 101 "include/linux/io-mapping.h"
__inline static void *io_mapping_map_atomic_wc(struct io_mapping *mapping , unsigned long offset ) 
{ 


  {
#line 103
  return ((void *)mapping + offset);
}
}
#line 107 "include/linux/io-mapping.h"
__inline static void io_mapping_unmap_atomic(void *vaddr ) 
{ 


  {
#line 109
  return;
}
}
#line 517 "/work/ldvuser/novikov/inst/current/envs/linux/linux/drivers/gpu/drm/i915/i915_drv.h"
int i915_gem_object_pin(struct drm_gem_object *obj , uint32_t alignment ) ;
#line 518
void i915_gem_object_unpin(struct drm_gem_object *obj ) ;
#line 521
void i915_gem_retire_requests(struct drm_device *dev ) ;
#line 522
void i915_gem_retire_work_handler(struct work_struct *work ) ;
#line 523
void i915_gem_clflush_object(struct drm_gem_object *obj ) ;
#line 526
void i915_gem_detect_bit_6_swizzle(struct drm_device *dev ) ;
#line 180 "include/linux/swap.h"
extern void mark_page_accessed(struct page * ) ;
#line 51 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_object_set_to_gpu_domain(struct drm_gem_object *obj , uint32_t read_domains ,
                                              uint32_t write_domain ) ;
#line 54
static void i915_gem_object_flush_gpu_write_domain(struct drm_gem_object *obj ) ;
#line 55
static void i915_gem_object_flush_gtt_write_domain(struct drm_gem_object *obj ) ;
#line 56
static void i915_gem_object_flush_cpu_write_domain(struct drm_gem_object *obj ) ;
#line 57
static int i915_gem_object_set_to_gtt_domain(struct drm_gem_object *obj , int write ) ;
#line 59
static int i915_gem_object_set_to_cpu_domain(struct drm_gem_object *obj , int write ) ;
#line 61
static int i915_gem_object_set_cpu_read_domain_range(struct drm_gem_object *obj ,
                                                     uint64_t offset , uint64_t size ) ;
#line 64
static void i915_gem_object_set_to_full_cpu_read_domain(struct drm_gem_object *obj ) ;
#line 65
static int i915_gem_object_get_page_list(struct drm_gem_object *obj ) ;
#line 66
static void i915_gem_object_free_page_list(struct drm_gem_object *obj ) ;
#line 67
static int i915_gem_object_wait_rendering(struct drm_gem_object *obj ) ;
#line 70
static void i915_gem_cleanup_ringbuffer(struct drm_device *dev ) ;
#line 73 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_init_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_init *args ;

  {
#line 76
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 77
  args = (struct drm_i915_gem_init *)data;
#line 79
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 81
  if ((args->gtt_start >= args->gtt_end || (args->gtt_start & 4095ULL) != 0ULL) || (args->gtt_end & 4095ULL) != 0ULL) {
#line 84
    mutex_unlock(& dev->struct_mutex);
#line 85
    return (-22);
  } else {

  }
#line 88
  drm_mm_init(& dev_priv->mm.gtt_space, (unsigned long )args->gtt_start, (unsigned long )(args->gtt_end - args->gtt_start));
#line 91
  dev->gtt_total = (unsigned int )args->gtt_end - (unsigned int )args->gtt_start;
#line 93
  mutex_unlock(& dev->struct_mutex);
#line 95
  return (0);
}
}
#line 99 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_get_aperture_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_get_aperture *args ;

  {
#line 102
  args = (struct drm_i915_gem_get_aperture *)data;
#line 104
  if (((dev->driver)->driver_features & 4096U) == 0U) {
#line 105
    return (-19);
  } else {

  }
#line 107
  args->aper_size = (uint64_t )dev->gtt_total;
#line 108
  args->aper_available_size = args->aper_size - (uint64_t )dev->pin_memory.counter;
#line 111
  return (0);
}
}
#line 119 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_create_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_create *args ;
  struct drm_gem_object *obj ;
  int handle ;
  int ret ;

  {
#line 122
  args = (struct drm_i915_gem_create *)data;
#line 126
  args->size = ((args->size + 4095ULL) / 4096ULL) * 4096ULL;
#line 129
  obj = drm_gem_object_alloc(dev, (size_t )args->size);
#line 130
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 131
    return (-12);
  } else {

  }
#line 133
  ret = drm_gem_handle_create(file_priv, obj, & handle);
#line 134
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 135
  drm_gem_object_handle_unreference(obj);
#line 136
  mutex_unlock(& dev->struct_mutex);
#line 138
  if (ret != 0) {
#line 139
    return (ret);
  } else {

  }
#line 141
  args->handle = (uint32_t )handle;
#line 143
  return (0);
}
}
#line 152 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_pread_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_pread *args ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;
  ssize_t read ;
  loff_t offset ;
  int ret ;

  {
#line 155
  args = (struct drm_i915_gem_pread *)data;
#line 162
  obj = drm_gem_object_lookup(dev, file_priv, (int )args->handle);
#line 163
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 164
    return (-9);
  } else {

  }
#line 165
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 171
  if ((args->offset > (unsigned long long )obj->size || args->size > (unsigned long long )obj->size) || args->offset + args->size > (unsigned long long )obj->size) {
#line 173
    drm_gem_object_unreference(obj);
#line 174
    return (-22);
  } else {

  }
#line 177
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 179
  ret = i915_gem_object_set_cpu_read_domain_range(obj, args->offset, args->size);
#line 181
  if (ret != 0) {
#line 182
    drm_gem_object_unreference(obj);
#line 183
    mutex_unlock(& dev->struct_mutex);
#line 184
    return (ret);
  } else {

  }
#line 187
  offset = (loff_t )args->offset;
#line 189
  read = vfs_read(obj->filp, (char *)args->data_ptr, (size_t )args->size, & offset);
#line 191
  if ((unsigned long long )read != args->size) {
#line 192
    drm_gem_object_unreference(obj);
#line 193
    mutex_unlock(& dev->struct_mutex);
#line 194
    if (read < 0L) {
#line 195
      return ((int )read);
    } else {
#line 197
      return (-22);
    }
  } else {

  }
#line 200
  drm_gem_object_unreference(obj);
#line 201
  mutex_unlock(& dev->struct_mutex);
#line 203
  return (0);
}
}
#line 211 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
__inline static int fast_user_write(struct io_mapping *mapping , loff_t page_base ,
                                    int page_offset___0 , char *user_data , int length ) 
{ 
  char *vaddr_atomic ;
  unsigned long unwritten ;
  void *tmp ;
  int tmp___0 ;

  {
#line 219
  tmp = io_mapping_map_atomic_wc(mapping, (unsigned long )page_base);
#line 219
  vaddr_atomic = (char *)tmp;
#line 220
  tmp___0 = __copy_from_user_inatomic_nocache((void *)vaddr_atomic + (unsigned long )page_offset___0,
                                              (void const   *)user_data, (unsigned int )length);
#line 220
  unwritten = (unsigned long )tmp___0;
#line 222
  io_mapping_unmap_atomic((void *)vaddr_atomic);
#line 223
  if (unwritten != 0UL) {
#line 224
    return (-14);
  } else {

  }
#line 225
  return (0);
}
}
#line 233 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
__inline static int slow_user_write(struct io_mapping *mapping , loff_t page_base ,
                                    int page_offset___0 , char *user_data , int length ) 
{ 
  char *vaddr ;
  unsigned long unwritten ;
  void *tmp ;
  int tmp___0 ;

  {
#line 241
  tmp = io_mapping_map_atomic_wc(mapping, (unsigned long )page_base);
#line 241
  vaddr = (char *)tmp;
#line 242
  if ((unsigned long )vaddr == (unsigned long )((char *)0)) {
#line 243
    return (-14);
  } else {

  }
#line 244
  tmp___0 = __copy_from_user((void *)vaddr + (unsigned long )page_offset___0, (void const   *)user_data,
                             (unsigned int )length);
#line 244
  unwritten = (unsigned long )tmp___0;
#line 246
  io_mapping_unmap_atomic((void *)vaddr);
#line 247
  if (unwritten != 0UL) {
#line 248
    return (-14);
  } else {

  }
#line 249
  return (0);
}
}
#line 253 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_gtt_pwrite(struct drm_device *dev , struct drm_gem_object *obj ,
                               struct drm_i915_gem_pwrite *args , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_object *obj_priv ;
  drm_i915_private_t *dev_priv ;
  ssize_t remain ;
  loff_t offset ;
  loff_t page_base ;
  char *user_data ;
  int page_offset___0 ;
  int page_length ;
  int ret ;
  unsigned long flag ;
  unsigned long roksum ;
  struct thread_info *tmp ;
  long tmp___0 ;

  {
#line 257
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 258
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 265
  user_data = (char *)args->data_ptr;
#line 266
  remain = (ssize_t )args->size;
#line 267
  tmp = current_thread_info();
#line 267
  __asm__  ("add %3,%1 ; sbb %0,%0 ; cmp %1,%4 ; sbb $0,%0": "=&r" (flag), "=r" (roksum): "1" (user_data),
            "g" (remain), "rm" (tmp->addr_limit.seg));
#line 267
  tmp___0 = __builtin_expect(flag == 0UL, 1L);
#line 267
  if (tmp___0 == 0L) {
#line 268
    return (-14);
  } else {

  }
#line 271
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 272
  ret = i915_gem_object_pin(obj, 0U);
#line 273
  if (ret != 0) {
#line 274
    mutex_unlock(& dev->struct_mutex);
#line 275
    return (ret);
  } else {

  }
#line 277
  ret = i915_gem_object_set_to_gtt_domain(obj, 1);
#line 278
  if (ret != 0) {
#line 279
    goto fail;
  } else {

  }
#line 281
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 282
  offset = (loff_t )((uint64_t )obj_priv->gtt_offset + args->offset);
#line 283
  obj_priv->dirty = 1;
#line 285
  goto ldv_24299;
  ldv_24298: 
#line 292
  page_base = offset & -4096LL;
#line 293
  page_offset___0 = (int )offset & 4095;
#line 294
  page_length = (int )remain;
#line 295
  if ((unsigned long )((ssize_t )page_offset___0 + remain) > 4096UL) {
#line 296
    page_length = (int )(4096U - (unsigned int )page_offset___0);
  } else {

  }
#line 298
  ret = fast_user_write(dev_priv->mm.gtt_mapping, page_base, page_offset___0, user_data,
                        page_length);
#line 305
  if (ret != 0) {
#line 306
    ret = slow_user_write(dev_priv->mm.gtt_mapping, page_base, page_offset___0, user_data,
                          page_length);
#line 309
    if (ret != 0) {
#line 310
      goto fail;
    } else {

    }
  } else {

  }
#line 313
  remain = remain - (ssize_t )page_length;
#line 314
  user_data = user_data + (unsigned long )page_length;
#line 315
  offset = (loff_t )page_length + offset;
  ldv_24299: ;
#line 285
  if (remain > 0L) {
#line 286
    goto ldv_24298;
  } else {

  }

  fail: 
#line 319
  i915_gem_object_unpin(obj);
#line 320
  mutex_unlock(& dev->struct_mutex);
#line 322
  return (ret);
}
}
#line 326 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_shmem_pwrite(struct drm_device *dev , struct drm_gem_object *obj ,
                                 struct drm_i915_gem_pwrite *args , struct drm_file *file_priv ) 
{ 
  int ret ;
  loff_t offset ;
  ssize_t written ;

  {
#line 334
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 336
  ret = i915_gem_object_set_to_cpu_domain(obj, 1);
#line 337
  if (ret != 0) {
#line 338
    mutex_unlock(& dev->struct_mutex);
#line 339
    return (ret);
  } else {

  }
#line 342
  offset = (loff_t )args->offset;
#line 344
  written = vfs_write(obj->filp, (char const   *)args->data_ptr, (size_t )args->size,
                      & offset);
#line 347
  if ((unsigned long long )written != args->size) {
#line 348
    mutex_unlock(& dev->struct_mutex);
#line 349
    if (written < 0L) {
#line 350
      return ((int )written);
    } else {
#line 352
      return (-22);
    }
  } else {

  }
#line 355
  mutex_unlock(& dev->struct_mutex);
#line 357
  return (0);
}
}
#line 366 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_pwrite_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_pwrite *args ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;
  int ret ;

  {
#line 369
  args = (struct drm_i915_gem_pwrite *)data;
#line 372
  ret = 0;
#line 374
  obj = drm_gem_object_lookup(dev, file_priv, (int )args->handle);
#line 375
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 376
    return (-9);
  } else {

  }
#line 377
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 383
  if ((args->offset > (unsigned long long )obj->size || args->size > (unsigned long long )obj->size) || args->offset + args->size > (unsigned long long )obj->size) {
#line 385
    drm_gem_object_unreference(obj);
#line 386
    return (-22);
  } else {

  }
#line 395
  if (obj_priv->tiling_mode == 0U && dev->gtt_total != 0U) {
#line 397
    ret = i915_gem_gtt_pwrite(dev, obj, args, file_priv);
  } else {
#line 399
    ret = i915_gem_shmem_pwrite(dev, obj, args, file_priv);
  }
#line 406
  drm_gem_object_unreference(obj);
#line 408
  return (ret);
}
}
#line 416 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_set_domain_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_set_domain *args ;
  struct drm_gem_object *obj ;
  uint32_t read_domains ;
  uint32_t write_domain ;
  int ret ;

  {
#line 419
  args = (struct drm_i915_gem_set_domain *)data;
#line 421
  read_domains = args->read_domains;
#line 422
  write_domain = args->write_domain;
#line 425
  if (((dev->driver)->driver_features & 4096U) == 0U) {
#line 426
    return (-19);
  } else {

  }
#line 429
  if ((write_domain & 4294967230U) != 0U) {
#line 430
    return (-22);
  } else {

  }
#line 432
  if ((read_domains & 4294967230U) != 0U) {
#line 433
    return (-22);
  } else {

  }
#line 438
  if (write_domain != 0U && read_domains != write_domain) {
#line 439
    return (-22);
  } else {

  }
#line 441
  obj = drm_gem_object_lookup(dev, file_priv, (int )args->handle);
#line 442
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 443
    return (-9);
  } else {

  }
#line 445
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 450
  if ((read_domains & 64U) != 0U) {
#line 451
    ret = i915_gem_object_set_to_gtt_domain(obj, write_domain != 0U);
  } else {
#line 453
    ret = i915_gem_object_set_to_cpu_domain(obj, write_domain != 0U);
  }
#line 456
  drm_gem_object_unreference(obj);
#line 457
  mutex_unlock(& dev->struct_mutex);
#line 458
  return (ret);
}
}
#line 465 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_sw_finish_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_sw_finish *args ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;
  int ret ;

  {
#line 468
  args = (struct drm_i915_gem_sw_finish *)data;
#line 471
  ret = 0;
#line 473
  if (((dev->driver)->driver_features & 4096U) == 0U) {
#line 474
    return (-19);
  } else {

  }
#line 476
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 477
  obj = drm_gem_object_lookup(dev, file_priv, (int )args->handle);
#line 478
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 479
    mutex_unlock(& dev->struct_mutex);
#line 480
    return (-9);
  } else {

  }
#line 487
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 490
  if (obj_priv->pin_count != 0) {
#line 491
    i915_gem_object_flush_cpu_write_domain(obj);
  } else {

  }
#line 493
  drm_gem_object_unreference(obj);
#line 494
  mutex_unlock(& dev->struct_mutex);
#line 495
  return (ret);
}
}
#line 506 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_mmap_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_mmap *args ;
  struct drm_gem_object *obj ;
  loff_t offset ;
  unsigned long addr ;
  struct task_struct *tmp ;
  struct task_struct *tmp___0 ;
  long tmp___1 ;

  {
#line 509
  args = (struct drm_i915_gem_mmap *)data;
#line 514
  if (((dev->driver)->driver_features & 4096U) == 0U) {
#line 515
    return (-19);
  } else {

  }
#line 517
  obj = drm_gem_object_lookup(dev, file_priv, (int )args->handle);
#line 518
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 519
    return (-9);
  } else {

  }
#line 521
  offset = (loff_t )args->offset;
#line 523
  tmp = get_current();
#line 523
  down_write(& (tmp->mm)->mmap_sem);
#line 524
  addr = do_mmap(obj->filp, 0UL, (unsigned long )args->size, 3UL, 1UL, (unsigned long )args->offset);
#line 527
  tmp___0 = get_current();
#line 527
  up_write(& (tmp___0->mm)->mmap_sem);
#line 528
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 529
  drm_gem_object_unreference(obj);
#line 530
  mutex_unlock(& dev->struct_mutex);
#line 531
  tmp___1 = IS_ERR((void const   *)addr);
#line 531
  if (tmp___1 != 0L) {
#line 532
    return ((int )addr);
  } else {

  }
#line 534
  args->addr_ptr = (unsigned long long )addr;
#line 536
  return (0);
}
}
#line 540 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_object_free_page_list(struct drm_gem_object *obj ) 
{ 
  struct drm_i915_gem_object *obj_priv ;
  int page_count___0 ;
  int i ;

  {
#line 542
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 543
  page_count___0 = (int )(obj->size / 4096UL);
#line 546
  if ((unsigned long )obj_priv->page_list == (unsigned long )((struct page **)0)) {
#line 547
    return;
  } else {

  }
#line 550
  i = 0;
#line 550
  goto ldv_24354;
  ldv_24353: ;
#line 551
  if ((unsigned long )*(obj_priv->page_list + (unsigned long )i) != (unsigned long )((struct page *)0)) {
#line 552
    if (obj_priv->dirty != 0) {
#line 553
      set_page_dirty(*(obj_priv->page_list + (unsigned long )i));
    } else {

    }
#line 554
    mark_page_accessed(*(obj_priv->page_list + (unsigned long )i));
#line 555
    put_page(*(obj_priv->page_list + (unsigned long )i));
  } else {

  }
#line 550
  i = i + 1;
  ldv_24354: ;
#line 550
  if (i < page_count___0) {
#line 551
    goto ldv_24353;
  } else {

  }
#line 557
  obj_priv->dirty = 0;
#line 559
  drm_free((void *)obj_priv->page_list, (unsigned long )page_count___0 * 8UL, 2);
#line 562
  obj_priv->page_list = 0;
#line 563
  return;
}
}
#line 566 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_object_move_to_active(struct drm_gem_object *obj , uint32_t seqno ) 
{ 
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_object *obj_priv ;

  {
#line 568
  dev = obj->dev;
#line 569
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 570
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 573
  if (obj_priv->active == 0) {
#line 574
    drm_gem_object_reference(obj);
#line 575
    obj_priv->active = 1;
  } else {

  }
#line 578
  list_move_tail(& obj_priv->list, & dev_priv->mm.active_list);
#line 580
  obj_priv->last_rendering_seqno = seqno;
#line 581
  return;
}
}
#line 584 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_object_move_to_flushing(struct drm_gem_object *obj ) 
{ 
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_object *obj_priv ;
  long tmp ;

  {
#line 586
  dev = obj->dev;
#line 587
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 588
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 590
  tmp = __builtin_expect(obj_priv->active == 0, 0L);
#line 590
  if (tmp != 0L) {
#line 590
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (590), "i" (24UL));
    ldv_24369: ;
#line 590
    goto ldv_24369;
  } else {

  }
#line 591
  list_move_tail(& obj_priv->list, & dev_priv->mm.flushing_list);
#line 592
  obj_priv->last_rendering_seqno = 0U;
#line 593
  return;
}
}
#line 596 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_object_move_to_inactive(struct drm_gem_object *obj ) 
{ 
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_object *obj_priv ;

  {
#line 598
  dev = obj->dev;
#line 599
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 600
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 603
  if (obj_priv->pin_count != 0) {
#line 604
    list_del_init(& obj_priv->list);
  } else {
#line 606
    list_move_tail(& obj_priv->list, & dev_priv->mm.inactive_list);
  }
#line 608
  obj_priv->last_rendering_seqno = 0U;
#line 609
  if (obj_priv->active != 0) {
#line 610
    obj_priv->active = 0;
#line 611
    drm_gem_object_unreference(obj);
  } else {

  }
#line 613
  return;
}
}
#line 625 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static uint32_t i915_add_request(struct drm_device *dev , uint32_t flush_domains ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_request *request ;
  uint32_t seqno ;
  int was_empty ;
  unsigned int outring ;
  unsigned int ringmask ;
  unsigned int outcount ;
  char volatile   *virt ;
  void *tmp ;
  struct drm_i915_gem_object *obj_priv ;
  struct drm_i915_gem_object *next ;
  struct list_head  const  *__mptr ;
  struct list_head  const  *__mptr___0 ;
  struct drm_gem_object *obj ;
  struct list_head  const  *__mptr___1 ;

  {
#line 627
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 633
  tmp = drm_calloc(1UL, 32UL, 2);
#line 633
  request = (struct drm_i915_gem_request *)tmp;
#line 634
  if ((unsigned long )request == (unsigned long )((struct drm_i915_gem_request *)0)) {
#line 635
    return (0U);
  } else {

  }
#line 640
  seqno = dev_priv->mm.next_gem_seqno;
#line 641
  dev_priv->mm.next_gem_seqno = dev_priv->mm.next_gem_seqno + (uint32_t )1;
#line 642
  if (dev_priv->mm.next_gem_seqno == 0U) {
#line 643
    dev_priv->mm.next_gem_seqno = dev_priv->mm.next_gem_seqno + (uint32_t )1;
  } else {

  }
#line 645
  if (dev_priv->ring.space <= 15) {
#line 645
    i915_wait_ring(dev, 16, "i915_add_request");
  } else {

  }
#line 645
  outcount = 0U;
#line 645
  outring = (unsigned int )dev_priv->ring.tail;
#line 645
  ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 645
  virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 646
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 276824065U;
#line 646
  outcount = outcount + 1U;
#line 646
  outring = outring + 4U;
#line 646
  outring = outring & ringmask;
#line 647
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 128U;
#line 647
  outcount = outcount + 1U;
#line 647
  outring = outring + 4U;
#line 647
  outring = outring & ringmask;
#line 648
  *((unsigned int volatile   *)virt + (unsigned long )outring) = seqno;
#line 648
  outcount = outcount + 1U;
#line 648
  outring = outring + 4U;
#line 648
  outring = outring & ringmask;
#line 650
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 16777216U;
#line 650
  outcount = outcount + 1U;
#line 650
  outring = outring + 4U;
#line 650
  outring = outring & ringmask;
#line 651
  dev_priv->ring.tail = (int )outring;
#line 651
  dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 651
  writel(outring, (void volatile   *)dev_priv->regs + 8240U);
#line 653
  if (drm_debug != 0U) {
#line 653
    printk("<7>[drm:%s] %d\n", "i915_add_request", seqno);
  } else {

  }
#line 655
  request->seqno = seqno;
#line 656
  request->emitted_jiffies = jiffies;
#line 657
  was_empty = list_empty((struct list_head  const  *)(& dev_priv->mm.request_list));
#line 658
  list_add_tail(& request->list, & dev_priv->mm.request_list);
#line 663
  if (flush_domains != 0U) {
#line 666
    __mptr = (struct list_head  const  *)dev_priv->mm.flushing_list.next;
#line 666
    obj_priv = (struct drm_i915_gem_object *)__mptr + 0xfffffffffffffff0UL;
#line 666
    __mptr___0 = (struct list_head  const  *)obj_priv->list.next;
#line 666
    next = (struct drm_i915_gem_object *)__mptr___0 + 0xfffffffffffffff0UL;
#line 666
    goto ldv_24399;
    ldv_24398: 
#line 668
    obj = obj_priv->obj;
#line 670
    if ((obj->write_domain & flush_domains) == obj->write_domain) {
#line 672
      obj->write_domain = 0U;
#line 673
      i915_gem_object_move_to_active(obj, seqno);
    } else {

    }
#line 666
    obj_priv = next;
#line 666
    __mptr___1 = (struct list_head  const  *)next->list.next;
#line 666
    next = (struct drm_i915_gem_object *)__mptr___1 + 0xfffffffffffffff0UL;
    ldv_24399: ;
#line 666
    if ((unsigned long )(& obj_priv->list) != (unsigned long )(& dev_priv->mm.flushing_list)) {
#line 667
      goto ldv_24398;
    } else {

    }

  } else {

  }
#line 679
  if (was_empty != 0 && dev_priv->mm.suspended == 0) {
#line 680
    schedule_delayed_work(& dev_priv->mm.retire_work, 250UL);
  } else {

  }
#line 681
  return (seqno);
}
}
#line 691 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static uint32_t i915_retire_commands(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  uint32_t cmd ;
  uint32_t flush_domains ;
  unsigned int outring ;
  unsigned int ringmask ;
  unsigned int outcount ;
  char volatile   *virt ;

  {
#line 693
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 694
  cmd = 33554436U;
#line 695
  flush_domains = 0U;
#line 699
  if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 700
    flush_domains = flush_domains | 4U;
  } else {

  }
#line 701
  if (dev_priv->ring.space <= 7) {
#line 701
    i915_wait_ring(dev, 8, "i915_retire_commands");
  } else {

  }
#line 701
  outcount = 0U;
#line 701
  outring = (unsigned int )dev_priv->ring.tail;
#line 701
  ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 701
  virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 702
  *((unsigned int volatile   *)virt + (unsigned long )outring) = cmd;
#line 702
  outcount = outcount + 1U;
#line 702
  outring = outring + 4U;
#line 702
  outring = outring & ringmask;
#line 703
  *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 703
  outcount = outcount + 1U;
#line 703
  outring = outring + 4U;
#line 703
  outring = outring & ringmask;
#line 704
  dev_priv->ring.tail = (int )outring;
#line 704
  dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 704
  writel(outring, (void volatile   *)dev_priv->regs + 8240U);
#line 705
  return (flush_domains);
}
}
#line 713 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_retire_request(struct drm_device *dev , struct drm_i915_gem_request *request ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;
  struct list_head  const  *__mptr ;
  int tmp ;

  {
#line 716
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 721
  goto ldv_24422;
  ldv_24421: 
#line 725
  __mptr = (struct list_head  const  *)dev_priv->mm.active_list.next;
#line 725
  obj_priv = (struct drm_i915_gem_object *)__mptr + 0xfffffffffffffff0UL;
#line 728
  obj = obj_priv->obj;
#line 734
  if (obj_priv->last_rendering_seqno != request->seqno) {
#line 735
    return;
  } else {

  }
#line 741
  if (obj->write_domain != 0U) {
#line 742
    i915_gem_object_move_to_flushing(obj);
  } else {
#line 744
    i915_gem_object_move_to_inactive(obj);
  }
  ldv_24422: 
#line 721
  tmp = list_empty((struct list_head  const  *)(& dev_priv->mm.active_list));
#line 721
  if (tmp == 0) {
#line 722
    goto ldv_24421;
  } else {

  }

#line 726
  return;
}
}
#line 752 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_seqno_passed(uint32_t seq1 , uint32_t seq2 ) 
{ 


  {
#line 754
  return ((int )(seq1 - seq2) >= 0);
}
}
#line 758 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
uint32_t i915_get_gem_seqno(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;

  {
#line 760
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 762
  return ((uint32_t )*((u32 volatile   *)dev_priv->hw_status_page + 32UL));
}
}
#line 769 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
void i915_gem_retire_requests(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  uint32_t seqno ;
  struct drm_i915_gem_request *request ;
  uint32_t retiring_seqno ;
  struct list_head  const  *__mptr ;
  int tmp ;
  int tmp___0 ;

  {
#line 771
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 774
  seqno = i915_get_gem_seqno(dev);
#line 776
  goto ldv_24443;
  ldv_24442: 
#line 780
  __mptr = (struct list_head  const  *)dev_priv->mm.request_list.next;
#line 780
  request = (struct drm_i915_gem_request *)__mptr + 0xfffffffffffffff0UL;
#line 783
  retiring_seqno = request->seqno;
#line 785
  tmp = i915_seqno_passed(seqno, retiring_seqno);
#line 785
  if (tmp != 0 || dev_priv->mm.wedged != 0) {
#line 787
    i915_gem_retire_request(dev, request);
#line 789
    list_del(& request->list);
#line 790
    drm_free((void *)request, 32UL, 2);
  } else {
#line 792
    goto ldv_24441;
  }
  ldv_24443: 
#line 776
  tmp___0 = list_empty((struct list_head  const  *)(& dev_priv->mm.request_list));
#line 776
  if (tmp___0 == 0) {
#line 777
    goto ldv_24442;
  } else {

  }
  ldv_24441: ;
#line 781
  return;
}
}
#line 797 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
void i915_gem_retire_work_handler(struct work_struct *work ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_device *dev ;
  struct work_struct  const  *__mptr ;
  int tmp ;

  {
#line 802
  __mptr = (struct work_struct  const  *)work;
#line 802
  dev_priv = (drm_i915_private_t *)__mptr + 0xfffffffffffff0a8UL;
#line 804
  dev = dev_priv->dev;
#line 806
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 807
  i915_gem_retire_requests(dev);
#line 808
  if (dev_priv->mm.suspended == 0) {
#line 808
    tmp = list_empty((struct list_head  const  *)(& dev_priv->mm.request_list));
#line 808
    if (tmp == 0) {
#line 810
      schedule_delayed_work(& dev_priv->mm.retire_work, 250UL);
    } else {

    }
  } else {

  }
#line 811
  mutex_unlock(& dev->struct_mutex);
#line 812
  return;
}
}
#line 819 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_wait_request(struct drm_device *dev , uint32_t seqno ) 
{ 
  drm_i915_private_t *dev_priv ;
  int ret ;
  long tmp ;
  int __ret ;
  wait_queue_t __wait ;
  struct task_struct *tmp___0 ;
  uint32_t tmp___1 ;
  int tmp___2 ;
  struct task_struct *tmp___3 ;
  int tmp___4 ;
  uint32_t tmp___5 ;
  int tmp___6 ;
  uint32_t tmp___7 ;
  int tmp___8 ;
  uint32_t tmp___9 ;

  {
#line 821
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 822
  ret = 0;
#line 824
  tmp = __builtin_expect(seqno == 0U, 0L);
#line 824
  if (tmp != 0L) {
#line 824
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (824), "i" (24UL));
    ldv_24457: ;
#line 824
    goto ldv_24457;
  } else {

  }
#line 826
  tmp___7 = i915_get_gem_seqno(dev);
#line 826
  tmp___8 = i915_seqno_passed(tmp___7, seqno);
#line 826
  if (tmp___8 == 0) {
#line 827
    dev_priv->mm.waiting_gem_seqno = seqno;
#line 828
    i915_user_irq_get(dev);
#line 829
    __ret = 0;
#line 829
    tmp___5 = i915_get_gem_seqno(dev);
#line 829
    tmp___6 = i915_seqno_passed(tmp___5, seqno);
#line 829
    if (tmp___6 == 0 && dev_priv->mm.wedged == 0) {
#line 829
      tmp___0 = get_current();
#line 829
      __wait.flags = 0U;
#line 829
      __wait.private = (void *)tmp___0;
#line 829
      __wait.func = & autoremove_wake_function;
#line 829
      __wait.task_list.next = & __wait.task_list;
#line 829
      __wait.task_list.prev = & __wait.task_list;
      ldv_24462: 
#line 829
      prepare_to_wait(& dev_priv->irq_queue, & __wait, 1);
#line 829
      tmp___1 = i915_get_gem_seqno(dev);
#line 829
      tmp___2 = i915_seqno_passed(tmp___1, seqno);
#line 829
      if (tmp___2 != 0 || dev_priv->mm.wedged != 0) {
#line 829
        goto ldv_24460;
      } else {

      }
#line 829
      tmp___3 = get_current();
#line 829
      tmp___4 = signal_pending(tmp___3);
#line 829
      if (tmp___4 == 0) {
#line 829
        schedule();
#line 829
        goto ldv_24461;
      } else {

      }
#line 829
      __ret = -512;
#line 829
      goto ldv_24460;
      ldv_24461: ;
#line 829
      goto ldv_24462;
      ldv_24460: 
#line 829
      finish_wait(& dev_priv->irq_queue, & __wait);
    } else {

    }
#line 829
    ret = __ret;
#line 833
    i915_user_irq_put(dev);
#line 834
    dev_priv->mm.waiting_gem_seqno = 0U;
  } else {

  }
#line 836
  if (dev_priv->mm.wedged != 0) {
#line 837
    ret = -5;
  } else {

  }
#line 839
  if (ret != 0 && ret != -512) {
#line 840
    tmp___9 = i915_get_gem_seqno(dev);
#line 840
    printk("<3>[drm:%s] *ERROR* %s returns %d (awaiting %d at %d)\n", "i915_wait_request",
           "i915_wait_request", ret, seqno, tmp___9);
  } else {

  }
#line 848
  if (ret == 0) {
#line 849
    i915_gem_retire_requests(dev);
  } else {

  }
#line 851
  return (ret);
}
}
#line 855 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_flush(struct drm_device *dev , uint32_t invalidate_domains ,
                           uint32_t flush_domains ) 
{ 
  drm_i915_private_t *dev_priv ;
  uint32_t cmd ;
  unsigned int outring ;
  unsigned int ringmask ;
  unsigned int outcount ;
  char volatile   *virt ;

  {
#line 859
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 868
  if ((int )flush_domains & 1) {
#line 869
    drm_agp_chipset_flush(dev);
  } else {

  }
#line 871
  if (((invalidate_domains | flush_domains) & 4294967230U) != 0U) {
#line 901
    cmd = 33554436U;
#line 902
    if (((invalidate_domains | flush_domains) & 2U) != 0U) {
#line 904
      cmd = cmd & 4294967291U;
    } else {

    }
#line 905
    if (((((((((dev->pci_device != 10610 && dev->pci_device != 10626) && dev->pci_device != 10642) && dev->pci_device != 10658) && dev->pci_device != 10754) && dev->pci_device != 10770) && dev->pci_device != 10818) && dev->pci_device != 11778) && dev->pci_device != 11794) && dev->pci_device != 11810) {
#line 910
      if ((invalidate_domains & 4U) != 0U) {
#line 911
        cmd = cmd | 1U;
      } else {

      }
    } else {

    }
#line 913
    if ((invalidate_domains & 16U) != 0U) {
#line 914
      cmd = cmd | 2U;
    } else {

    }
#line 919
    if (dev_priv->ring.space <= 7) {
#line 919
      i915_wait_ring(dev, 8, "i915_gem_flush");
    } else {

    }
#line 919
    outcount = 0U;
#line 919
    outring = (unsigned int )dev_priv->ring.tail;
#line 919
    ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 919
    virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 920
    *((unsigned int volatile   *)virt + (unsigned long )outring) = cmd;
#line 920
    outcount = outcount + 1U;
#line 920
    outring = outring + 4U;
#line 920
    outring = outring & ringmask;
#line 921
    *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 921
    outcount = outcount + 1U;
#line 921
    outring = outring + 4U;
#line 921
    outring = outring & ringmask;
#line 922
    dev_priv->ring.tail = (int )outring;
#line 922
    dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 922
    writel(outring, (void volatile   *)dev_priv->regs + 8240U);
  } else {

  }
#line 924
  return;
}
}
#line 931 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_object_wait_rendering(struct drm_gem_object *obj ) 
{ 
  struct drm_device *dev ;
  struct drm_i915_gem_object *obj_priv ;
  int ret ;
  long tmp ;

  {
#line 933
  dev = obj->dev;
#line 934
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 940
  tmp = __builtin_expect((obj->write_domain & 4294967230U) != 0U, 0L);
#line 940
  if (tmp != 0L) {
#line 940
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (940), "i" (24UL));
    ldv_24483: ;
#line 940
    goto ldv_24483;
  } else {

  }
#line 945
  if (obj_priv->active != 0) {
#line 950
    ret = i915_wait_request(dev, obj_priv->last_rendering_seqno);
#line 951
    if (ret != 0) {
#line 952
      return (ret);
    } else {

    }
  } else {

  }
#line 955
  return (0);
}
}
#line 962 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_object_unbind(struct drm_gem_object *obj ) 
{ 
  struct drm_device *dev ;
  struct drm_i915_gem_object *obj_priv ;
  int ret ;
  long tmp ;
  int tmp___0 ;

  {
#line 964
  dev = obj->dev;
#line 965
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 966
  ret = 0;
#line 972
  if ((unsigned long )obj_priv->gtt_space == (unsigned long )((struct drm_mm_node *)0)) {
#line 973
    return (0);
  } else {

  }
#line 975
  if (obj_priv->pin_count != 0) {
#line 976
    printk("<3>[drm:%s] *ERROR* Attempting to unbind pinned buffer\n", "i915_gem_object_unbind");
#line 977
    return (-22);
  } else {

  }
#line 986
  ret = i915_gem_object_set_to_cpu_domain(obj, 1);
#line 987
  if (ret != 0) {
#line 988
    if (ret != -512) {
#line 989
      printk("<3>[drm:%s] *ERROR* set_domain failed: %d\n", "i915_gem_object_unbind",
             ret);
    } else {

    }
#line 990
    return (ret);
  } else {

  }
#line 993
  if ((unsigned long )obj_priv->agp_mem != (unsigned long )((struct agp_memory *)0)) {
#line 994
    drm_unbind_agp(obj_priv->agp_mem);
#line 995
    drm_free_agp(obj_priv->agp_mem, (int )(obj->size / 4096UL));
#line 996
    obj_priv->agp_mem = 0;
  } else {

  }
#line 999
  tmp = __builtin_expect(obj_priv->active != 0, 0L);
#line 999
  if (tmp != 0L) {
#line 999
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (999), "i" (24UL));
    ldv_24491: ;
#line 999
    goto ldv_24491;
  } else {

  }
#line 1001
  i915_gem_object_free_page_list(obj);
#line 1003
  if ((unsigned long )obj_priv->gtt_space != (unsigned long )((struct drm_mm_node *)0)) {
#line 1004
    atomic_dec(& dev->gtt_count);
#line 1005
    atomic_sub((int )obj->size, & dev->gtt_memory);
#line 1007
    drm_mm_put_block(obj_priv->gtt_space);
#line 1008
    obj_priv->gtt_space = 0;
  } else {

  }
#line 1012
  tmp___0 = list_empty((struct list_head  const  *)(& obj_priv->list));
#line 1012
  if (tmp___0 == 0) {
#line 1013
    list_del_init(& obj_priv->list);
  } else {

  }
#line 1015
  return (0);
}
}
#line 1019 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_evict_something(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;
  int ret ;
  struct list_head  const  *__mptr ;
  long tmp ;
  long tmp___0 ;
  int tmp___1 ;
  struct drm_i915_gem_request *request ;
  struct list_head  const  *__mptr___0 ;
  int tmp___2 ;
  int tmp___3 ;
  struct list_head  const  *__mptr___1 ;
  int tmp___4 ;
  int tmp___5 ;
  int tmp___6 ;
  int tmp___7 ;

  {
#line 1021
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 1024
  ret = 0;
  ldv_24511: 
#line 1030
  tmp___1 = list_empty((struct list_head  const  *)(& dev_priv->mm.inactive_list));
#line 1030
  if (tmp___1 == 0) {
#line 1031
    __mptr = (struct list_head  const  *)dev_priv->mm.inactive_list.next;
#line 1031
    obj_priv = (struct drm_i915_gem_object *)__mptr + 0xfffffffffffffff0UL;
#line 1034
    obj = obj_priv->obj;
#line 1035
    tmp = __builtin_expect(obj_priv->pin_count != 0, 0L);
#line 1035
    if (tmp != 0L) {
#line 1035
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                           "i" (1035), "i" (24UL));
      ldv_24501: ;
#line 1035
      goto ldv_24501;
    } else {

    }
#line 1039
    tmp___0 = __builtin_expect(obj_priv->active != 0, 0L);
#line 1039
    if (tmp___0 != 0L) {
#line 1039
      __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                           "i" (1039), "i" (24UL));
      ldv_24502: ;
#line 1039
      goto ldv_24502;
    } else {

    }
#line 1042
    ret = i915_gem_object_unbind(obj);
#line 1043
    goto ldv_24503;
  } else {

  }
#line 1050
  tmp___3 = list_empty((struct list_head  const  *)(& dev_priv->mm.request_list));
#line 1050
  if (tmp___3 == 0) {
#line 1053
    __mptr___0 = (struct list_head  const  *)dev_priv->mm.request_list.next;
#line 1053
    request = (struct drm_i915_gem_request *)__mptr___0 + 0xfffffffffffffff0UL;
#line 1057
    ret = i915_wait_request(dev, request->seqno);
#line 1058
    if (ret != 0) {
#line 1059
      goto ldv_24503;
    } else {

    }
#line 1066
    tmp___2 = list_empty((struct list_head  const  *)(& dev_priv->mm.inactive_list));
#line 1066
    if (tmp___2 == 0) {
#line 1067
      goto ldv_24507;
    } else {

    }
#line 1068
    goto ldv_24503;
  } else {

  }
#line 1076
  tmp___4 = list_empty((struct list_head  const  *)(& dev_priv->mm.flushing_list));
#line 1076
  if (tmp___4 == 0) {
#line 1077
    __mptr___1 = (struct list_head  const  *)dev_priv->mm.flushing_list.next;
#line 1077
    obj_priv = (struct drm_i915_gem_object *)__mptr___1 + 0xfffffffffffffff0UL;
#line 1080
    obj = obj_priv->obj;
#line 1082
    i915_gem_flush(dev, obj->write_domain, obj->write_domain);
#line 1085
    i915_add_request(dev, obj->write_domain);
#line 1087
    obj = 0;
#line 1088
    goto ldv_24507;
  } else {

  }
#line 1091
  tmp___5 = list_empty((struct list_head  const  *)(& dev_priv->mm.flushing_list));
#line 1091
  tmp___6 = list_empty((struct list_head  const  *)(& dev_priv->mm.request_list));
#line 1091
  tmp___7 = list_empty((struct list_head  const  *)(& dev_priv->mm.inactive_list));
#line 1091
  printk("<3>[drm:%s] *ERROR* inactive empty %d request empty %d flushing empty %d\n",
         "i915_gem_evict_something", tmp___7, tmp___6, tmp___5);
#line 1099
  return (-12);
  ldv_24507: ;
#line 1100
  goto ldv_24511;
  ldv_24503: ;
#line 1101
  return (ret);
}
}
#line 1105 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_object_get_page_list(struct drm_gem_object *obj ) 
{ 
  struct drm_i915_gem_object *obj_priv ;
  int page_count___0 ;
  int i ;
  struct address_space *mapping ;
  struct inode *inode ;
  struct page *page ;
  int ret ;
  long tmp ;
  void *tmp___0 ;
  long tmp___1 ;
  long tmp___2 ;

  {
#line 1107
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 1114
  if ((unsigned long )obj_priv->page_list != (unsigned long )((struct page **)0)) {
#line 1115
    return (0);
  } else {

  }
#line 1120
  page_count___0 = (int )(obj->size / 4096UL);
#line 1121
  tmp = __builtin_expect((unsigned long )obj_priv->page_list != (unsigned long )((struct page **)0),
                         0L);
#line 1121
  if (tmp != 0L) {
#line 1121
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (1121), "i" (24UL));
    ldv_24522: ;
#line 1121
    goto ldv_24522;
  } else {

  }
#line 1122
  tmp___0 = drm_calloc((size_t )page_count___0, 8UL, 2);
#line 1122
  obj_priv->page_list = (struct page **)tmp___0;
#line 1124
  if ((unsigned long )obj_priv->page_list == (unsigned long )((struct page **)0)) {
#line 1125
    printk("<3>[drm:%s] *ERROR* Faled to allocate page list\n", "i915_gem_object_get_page_list");
#line 1126
    return (-12);
  } else {

  }
#line 1129
  inode = ((obj->filp)->f_path.dentry)->d_inode;
#line 1130
  mapping = inode->i_mapping;
#line 1131
  i = 0;
#line 1131
  goto ldv_24525;
  ldv_24524: 
#line 1132
  page = read_mapping_page(mapping, (unsigned long )i, 0);
#line 1133
  tmp___2 = IS_ERR((void const   *)page);
#line 1133
  if (tmp___2 != 0L) {
#line 1134
    tmp___1 = PTR_ERR((void const   *)page);
#line 1134
    ret = (int )tmp___1;
#line 1135
    printk("<3>[drm:%s] *ERROR* read_mapping_page failed: %d\n", "i915_gem_object_get_page_list",
           ret);
#line 1136
    i915_gem_object_free_page_list(obj);
#line 1137
    return (ret);
  } else {

  }
#line 1139
  *(obj_priv->page_list + (unsigned long )i) = page;
#line 1131
  i = i + 1;
  ldv_24525: ;
#line 1131
  if (i < page_count___0) {
#line 1132
    goto ldv_24524;
  } else {

  }

#line 1141
  return (0);
}
}
#line 1148 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_object_bind_to_gtt(struct drm_gem_object *obj , unsigned int alignment ) 
{ 
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_object *obj_priv ;
  struct drm_mm_node *free_space ;
  int page_count___0 ;
  int ret ;
  int tmp ;
  int tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;
  long tmp___3 ;

  {
#line 1150
  dev = obj->dev;
#line 1151
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 1152
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 1156
  if (alignment == 0U) {
#line 1157
    alignment = 4096U;
  } else {

  }
#line 1158
  if (((unsigned long )alignment & 4095UL) != 0UL) {
#line 1159
    printk("<3>[drm:%s] *ERROR* Invalid object alignment requested %u\n", "i915_gem_object_bind_to_gtt",
           alignment);
#line 1160
    return (-22);
  } else {

  }
  search_free: 
#line 1164
  free_space = drm_mm_search_free((struct drm_mm  const  *)(& dev_priv->mm.gtt_space),
                                  obj->size, alignment, 0);
#line 1166
  if ((unsigned long )free_space != (unsigned long )((struct drm_mm_node *)0)) {
#line 1167
    obj_priv->gtt_space = drm_mm_get_block(free_space, obj->size, alignment);
#line 1169
    if ((unsigned long )obj_priv->gtt_space != (unsigned long )((struct drm_mm_node *)0)) {
#line 1170
      (obj_priv->gtt_space)->private = (void *)obj;
#line 1171
      obj_priv->gtt_offset = (uint32_t )(obj_priv->gtt_space)->start;
    } else {

    }
  } else {

  }
#line 1174
  if ((unsigned long )obj_priv->gtt_space == (unsigned long )((struct drm_mm_node *)0)) {
#line 1181
    tmp = list_empty((struct list_head  const  *)(& dev_priv->mm.inactive_list));
#line 1181
    if (tmp != 0) {
#line 1181
      tmp___0 = list_empty((struct list_head  const  *)(& dev_priv->mm.flushing_list));
#line 1181
      if (tmp___0 != 0) {
#line 1181
        tmp___1 = list_empty((struct list_head  const  *)(& dev_priv->mm.active_list));
#line 1181
        if (tmp___1 != 0) {
#line 1184
          printk("<3>[drm:%s] *ERROR* GTT full, but LRU list empty\n", "i915_gem_object_bind_to_gtt");
#line 1185
          return (-12);
        } else {

        }
      } else {

      }
    } else {

    }
#line 1188
    ret = i915_gem_evict_something(dev);
#line 1189
    if (ret != 0) {
#line 1190
      printk("<3>[drm:%s] *ERROR* Failed to evict a buffer %d\n", "i915_gem_object_bind_to_gtt",
             ret);
#line 1191
      return (ret);
    } else {

    }
#line 1193
    goto search_free;
  } else {

  }
#line 1200
  ret = i915_gem_object_get_page_list(obj);
#line 1201
  if (ret != 0) {
#line 1202
    drm_mm_put_block(obj_priv->gtt_space);
#line 1203
    obj_priv->gtt_space = 0;
#line 1204
    return (ret);
  } else {

  }
#line 1207
  page_count___0 = (int )(obj->size / 4096UL);
#line 1211
  obj_priv->agp_mem = drm_agp_bind_pages(dev, obj_priv->page_list, (unsigned long )page_count___0,
                                         obj_priv->gtt_offset, obj_priv->agp_type);
#line 1216
  if ((unsigned long )obj_priv->agp_mem == (unsigned long )((struct agp_memory *)0)) {
#line 1217
    i915_gem_object_free_page_list(obj);
#line 1218
    drm_mm_put_block(obj_priv->gtt_space);
#line 1219
    obj_priv->gtt_space = 0;
#line 1220
    return (-12);
  } else {

  }
#line 1222
  atomic_inc(& dev->gtt_count);
#line 1223
  atomic_add((int )obj->size, & dev->gtt_memory);
#line 1229
  tmp___2 = __builtin_expect((obj->read_domains & 4294967230U) != 0U, 0L);
#line 1229
  if (tmp___2 != 0L) {
#line 1229
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (1229), "i" (24UL));
    ldv_24539: ;
#line 1229
    goto ldv_24539;
  } else {

  }
#line 1230
  tmp___3 = __builtin_expect((obj->write_domain & 4294967230U) != 0U, 0L);
#line 1230
  if (tmp___3 != 0L) {
#line 1230
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (1230), "i" (24UL));
    ldv_24540: ;
#line 1230
    goto ldv_24540;
  } else {

  }
#line 1232
  return (0);
}
}
#line 1236 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
void i915_gem_clflush_object(struct drm_gem_object *obj ) 
{ 
  struct drm_i915_gem_object *obj_priv ;

  {
#line 1238
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 1244
  if ((unsigned long )obj_priv->page_list == (unsigned long )((struct page **)0)) {
#line 1245
    return;
  } else {

  }
#line 1247
  drm_clflush_pages(obj_priv->page_list, obj->size / 4096UL);
#line 1248
  return;
}
}
#line 1252 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_object_flush_gpu_write_domain(struct drm_gem_object *obj ) 
{ 
  struct drm_device *dev ;
  uint32_t seqno ;

  {
#line 1254
  dev = obj->dev;
#line 1257
  if ((obj->write_domain & 4294967230U) == 0U) {
#line 1258
    return;
  } else {

  }
#line 1261
  i915_gem_flush(dev, 0U, obj->write_domain);
#line 1262
  seqno = i915_add_request(dev, obj->write_domain);
#line 1263
  obj->write_domain = 0U;
#line 1264
  i915_gem_object_move_to_active(obj, seqno);
#line 1265
  return;
}
}
#line 1269 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_object_flush_gtt_write_domain(struct drm_gem_object *obj ) 
{ 


  {
#line 1271
  if (obj->write_domain != 64U) {
#line 1272
    return;
  } else {

  }
#line 1278
  obj->write_domain = 0U;
#line 1279
  return;
}
}
#line 1283 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_object_flush_cpu_write_domain(struct drm_gem_object *obj ) 
{ 
  struct drm_device *dev ;

  {
#line 1285
  dev = obj->dev;
#line 1287
  if (obj->write_domain != 1U) {
#line 1288
    return;
  } else {

  }
#line 1290
  i915_gem_clflush_object(obj);
#line 1291
  drm_agp_chipset_flush(dev);
#line 1292
  obj->write_domain = 0U;
#line 1293
  return;
}
}
#line 1302 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_object_set_to_gtt_domain(struct drm_gem_object *obj , int write ) 
{ 
  struct drm_i915_gem_object *obj_priv ;
  int ret ;
  long tmp ;

  {
#line 1304
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 1307
  i915_gem_object_flush_gpu_write_domain(obj);
#line 1309
  ret = i915_gem_object_wait_rendering(obj);
#line 1310
  if (ret != 0) {
#line 1311
    return (ret);
  } else {

  }
#line 1316
  if (write != 0) {
#line 1317
    obj->read_domains = obj->read_domains & 64U;
  } else {

  }
#line 1319
  i915_gem_object_flush_cpu_write_domain(obj);
#line 1324
  tmp = __builtin_expect((obj->write_domain & 4294967231U) != 0U, 0L);
#line 1324
  if (tmp != 0L) {
#line 1324
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (1324), "i" (24UL));
    ldv_24563: ;
#line 1324
    goto ldv_24563;
  } else {

  }
#line 1325
  obj->read_domains = obj->read_domains | 64U;
#line 1326
  if (write != 0) {
#line 1327
    obj->write_domain = 64U;
#line 1328
    obj_priv->dirty = 1;
  } else {

  }
#line 1331
  return (0);
}
}
#line 1341 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_object_set_to_cpu_domain(struct drm_gem_object *obj , int write ) 
{ 
  struct drm_device *dev ;
  int ret ;
  long tmp ;

  {
#line 1343
  dev = obj->dev;
#line 1346
  i915_gem_object_flush_gpu_write_domain(obj);
#line 1348
  ret = i915_gem_object_wait_rendering(obj);
#line 1349
  if (ret != 0) {
#line 1350
    return (ret);
  } else {

  }
#line 1352
  i915_gem_object_flush_gtt_write_domain(obj);
#line 1357
  i915_gem_object_set_to_full_cpu_read_domain(obj);
#line 1360
  if ((obj->read_domains & 1U) == 0U) {
#line 1361
    i915_gem_clflush_object(obj);
#line 1362
    drm_agp_chipset_flush(dev);
#line 1364
    obj->read_domains = obj->read_domains | 1U;
  } else {

  }
#line 1370
  tmp = __builtin_expect((obj->write_domain & 4294967294U) != 0U, 0L);
#line 1370
  if (tmp != 0L) {
#line 1370
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (1370), "i" (24UL));
    ldv_24570: ;
#line 1370
    goto ldv_24570;
  } else {

  }
#line 1375
  if (write != 0) {
#line 1376
    obj->read_domains = obj->read_domains & 1U;
#line 1377
    obj->write_domain = 1U;
  } else {

  }
#line 1380
  return (0);
}
}
#line 1495 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_object_set_to_gpu_domain(struct drm_gem_object *obj , uint32_t read_domains ,
                                              uint32_t write_domain ) 
{ 
  struct drm_device *dev ;
  struct drm_i915_gem_object *obj_priv ;
  uint32_t invalidate_domains ;
  uint32_t flush_domains ;
  long tmp ;
  long tmp___0 ;

  {
#line 1499
  dev = obj->dev;
#line 1500
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 1501
  invalidate_domains = 0U;
#line 1502
  flush_domains = 0U;
#line 1504
  tmp = __builtin_expect((long )((int )read_domains) & 1L, 0L);
#line 1504
  if (tmp != 0L) {
#line 1504
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (1504), "i" (24UL));
    ldv_24580: ;
#line 1504
    goto ldv_24580;
  } else {

  }
#line 1505
  tmp___0 = __builtin_expect(write_domain == 1U, 0L);
#line 1505
  if (tmp___0 != 0L) {
#line 1505
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (1505), "i" (24UL));
    ldv_24581: ;
#line 1505
    goto ldv_24581;
  } else {

  }
#line 1517
  if (write_domain == 0U) {
#line 1518
    read_domains = obj->read_domains | read_domains;
  } else {
#line 1520
    obj_priv->dirty = 1;
  }
#line 1528
  if (obj->write_domain != 0U && obj->write_domain != read_domains) {
#line 1529
    flush_domains = obj->write_domain | flush_domains;
#line 1530
    invalidate_domains = (~ obj->write_domain & read_domains) | invalidate_domains;
  } else {

  }
#line 1536
  invalidate_domains = (~ obj->read_domains & read_domains) | invalidate_domains;
#line 1537
  if ((int )(flush_domains | invalidate_domains) & 1) {
#line 1542
    i915_gem_clflush_object(obj);
  } else {

  }
#line 1545
  if ((write_domain | flush_domains) != 0U) {
#line 1546
    obj->write_domain = write_domain;
  } else {

  }
#line 1547
  obj->read_domains = read_domains;
#line 1549
  dev->invalidate_domains = dev->invalidate_domains | invalidate_domains;
#line 1550
  dev->flush_domains = dev->flush_domains | flush_domains;
#line 1551
  return;
}
}
#line 1566 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_object_set_to_full_cpu_read_domain(struct drm_gem_object *obj ) 
{ 
  struct drm_device *dev ;
  struct drm_i915_gem_object *obj_priv ;
  int i ;

  {
#line 1568
  dev = obj->dev;
#line 1569
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 1571
  if ((unsigned long )obj_priv->page_cpu_valid == (unsigned long )((uint8_t *)0)) {
#line 1572
    return;
  } else {

  }
#line 1576
  if ((int )obj->read_domains & 1) {
#line 1579
    i = 0;
#line 1579
    goto ldv_24590;
    ldv_24589: ;
#line 1580
    if ((unsigned int )*(obj_priv->page_cpu_valid + (unsigned long )i) != 0U) {
#line 1581
      goto ldv_24588;
    } else {

    }
#line 1582
    drm_clflush_pages(obj_priv->page_list + (unsigned long )i, 1UL);
    ldv_24588: 
#line 1579
    i = i + 1;
    ldv_24590: ;
#line 1579
    if ((unsigned long )i <= (obj->size - 1UL) / 4096UL) {
#line 1580
      goto ldv_24589;
    } else {

    }
#line 1584
    drm_agp_chipset_flush(dev);
  } else {

  }
#line 1590
  drm_free((void *)obj_priv->page_cpu_valid, obj->size / 4096UL, 2);
#line 1592
  obj_priv->page_cpu_valid = 0;
#line 1593
  return;
}
}
#line 1608 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_object_set_cpu_read_domain_range(struct drm_gem_object *obj ,
                                                     uint64_t offset , uint64_t size ) 
{ 
  struct drm_i915_gem_object *obj_priv ;
  int i ;
  int ret ;
  int tmp ;
  void *tmp___0 ;
  long tmp___1 ;

  {
#line 1611
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 1614
  if (offset == 0ULL && (unsigned long long )obj->size == size) {
#line 1615
    tmp = i915_gem_object_set_to_cpu_domain(obj, 0);
#line 1615
    return (tmp);
  } else {

  }
#line 1617
  i915_gem_object_flush_gpu_write_domain(obj);
#line 1619
  ret = i915_gem_object_wait_rendering(obj);
#line 1620
  if (ret != 0) {
#line 1621
    return (ret);
  } else {

  }
#line 1622
  i915_gem_object_flush_gtt_write_domain(obj);
#line 1625
  if ((unsigned long )obj_priv->page_cpu_valid == (unsigned long )((uint8_t *)0) && (int )obj->read_domains & 1) {
#line 1627
    return (0);
  } else {

  }
#line 1632
  if ((unsigned long )obj_priv->page_cpu_valid == (unsigned long )((uint8_t *)0)) {
#line 1633
    tmp___0 = drm_calloc(1UL, obj->size / 4096UL, 2);
#line 1633
    obj_priv->page_cpu_valid = (uint8_t *)tmp___0;
#line 1635
    if ((unsigned long )obj_priv->page_cpu_valid == (unsigned long )((uint8_t *)0)) {
#line 1636
      return (-12);
    } else {

    }
  } else
#line 1637
  if ((obj->read_domains & 1U) == 0U) {
#line 1638
    memset((void *)obj_priv->page_cpu_valid, 0, obj->size / 4096UL);
  } else {

  }
#line 1643
  i = (int )(offset / 4096ULL);
#line 1643
  goto ldv_24602;
  ldv_24601: ;
#line 1645
  if ((unsigned int )*(obj_priv->page_cpu_valid + (unsigned long )i) != 0U) {
#line 1646
    goto ldv_24600;
  } else {

  }
#line 1648
  drm_clflush_pages(obj_priv->page_list + (unsigned long )i, 1UL);
#line 1650
  *(obj_priv->page_cpu_valid + (unsigned long )i) = 1U;
  ldv_24600: 
#line 1644
  i = i + 1;
  ldv_24602: ;
#line 1643
  if ((unsigned long long )i <= ((offset + size) - 1ULL) / 4096ULL) {
#line 1644
    goto ldv_24601;
  } else {

  }
#line 1656
  tmp___1 = __builtin_expect((obj->write_domain & 4294967294U) != 0U, 0L);
#line 1656
  if (tmp___1 != 0L) {
#line 1656
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (1656), "i" (24UL));
    ldv_24604: ;
#line 1656
    goto ldv_24604;
  } else {

  }
#line 1658
  obj->read_domains = obj->read_domains | 1U;
#line 1660
  return (0);
}
}
#line 1670 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static uint32_t i915_gem_dev_set_domain(struct drm_device *dev ) 
{ 
  uint32_t flush_domains ;

  {
#line 1672
  flush_domains = dev->flush_domains;
#line 1678
  if ((dev->invalidate_domains | dev->flush_domains) != 0U) {
#line 1685
    i915_gem_flush(dev, dev->invalidate_domains, dev->flush_domains);
#line 1688
    dev->invalidate_domains = 0U;
#line 1689
    dev->flush_domains = 0U;
  } else {

  }
#line 1692
  return (flush_domains);
}
}
#line 1699 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_object_pin_and_relocate(struct drm_gem_object *obj , struct drm_file *file_priv ,
                                            struct drm_i915_gem_exec_object *entry ) 
{ 
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_relocation_entry reloc ;
  struct drm_i915_gem_relocation_entry *relocs ;
  struct drm_i915_gem_object *obj_priv ;
  int i ;
  int ret ;
  void *reloc_page ;
  struct drm_gem_object *target_obj ;
  struct drm_i915_gem_object *target_obj_priv ;
  uint32_t reloc_val ;
  uint32_t reloc_offset ;
  uint32_t *reloc_entry ;
  unsigned long tmp ;
  unsigned long tmp___0 ;

  {
#line 1703
  dev = obj->dev;
#line 1704
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 1707
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 1712
  ret = i915_gem_object_pin(obj, (unsigned int )entry->alignment);
#line 1713
  if (ret != 0) {
#line 1714
    return (ret);
  } else {

  }
#line 1716
  entry->offset = (uint64_t )obj_priv->gtt_offset;
#line 1718
  relocs = (struct drm_i915_gem_relocation_entry *)entry->relocs_ptr;
#line 1723
  i = 0;
#line 1723
  goto ldv_24630;
  ldv_24629: 
#line 1729
  tmp = copy_from_user((void *)(& reloc), (void const   *)relocs + (unsigned long )i,
                       32U);
#line 1729
  ret = (int )tmp;
#line 1730
  if (ret != 0) {
#line 1731
    i915_gem_object_unpin(obj);
#line 1732
    return (ret);
  } else {

  }
#line 1735
  target_obj = drm_gem_object_lookup(obj->dev, file_priv, (int )reloc.target_handle);
#line 1737
  if ((unsigned long )target_obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 1738
    i915_gem_object_unpin(obj);
#line 1739
    return (-9);
  } else {

  }
#line 1741
  target_obj_priv = (struct drm_i915_gem_object *)target_obj->driver_private;
#line 1746
  if ((unsigned long )target_obj_priv->gtt_space == (unsigned long )((struct drm_mm_node *)0)) {
#line 1747
    printk("<3>[drm:%s] *ERROR* No GTT space found for object %d\n", "i915_gem_object_pin_and_relocate",
           reloc.target_handle);
#line 1749
    drm_gem_object_unreference(target_obj);
#line 1750
    i915_gem_object_unpin(obj);
#line 1751
    return (-22);
  } else {

  }
#line 1754
  if (reloc.offset > (unsigned long long )(obj->size - 4UL)) {
#line 1755
    printk("<3>[drm:%s] *ERROR* Relocation beyond object bounds: obj %p target %d offset %d size %d.\n",
           "i915_gem_object_pin_and_relocate", obj, reloc.target_handle, (int )reloc.offset,
           (int )obj->size);
#line 1759
    drm_gem_object_unreference(target_obj);
#line 1760
    i915_gem_object_unpin(obj);
#line 1761
    return (-22);
  } else {

  }
#line 1763
  if ((reloc.offset & 3ULL) != 0ULL) {
#line 1764
    printk("<3>[drm:%s] *ERROR* Relocation not 4-byte aligned: obj %p target %d offset %d.\n",
           "i915_gem_object_pin_and_relocate", obj, reloc.target_handle, (int )reloc.offset);
#line 1768
    drm_gem_object_unreference(target_obj);
#line 1769
    i915_gem_object_unpin(obj);
#line 1770
    return (-22);
  } else {

  }
#line 1773
  if ((int )reloc.write_domain & 1 || (int )reloc.read_domains & 1) {
#line 1775
    printk("<3>[drm:%s] *ERROR* reloc with read/write CPU domains: obj %p target %d offset %d read %08x write %08x",
           "i915_gem_object_pin_and_relocate", obj, reloc.target_handle, (int )reloc.offset,
           reloc.read_domains, reloc.write_domain);
#line 1782
    return (-22);
  } else {

  }
#line 1785
  if ((reloc.write_domain != 0U && target_obj->pending_write_domain != 0U) && reloc.write_domain != target_obj->pending_write_domain) {
#line 1787
    printk("<3>[drm:%s] *ERROR* Write domain conflict: obj %p target %d offset %d new %08x old %08x\n",
           "i915_gem_object_pin_and_relocate", obj, reloc.target_handle, (int )reloc.offset,
           reloc.write_domain, target_obj->pending_write_domain);
#line 1794
    drm_gem_object_unreference(target_obj);
#line 1795
    i915_gem_object_unpin(obj);
#line 1796
    return (-22);
  } else {

  }
#line 1814
  target_obj->pending_read_domains = target_obj->pending_read_domains | reloc.read_domains;
#line 1815
  target_obj->pending_write_domain = target_obj->pending_write_domain | reloc.write_domain;
#line 1820
  if ((uint64_t )target_obj_priv->gtt_offset == reloc.presumed_offset) {
#line 1821
    drm_gem_object_unreference(target_obj);
#line 1822
    goto ldv_24628;
  } else {

  }
#line 1825
  ret = i915_gem_object_set_to_gtt_domain(obj, 1);
#line 1826
  if (ret != 0) {
#line 1827
    drm_gem_object_unreference(target_obj);
#line 1828
    i915_gem_object_unpin(obj);
#line 1829
    return (-22);
  } else {

  }
#line 1835
  reloc_offset = obj_priv->gtt_offset + (uint32_t )reloc.offset;
#line 1836
  reloc_page = io_mapping_map_atomic_wc(dev_priv->mm.gtt_mapping, (unsigned long )reloc_offset & 0xfffffffffffff000UL);
#line 1839
  reloc_entry = (uint32_t *)(reloc_page + ((unsigned long )reloc_offset & 4095UL));
#line 1841
  reloc_val = target_obj_priv->gtt_offset + reloc.delta;
#line 1848
  writel(reloc_val, (void volatile   *)reloc_entry);
#line 1849
  io_mapping_unmap_atomic(reloc_page);
#line 1854
  reloc.presumed_offset = (uint64_t )target_obj_priv->gtt_offset;
#line 1855
  tmp___0 = copy_to_user((void *)relocs + (unsigned long )i, (void const   *)(& reloc),
                         32U);
#line 1855
  ret = (int )tmp___0;
#line 1856
  if (ret != 0) {
#line 1857
    drm_gem_object_unreference(target_obj);
#line 1858
    i915_gem_object_unpin(obj);
#line 1859
    return (ret);
  } else {

  }
#line 1862
  drm_gem_object_unreference(target_obj);
  ldv_24628: 
#line 1723
  i = i + 1;
  ldv_24630: ;
#line 1723
  if ((uint32_t )i < entry->relocation_count) {
#line 1724
    goto ldv_24629;
  } else {

  }

#line 1869
  return (0);
}
}
#line 1875 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_dispatch_gem_execbuffer(struct drm_device *dev , struct drm_i915_gem_execbuffer *exec ,
                                        uint64_t exec_offset ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_clip_rect *boxes ;
  int nbox ;
  int i ;
  int count ;
  uint32_t exec_start ;
  uint32_t exec_len ;
  unsigned int outring ;
  unsigned int ringmask ;
  unsigned int outcount ;
  char volatile   *virt ;
  int ret ;
  int tmp ;

  {
#line 1879
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 1880
  boxes = (struct drm_clip_rect *)exec->cliprects_ptr;
#line 1882
  nbox = (int )exec->num_cliprects;
#line 1883
  i = 0;
#line 1887
  exec_start = (unsigned int )exec_offset + exec->batch_start_offset;
#line 1888
  exec_len = exec->batch_len;
#line 1890
  if (((exec_start | exec_len) & 7U) != 0U) {
#line 1891
    printk("<3>[drm:%s] *ERROR* alignment\n", "i915_dispatch_gem_execbuffer");
#line 1892
    return (-22);
  } else {

  }
#line 1895
  if (exec_start == 0U) {
#line 1896
    return (-22);
  } else {

  }
#line 1898
  count = nbox != 0 ? nbox : 1;
#line 1900
  i = 0;
#line 1900
  goto ldv_24651;
  ldv_24650: ;
#line 1901
  if (i < nbox) {
#line 1902
    tmp = i915_emit_box(dev, boxes, i, (int )exec->DR1, (int )exec->DR4);
#line 1902
    ret = tmp;
#line 1904
    if (ret != 0) {
#line 1905
      return (ret);
    } else {

    }
  } else {

  }
#line 1908
  if (dev->pci_device == 13687 || dev->pci_device == 9570) {
#line 1909
    if (dev_priv->ring.space <= 15) {
#line 1909
      i915_wait_ring(dev, 16, "i915_dispatch_gem_execbuffer");
    } else {

    }
#line 1909
    outcount = 0U;
#line 1909
    outring = (unsigned int )dev_priv->ring.tail;
#line 1909
    ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 1909
    virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 1910
    *((unsigned int volatile   *)virt + (unsigned long )outring) = 402653185U;
#line 1910
    outcount = outcount + 1U;
#line 1910
    outring = outring + 4U;
#line 1910
    outring = outring & ringmask;
#line 1911
    *((unsigned int volatile   *)virt + (unsigned long )outring) = exec_start | 1U;
#line 1911
    outcount = outcount + 1U;
#line 1911
    outring = outring + 4U;
#line 1911
    outring = outring & ringmask;
#line 1912
    *((unsigned int volatile   *)virt + (unsigned long )outring) = (exec_start + exec_len) - 4U;
#line 1912
    outcount = outcount + 1U;
#line 1912
    outring = outring + 4U;
#line 1912
    outring = outring & ringmask;
#line 1913
    *((unsigned int volatile   *)virt + (unsigned long )outring) = 0U;
#line 1913
    outcount = outcount + 1U;
#line 1913
    outring = outring + 4U;
#line 1913
    outring = outring & ringmask;
#line 1914
    dev_priv->ring.tail = (int )outring;
#line 1914
    dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 1914
    writel(outring, (void volatile   *)dev_priv->regs + 8240U);
  } else {
#line 1916
    if (dev_priv->ring.space <= 7) {
#line 1916
      i915_wait_ring(dev, 8, "i915_dispatch_gem_execbuffer");
    } else {

    }
#line 1916
    outcount = 0U;
#line 1916
    outring = (unsigned int )dev_priv->ring.tail;
#line 1916
    ringmask = (unsigned int )dev_priv->ring.tail_mask;
#line 1916
    virt = (char volatile   *)dev_priv->ring.virtual_start;
#line 1917
    if (((((((((dev->pci_device == 10610 || dev->pci_device == 10626) || dev->pci_device == 10642) || dev->pci_device == 10658) || dev->pci_device == 10754) || dev->pci_device == 10770) || dev->pci_device == 10818) || dev->pci_device == 11778) || dev->pci_device == 11794) || dev->pci_device == 11810) {
#line 1918
      *((unsigned int volatile   *)virt + (unsigned long )outring) = 411042176U;
#line 1918
      outcount = outcount + 1U;
#line 1918
      outring = outring + 4U;
#line 1918
      outring = outring & ringmask;
#line 1921
      *((unsigned int volatile   *)virt + (unsigned long )outring) = exec_start;
#line 1921
      outcount = outcount + 1U;
#line 1921
      outring = outring + 4U;
#line 1921
      outring = outring & ringmask;
    } else {
#line 1923
      *((unsigned int volatile   *)virt + (unsigned long )outring) = 411041920U;
#line 1923
      outcount = outcount + 1U;
#line 1923
      outring = outring + 4U;
#line 1923
      outring = outring & ringmask;
#line 1925
      *((unsigned int volatile   *)virt + (unsigned long )outring) = exec_start | 1U;
#line 1925
      outcount = outcount + 1U;
#line 1925
      outring = outring + 4U;
#line 1925
      outring = outring & ringmask;
    }
#line 1927
    dev_priv->ring.tail = (int )outring;
#line 1927
    dev_priv->ring.space = (int )((unsigned int )dev_priv->ring.space - outcount * 4U);
#line 1927
    writel(outring, (void volatile   *)dev_priv->regs + 8240U);
  }
#line 1900
  i = i + 1;
  ldv_24651: ;
#line 1900
  if (i < count) {
#line 1901
    goto ldv_24650;
  } else {

  }

#line 1932
  return (0);
}
}
#line 1942 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_ring_throttle(struct drm_device *dev , struct drm_file *file_priv ) 
{ 
  struct drm_i915_file_private *i915_file_priv ;
  int ret ;
  uint32_t seqno ;

  {
#line 1944
  i915_file_priv = (struct drm_i915_file_private *)file_priv->driver_priv;
#line 1945
  ret = 0;
#line 1948
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 1949
  seqno = i915_file_priv->mm.last_gem_throttle_seqno;
#line 1950
  i915_file_priv->mm.last_gem_throttle_seqno = i915_file_priv->mm.last_gem_seqno;
#line 1952
  if (seqno != 0U) {
#line 1953
    ret = i915_wait_request(dev, seqno);
  } else {

  }
#line 1954
  mutex_unlock(& dev->struct_mutex);
#line 1955
  return (ret);
}
}
#line 1959 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_execbuffer(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_i915_file_private *i915_file_priv ;
  struct drm_i915_gem_execbuffer *args ;
  struct drm_i915_gem_exec_object *exec_list ;
  struct drm_gem_object **object_list ;
  struct drm_gem_object *batch_obj ;
  int ret ;
  int i ;
  int pinned ;
  uint64_t exec_offset ;
  uint32_t seqno ;
  uint32_t flush_domains ;
  void *tmp ;
  void *tmp___0 ;
  unsigned long tmp___1 ;
  struct drm_gem_object *obj ;
  long tmp___2 ;
  struct drm_gem_object *obj___0 ;
  unsigned long tmp___3 ;

  {
#line 1962
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 1963
  i915_file_priv = (struct drm_i915_file_private *)file_priv->driver_priv;
#line 1964
  args = (struct drm_i915_gem_execbuffer *)data;
#line 1965
  exec_list = 0;
#line 1966
  object_list = 0;
#line 1968
  pinned = 0;
#line 1977
  if (args->buffer_count == 0U) {
#line 1978
    printk("<3>[drm:%s] *ERROR* execbuf with %d buffers\n", "i915_gem_execbuffer",
           args->buffer_count);
#line 1979
    return (-22);
  } else {

  }
#line 1982
  tmp = drm_calloc(32UL, (size_t )args->buffer_count, 2);
#line 1982
  exec_list = (struct drm_i915_gem_exec_object *)tmp;
#line 1984
  tmp___0 = drm_calloc(8UL, (size_t )args->buffer_count, 2);
#line 1984
  object_list = (struct drm_gem_object **)tmp___0;
#line 1986
  if ((unsigned long )exec_list == (unsigned long )((struct drm_i915_gem_exec_object *)0) || (unsigned long )object_list == (unsigned long )((struct drm_gem_object **)0)) {
#line 1987
    printk("<3>[drm:%s] *ERROR* Failed to allocate exec or object list for %d buffers\n",
           "i915_gem_execbuffer", args->buffer_count);
#line 1990
    ret = -12;
#line 1991
    goto pre_mutex_err;
  } else {

  }
#line 1993
  tmp___1 = copy_from_user((void *)exec_list, (void const   *)args->buffers_ptr, args->buffer_count * 32U);
#line 1993
  ret = (int )tmp___1;
#line 1997
  if (ret != 0) {
#line 1998
    printk("<3>[drm:%s] *ERROR* copy %d exec entries failed %d\n", "i915_gem_execbuffer",
           args->buffer_count, ret);
#line 2000
    goto pre_mutex_err;
  } else {

  }
#line 2003
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 2007
  if (dev_priv->mm.wedged != 0) {
#line 2008
    printk("<3>[drm:%s] *ERROR* Execbuf while wedged\n", "i915_gem_execbuffer");
#line 2009
    mutex_unlock(& dev->struct_mutex);
#line 2010
    return (-5);
  } else {

  }
#line 2013
  if (dev_priv->mm.suspended != 0) {
#line 2014
    printk("<3>[drm:%s] *ERROR* Execbuf while VT-switched.\n", "i915_gem_execbuffer");
#line 2015
    mutex_unlock(& dev->struct_mutex);
#line 2016
    return (-16);
  } else {

  }
#line 2023
  dev->invalidate_domains = 0U;
#line 2024
  dev->flush_domains = 0U;
#line 2027
  i = 0;
#line 2027
  goto ldv_24682;
  ldv_24681: 
#line 2028
  *(object_list + (unsigned long )i) = drm_gem_object_lookup(dev, file_priv, (int )(exec_list + (unsigned long )i)->handle);
#line 2030
  if ((unsigned long )*(object_list + (unsigned long )i) == (unsigned long )((struct drm_gem_object *)0)) {
#line 2031
    printk("<3>[drm:%s] *ERROR* Invalid object handle %d at index %d\n", "i915_gem_execbuffer",
           (exec_list + (unsigned long )i)->handle, i);
#line 2033
    ret = -9;
#line 2034
    goto err;
  } else {

  }
#line 2037
  (*(object_list + (unsigned long )i))->pending_read_domains = 0U;
#line 2038
  (*(object_list + (unsigned long )i))->pending_write_domain = 0U;
#line 2039
  ret = i915_gem_object_pin_and_relocate(*(object_list + (unsigned long )i), file_priv,
                                         exec_list + (unsigned long )i);
#line 2042
  if (ret != 0) {
#line 2043
    printk("<3>[drm:%s] *ERROR* object bind and relocate failed %d\n", "i915_gem_execbuffer",
           ret);
#line 2044
    goto err;
  } else {

  }
#line 2046
  pinned = i + 1;
#line 2027
  i = i + 1;
  ldv_24682: ;
#line 2027
  if ((uint32_t )i < args->buffer_count) {
#line 2028
    goto ldv_24681;
  } else {

  }
#line 2050
  batch_obj = *(object_list + (unsigned long )(args->buffer_count - 1U));
#line 2051
  batch_obj->pending_read_domains = 8U;
#line 2052
  batch_obj->pending_write_domain = 0U;
#line 2056
  i = 0;
#line 2056
  goto ldv_24686;
  ldv_24685: 
#line 2057
  obj = *(object_list + (unsigned long )i);
#line 2060
  i915_gem_object_set_to_gpu_domain(obj, obj->pending_read_domains, obj->pending_write_domain);
#line 2056
  i = i + 1;
  ldv_24686: ;
#line 2056
  if ((uint32_t )i < args->buffer_count) {
#line 2057
    goto ldv_24685;
  } else {

  }
#line 2068
  flush_domains = i915_gem_dev_set_domain(dev);
#line 2079
  exec_offset = (exec_list + (unsigned long )(args->buffer_count - 1U))->offset;
#line 2088
  i915_add_request(dev, flush_domains);
#line 2091
  ret = i915_dispatch_gem_execbuffer(dev, args, exec_offset);
#line 2092
  if (ret != 0) {
#line 2093
    printk("<3>[drm:%s] *ERROR* dispatch failed %d\n", "i915_gem_execbuffer", ret);
#line 2094
    goto err;
  } else {

  }
#line 2101
  flush_domains = i915_retire_commands(dev);
#line 2112
  seqno = i915_add_request(dev, flush_domains);
#line 2113
  tmp___2 = __builtin_expect(seqno == 0U, 0L);
#line 2113
  if (tmp___2 != 0L) {
#line 2113
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (2113), "i" (24UL));
    ldv_24688: ;
#line 2113
    goto ldv_24688;
  } else {

  }
#line 2114
  i915_file_priv->mm.last_gem_seqno = seqno;
#line 2115
  i = 0;
#line 2115
  goto ldv_24691;
  ldv_24690: 
#line 2116
  obj___0 = *(object_list + (unsigned long )i);
#line 2118
  i915_gem_object_move_to_active(obj___0, seqno);
#line 2115
  i = i + 1;
  ldv_24691: ;
#line 2115
  if ((uint32_t )i < args->buffer_count) {
#line 2116
    goto ldv_24690;
  } else {

  }
#line 2130
  tmp___3 = copy_to_user((void *)args->buffers_ptr, (void const   *)exec_list, args->buffer_count * 32U);
#line 2130
  ret = (int )tmp___3;
#line 2134
  if (ret != 0) {
#line 2135
    printk("<3>[drm:%s] *ERROR* failed to copy %d exec entries back to user (%d)\n",
           "i915_gem_execbuffer", args->buffer_count, ret);
  } else {

  }
  err: ;
#line 2139
  if ((unsigned long )object_list != (unsigned long )((struct drm_gem_object **)0)) {
#line 2140
    i = 0;
#line 2140
    goto ldv_24694;
    ldv_24693: 
#line 2141
    i915_gem_object_unpin(*(object_list + (unsigned long )i));
#line 2140
    i = i + 1;
    ldv_24694: ;
#line 2140
    if (i < pinned) {
#line 2141
      goto ldv_24693;
    } else {

    }
#line 2143
    i = 0;
#line 2143
    goto ldv_24697;
    ldv_24696: 
#line 2144
    drm_gem_object_unreference(*(object_list + (unsigned long )i));
#line 2143
    i = i + 1;
    ldv_24697: ;
#line 2143
    if ((uint32_t )i < args->buffer_count) {
#line 2144
      goto ldv_24696;
    } else {

    }

  } else {

  }
#line 2146
  mutex_unlock(& dev->struct_mutex);
  pre_mutex_err: 
#line 2149
  drm_free((void *)object_list, (unsigned long )args->buffer_count * 8UL, 2);
#line 2151
  drm_free((void *)exec_list, (unsigned long )args->buffer_count * 32UL, 2);
#line 2154
  return (ret);
}
}
#line 2158 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_object_pin(struct drm_gem_object *obj , uint32_t alignment ) 
{ 
  struct drm_device *dev ;
  struct drm_i915_gem_object *obj_priv ;
  int ret ;
  int tmp ;

  {
#line 2160
  dev = obj->dev;
#line 2161
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 2165
  if ((unsigned long )obj_priv->gtt_space == (unsigned long )((struct drm_mm_node *)0)) {
#line 2166
    ret = i915_gem_object_bind_to_gtt(obj, alignment);
#line 2167
    if (ret != 0) {
#line 2168
      printk("<3>[drm:%s] *ERROR* Failure to bind: %d", "i915_gem_object_pin", ret);
#line 2169
      return (ret);
    } else {

    }
  } else {

  }
#line 2172
  obj_priv->pin_count = obj_priv->pin_count + 1;
#line 2177
  if (obj_priv->pin_count == 1) {
#line 2178
    atomic_inc(& dev->pin_count);
#line 2179
    atomic_add((int )obj->size, & dev->pin_memory);
#line 2180
    if (obj_priv->active == 0 && (obj->write_domain & 4294967230U) == 0U) {
#line 2180
      tmp = list_empty((struct list_head  const  *)(& obj_priv->list));
#line 2180
      if (tmp == 0) {
#line 2184
        list_del_init(& obj_priv->list);
      } else {

      }
    } else {

    }
  } else {

  }
#line 2188
  return (0);
}
}
#line 2192 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
void i915_gem_object_unpin(struct drm_gem_object *obj ) 
{ 
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_object *obj_priv ;
  long tmp ;
  long tmp___0 ;

  {
#line 2194
  dev = obj->dev;
#line 2195
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 2196
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 2199
  obj_priv->pin_count = obj_priv->pin_count - 1;
#line 2200
  tmp = __builtin_expect(obj_priv->pin_count < 0, 0L);
#line 2200
  if (tmp != 0L) {
#line 2200
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (2200), "i" (24UL));
    ldv_24713: ;
#line 2200
    goto ldv_24713;
  } else {

  }
#line 2201
  tmp___0 = __builtin_expect((unsigned long )obj_priv->gtt_space == (unsigned long )((struct drm_mm_node *)0),
                             0L);
#line 2201
  if (tmp___0 != 0L) {
#line 2201
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (2201), "i" (24UL));
    ldv_24714: ;
#line 2201
    goto ldv_24714;
  } else {

  }
#line 2207
  if (obj_priv->pin_count == 0) {
#line 2208
    if (obj_priv->active == 0 && (obj->write_domain & 4294967230U) == 0U) {
#line 2211
      list_move_tail(& obj_priv->list, & dev_priv->mm.inactive_list);
    } else {

    }
#line 2213
    atomic_dec(& dev->pin_count);
#line 2214
    atomic_sub((int )obj->size, & dev->pin_memory);
  } else {

  }
#line 2216
  return;
}
}
#line 2220 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_pin_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_pin *args ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;
  int ret ;

  {
#line 2223
  args = (struct drm_i915_gem_pin *)data;
#line 2228
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 2230
  obj = drm_gem_object_lookup(dev, file_priv, (int )args->handle);
#line 2231
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 2232
    printk("<3>[drm:%s] *ERROR* Bad handle in i915_gem_pin_ioctl(): %d\n", "i915_gem_pin_ioctl",
           args->handle);
#line 2234
    mutex_unlock(& dev->struct_mutex);
#line 2235
    return (-9);
  } else {

  }
#line 2237
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 2239
  ret = i915_gem_object_pin(obj, (uint32_t )args->alignment);
#line 2240
  if (ret != 0) {
#line 2241
    drm_gem_object_unreference(obj);
#line 2242
    mutex_unlock(& dev->struct_mutex);
#line 2243
    return (ret);
  } else {

  }
#line 2249
  i915_gem_object_flush_cpu_write_domain(obj);
#line 2250
  args->offset = (uint64_t )obj_priv->gtt_offset;
#line 2251
  drm_gem_object_unreference(obj);
#line 2252
  mutex_unlock(& dev->struct_mutex);
#line 2254
  return (0);
}
}
#line 2258 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_unpin_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_pin *args ;
  struct drm_gem_object *obj ;

  {
#line 2261
  args = (struct drm_i915_gem_pin *)data;
#line 2264
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 2266
  obj = drm_gem_object_lookup(dev, file_priv, (int )args->handle);
#line 2267
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 2268
    printk("<3>[drm:%s] *ERROR* Bad handle in i915_gem_unpin_ioctl(): %d\n", "i915_gem_unpin_ioctl",
           args->handle);
#line 2270
    mutex_unlock(& dev->struct_mutex);
#line 2271
    return (-9);
  } else {

  }
#line 2274
  i915_gem_object_unpin(obj);
#line 2276
  drm_gem_object_unreference(obj);
#line 2277
  mutex_unlock(& dev->struct_mutex);
#line 2278
  return (0);
}
}
#line 2282 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_busy_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_busy *args ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;

  {
#line 2285
  args = (struct drm_i915_gem_busy *)data;
#line 2289
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 2290
  obj = drm_gem_object_lookup(dev, file_priv, (int )args->handle);
#line 2291
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 2292
    printk("<3>[drm:%s] *ERROR* Bad handle in i915_gem_busy_ioctl(): %d\n", "i915_gem_busy_ioctl",
           args->handle);
#line 2294
    mutex_unlock(& dev->struct_mutex);
#line 2295
    return (-9);
  } else {

  }
#line 2298
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 2299
  args->busy = (uint32_t )obj_priv->active;
#line 2301
  drm_gem_object_unreference(obj);
#line 2302
  mutex_unlock(& dev->struct_mutex);
#line 2303
  return (0);
}
}
#line 2307 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_throttle_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  int tmp ;

  {
#line 2310
  tmp = i915_gem_ring_throttle(dev, file_priv);
#line 2310
  return (tmp);
}
}
#line 2313 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_init_object(struct drm_gem_object *obj ) 
{ 
  struct drm_i915_gem_object *obj_priv ;
  void *tmp ;

  {
#line 2317
  tmp = drm_calloc(1UL, 88UL, 2);
#line 2317
  obj_priv = (struct drm_i915_gem_object *)tmp;
#line 2318
  if ((unsigned long )obj_priv == (unsigned long )((struct drm_i915_gem_object *)0)) {
#line 2319
    return (-12);
  } else {

  }
#line 2327
  obj->write_domain = 1U;
#line 2328
  obj->read_domains = 1U;
#line 2330
  obj_priv->agp_type = 65536U;
#line 2332
  obj->driver_private = (void *)obj_priv;
#line 2333
  obj_priv->obj = obj;
#line 2334
  INIT_LIST_HEAD(& obj_priv->list);
#line 2335
  return (0);
}
}
#line 2338 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
void i915_gem_free_object(struct drm_gem_object *obj ) 
{ 
  struct drm_i915_gem_object *obj_priv ;

  {
#line 2340
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 2342
  goto ldv_24756;
  ldv_24755: 
#line 2343
  i915_gem_object_unpin(obj);
  ldv_24756: ;
#line 2342
  if (obj_priv->pin_count > 0) {
#line 2343
    goto ldv_24755;
  } else {

  }
#line 2345
  i915_gem_object_unbind(obj);
#line 2347
  drm_free((void *)obj_priv->page_cpu_valid, 1UL, 2);
#line 2348
  drm_free(obj->driver_private, 1UL, 2);
#line 2349
  return;
}
}
#line 2353 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_evict_from_list(struct drm_device *dev , struct list_head *head ) 
{ 
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;
  int ret ;
  struct list_head  const  *__mptr ;
  int tmp ;

  {
#line 2359
  goto ldv_24769;
  ldv_24768: 
#line 2360
  __mptr = (struct list_head  const  *)head->next;
#line 2360
  obj_priv = (struct drm_i915_gem_object *)__mptr + 0xfffffffffffffff0UL;
#line 2363
  obj = obj_priv->obj;
#line 2365
  if (obj_priv->pin_count != 0) {
#line 2366
    printk("<3>[drm:%s] *ERROR* Pinned object in unbind list\n", "i915_gem_evict_from_list");
#line 2367
    mutex_unlock(& dev->struct_mutex);
#line 2368
    return (-22);
  } else {

  }
#line 2371
  ret = i915_gem_object_unbind(obj);
#line 2372
  if (ret != 0) {
#line 2373
    printk("<3>[drm:%s] *ERROR* Error unbinding object in LeaveVT: %d\n", "i915_gem_evict_from_list",
           ret);
#line 2375
    mutex_unlock(& dev->struct_mutex);
#line 2376
    return (ret);
  } else {

  }
  ldv_24769: 
#line 2359
  tmp = list_empty((struct list_head  const  *)head);
#line 2359
  if (tmp == 0) {
#line 2360
    goto ldv_24768;
  } else {

  }

#line 2381
  return (0);
}
}
#line 2385 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_idle(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  uint32_t seqno ;
  uint32_t cur_seqno ;
  uint32_t last_seqno ;
  int stuck ;
  int ret ;
  int tmp ;
  int tmp___0 ;
  int __ret_warn_on ;
  int tmp___1 ;
  long tmp___2 ;
  int __ret_warn_on___0 ;
  int tmp___3 ;
  long tmp___4 ;
  int __ret_warn_on___1 ;
  int tmp___5 ;
  long tmp___6 ;
  struct drm_i915_gem_object *obj_priv ;
  struct list_head  const  *__mptr ;
  int tmp___7 ;
  struct drm_i915_gem_object *obj_priv___0 ;
  struct list_head  const  *__mptr___0 ;
  int tmp___8 ;
  int __ret_warn_on___2 ;
  int tmp___9 ;
  long tmp___10 ;

  {
#line 2387
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 2391
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 2393
  if (dev_priv->mm.suspended != 0 || (unsigned long )dev_priv->ring.ring_obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 2394
    mutex_unlock(& dev->struct_mutex);
#line 2395
    return (0);
  } else {

  }
#line 2401
  dev_priv->mm.suspended = 1;
#line 2405
  mutex_unlock(& dev->struct_mutex);
#line 2406
  cancel_delayed_work_sync(& dev_priv->mm.retire_work);
#line 2407
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 2409
  i915_kernel_lost_context(dev);
#line 2413
  i915_gem_flush(dev, 4294967230U, 4294967230U);
#line 2415
  seqno = i915_add_request(dev, 4294967230U);
#line 2418
  if (seqno == 0U) {
#line 2419
    mutex_unlock(& dev->struct_mutex);
#line 2420
    return (-12);
  } else {

  }
#line 2423
  dev_priv->mm.waiting_gem_seqno = seqno;
#line 2424
  last_seqno = 0U;
#line 2425
  stuck = 0;
  ldv_24782: 
#line 2427
  cur_seqno = i915_get_gem_seqno(dev);
#line 2428
  tmp = i915_seqno_passed(cur_seqno, seqno);
#line 2428
  if (tmp != 0) {
#line 2429
    goto ldv_24780;
  } else {

  }
#line 2430
  if (last_seqno == cur_seqno) {
#line 2431
    tmp___0 = stuck;
#line 2431
    stuck = stuck + 1;
#line 2431
    if (tmp___0 > 100) {
#line 2432
      printk("<3>[drm:%s] *ERROR* hardware wedged\n", "i915_gem_idle");
#line 2433
      dev_priv->mm.wedged = 1;
#line 2434
      __wake_up(& dev_priv->irq_queue, 1U, 1, 0);
#line 2435
      goto ldv_24780;
    } else {

    }
  } else {

  }
#line 2438
  msleep(10U);
#line 2439
  last_seqno = cur_seqno;
#line 2440
  goto ldv_24782;
  ldv_24780: 
#line 2441
  dev_priv->mm.waiting_gem_seqno = 0U;
#line 2443
  i915_gem_retire_requests(dev);
#line 2445
  if (dev_priv->mm.wedged == 0) {
#line 2449
    tmp___1 = list_empty((struct list_head  const  *)(& dev_priv->mm.active_list));
#line 2449
    __ret_warn_on = tmp___1 == 0;
#line 2449
    tmp___2 = __builtin_expect(__ret_warn_on != 0, 0L);
#line 2449
    if (tmp___2 != 0L) {
#line 2449
      warn_on_slowpath("/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared",
                       2449);
    } else {

    }
#line 2449
    __builtin_expect(__ret_warn_on != 0, 0L);
#line 2450
    tmp___3 = list_empty((struct list_head  const  *)(& dev_priv->mm.flushing_list));
#line 2450
    __ret_warn_on___0 = tmp___3 == 0;
#line 2450
    tmp___4 = __builtin_expect(__ret_warn_on___0 != 0, 0L);
#line 2450
    if (tmp___4 != 0L) {
#line 2450
      warn_on_slowpath("/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared",
                       2450);
    } else {

    }
#line 2450
    __builtin_expect(__ret_warn_on___0 != 0, 0L);
#line 2454
    tmp___5 = list_empty((struct list_head  const  *)(& dev_priv->mm.request_list));
#line 2454
    __ret_warn_on___1 = tmp___5 == 0;
#line 2454
    tmp___6 = __builtin_expect(__ret_warn_on___1 != 0, 0L);
#line 2454
    if (tmp___6 != 0L) {
#line 2454
      warn_on_slowpath("/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared",
                       2454);
    } else {

    }
#line 2454
    __builtin_expect(__ret_warn_on___1 != 0, 0L);
  } else {

  }
#line 2462
  goto ldv_24793;
  ldv_24792: 
#line 2465
  __mptr = (struct list_head  const  *)dev_priv->mm.active_list.next;
#line 2465
  obj_priv = (struct drm_i915_gem_object *)__mptr + 0xfffffffffffffff0UL;
#line 2468
  (obj_priv->obj)->write_domain = (obj_priv->obj)->write_domain & 65U;
#line 2469
  i915_gem_object_move_to_inactive(obj_priv->obj);
  ldv_24793: 
#line 2462
  tmp___7 = list_empty((struct list_head  const  *)(& dev_priv->mm.active_list));
#line 2462
  if (tmp___7 == 0) {
#line 2463
    goto ldv_24792;
  } else {

  }

#line 2472
  goto ldv_24799;
  ldv_24798: 
#line 2475
  __mptr___0 = (struct list_head  const  *)dev_priv->mm.flushing_list.next;
#line 2475
  obj_priv___0 = (struct drm_i915_gem_object *)__mptr___0 + 0xfffffffffffffff0UL;
#line 2478
  (obj_priv___0->obj)->write_domain = (obj_priv___0->obj)->write_domain & 65U;
#line 2479
  i915_gem_object_move_to_inactive(obj_priv___0->obj);
  ldv_24799: 
#line 2472
  tmp___8 = list_empty((struct list_head  const  *)(& dev_priv->mm.flushing_list));
#line 2472
  if (tmp___8 == 0) {
#line 2473
    goto ldv_24798;
  } else {

  }
#line 2484
  ret = i915_gem_evict_from_list(dev, & dev_priv->mm.inactive_list);
#line 2485
  tmp___9 = list_empty((struct list_head  const  *)(& dev_priv->mm.inactive_list));
#line 2485
  __ret_warn_on___2 = tmp___9 == 0;
#line 2485
  tmp___10 = __builtin_expect(__ret_warn_on___2 != 0, 0L);
#line 2485
  if (tmp___10 != 0L) {
#line 2485
    warn_on_slowpath("/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared",
                     2485);
  } else {

  }
#line 2485
  __builtin_expect(__ret_warn_on___2 != 0, 0L);
#line 2486
  if (ret != 0) {
#line 2487
    mutex_unlock(& dev->struct_mutex);
#line 2488
    return (ret);
  } else {

  }
#line 2491
  i915_gem_cleanup_ringbuffer(dev);
#line 2492
  mutex_unlock(& dev->struct_mutex);
#line 2494
  return (0);
}
}
#line 2498 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_init_hws(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;
  int ret ;

  {
#line 2500
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 2508
  if ((((dev->pci_device != 10690 && dev->pci_device != 10674) && dev->pci_device != 10706) && dev->pci_device != 10818) && ((dev->pci_device != 11778 && dev->pci_device != 11794) && dev->pci_device != 11810)) {
#line 2509
    return (0);
  } else {

  }
#line 2511
  obj = drm_gem_object_alloc(dev, 4096UL);
#line 2512
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 2513
    printk("<3>[drm:%s] *ERROR* Failed to allocate status page\n", "i915_gem_init_hws");
#line 2514
    return (-12);
  } else {

  }
#line 2516
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 2517
  obj_priv->agp_type = 65537U;
#line 2519
  ret = i915_gem_object_pin(obj, 4096U);
#line 2520
  if (ret != 0) {
#line 2521
    drm_gem_object_unreference(obj);
#line 2522
    return (ret);
  } else {

  }
#line 2525
  dev_priv->status_gfx_addr = obj_priv->gtt_offset;
#line 2527
  dev_priv->hw_status_page = kmap(*(obj_priv->page_list));
#line 2528
  if ((unsigned long )dev_priv->hw_status_page == (unsigned long )((void *)0)) {
#line 2529
    printk("<3>[drm:%s] *ERROR* Failed to map status page.\n", "i915_gem_init_hws");
#line 2530
    memset((void *)(& dev_priv->hws_map), 0, 40UL);
#line 2531
    drm_gem_object_unreference(obj);
#line 2532
    return (-22);
  } else {

  }
#line 2534
  dev_priv->hws_obj = obj;
#line 2535
  memset(dev_priv->hw_status_page, 0, 4096UL);
#line 2536
  writel(dev_priv->status_gfx_addr, (void volatile   *)dev_priv->regs + 8320U);
#line 2537
  readl((void const volatile   *)dev_priv->regs + 8320U);
#line 2538
  if (drm_debug != 0U) {
#line 2538
    printk("<7>[drm:%s] hws offset: 0x%08x\n", "i915_gem_init_hws", dev_priv->status_gfx_addr);
  } else {

  }
#line 2540
  return (0);
}
}
#line 2544 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static int i915_gem_init_ringbuffer(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;
  int ret ;
  u32 head ;
  unsigned int tmp ;
  unsigned int tmp___0 ;
  unsigned int tmp___1 ;
  unsigned int tmp___2 ;
  unsigned int tmp___3 ;
  unsigned int tmp___4 ;
  unsigned int tmp___5 ;
  unsigned int tmp___6 ;
  unsigned int tmp___7 ;
  unsigned int tmp___8 ;
  unsigned int tmp___9 ;
  unsigned int tmp___10 ;
  unsigned int tmp___11 ;
  unsigned int tmp___12 ;

  {
#line 2546
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 2552
  ret = i915_gem_init_hws(dev);
#line 2553
  if (ret != 0) {
#line 2554
    return (ret);
  } else {

  }
#line 2556
  obj = drm_gem_object_alloc(dev, 131072UL);
#line 2557
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 2558
    printk("<3>[drm:%s] *ERROR* Failed to allocate ringbuffer\n", "i915_gem_init_ringbuffer");
#line 2559
    return (-12);
  } else {

  }
#line 2561
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 2563
  ret = i915_gem_object_pin(obj, 4096U);
#line 2564
  if (ret != 0) {
#line 2565
    drm_gem_object_unreference(obj);
#line 2566
    return (ret);
  } else {

  }
#line 2570
  dev_priv->ring.Size = obj->size;
#line 2571
  dev_priv->ring.tail_mask = (int )((unsigned int )obj->size - 1U);
#line 2573
  dev_priv->ring.map.offset = (dev->agp)->base + (unsigned long )obj_priv->gtt_offset;
#line 2574
  dev_priv->ring.map.size = obj->size;
#line 2575
  dev_priv->ring.map.type = _DRM_FRAME_BUFFER;
#line 2576
  dev_priv->ring.map.flags = 0;
#line 2577
  dev_priv->ring.map.mtrr = 0;
#line 2579
  drm_core_ioremap_wc(& dev_priv->ring.map, dev);
#line 2580
  if ((unsigned long )dev_priv->ring.map.handle == (unsigned long )((void *)0)) {
#line 2581
    printk("<3>[drm:%s] *ERROR* Failed to map ringbuffer.\n", "i915_gem_init_ringbuffer");
#line 2582
    memset((void *)(& dev_priv->ring), 0, 88UL);
#line 2583
    drm_gem_object_unreference(obj);
#line 2584
    return (-22);
  } else {

  }
#line 2586
  dev_priv->ring.ring_obj = obj;
#line 2587
  dev_priv->ring.virtual_start = (u8 *)dev_priv->ring.map.handle;
#line 2590
  writel(0U, (void volatile   *)dev_priv->regs + 8252U);
#line 2591
  writel(0U, (void volatile   *)dev_priv->regs + 8240U);
#line 2592
  writel(0U, (void volatile   *)dev_priv->regs + 8244U);
#line 2595
  writel(obj_priv->gtt_offset, (void volatile   *)dev_priv->regs + 8248U);
#line 2596
  tmp = readl((void const volatile   *)dev_priv->regs + 8244U);
#line 2596
  head = tmp & 2097148U;
#line 2599
  if (head != 0U) {
#line 2600
    tmp___0 = readl((void const volatile   *)dev_priv->regs + 8248U);
#line 2600
    tmp___1 = readl((void const volatile   *)dev_priv->regs + 8240U);
#line 2600
    tmp___2 = readl((void const volatile   *)dev_priv->regs + 8244U);
#line 2600
    tmp___3 = readl((void const volatile   *)dev_priv->regs + 8252U);
#line 2600
    printk("<3>[drm:%s] *ERROR* Ring head not reset to zero ctl %08x head %08x tail %08x start %08x\n",
           "i915_gem_init_ringbuffer", tmp___3, tmp___2, tmp___1, tmp___0);
#line 2606
    writel(0U, (void volatile   *)dev_priv->regs + 8244U);
#line 2608
    tmp___4 = readl((void const volatile   *)dev_priv->regs + 8248U);
#line 2608
    tmp___5 = readl((void const volatile   *)dev_priv->regs + 8240U);
#line 2608
    tmp___6 = readl((void const volatile   *)dev_priv->regs + 8244U);
#line 2608
    tmp___7 = readl((void const volatile   *)dev_priv->regs + 8252U);
#line 2608
    printk("<3>[drm:%s] *ERROR* Ring head forced to zero ctl %08x head %08x tail %08x start %08x\n",
           "i915_gem_init_ringbuffer", tmp___7, tmp___6, tmp___5, tmp___4);
  } else {

  }
#line 2616
  writel((((unsigned int )obj->size - 4096U) & 2093056U) | 1U, (void volatile   *)dev_priv->regs + 8252U);
#line 2621
  tmp___8 = readl((void const volatile   *)dev_priv->regs + 8244U);
#line 2621
  head = tmp___8 & 2097148U;
#line 2624
  if (head != 0U) {
#line 2625
    tmp___9 = readl((void const volatile   *)dev_priv->regs + 8248U);
#line 2625
    tmp___10 = readl((void const volatile   *)dev_priv->regs + 8240U);
#line 2625
    tmp___11 = readl((void const volatile   *)dev_priv->regs + 8244U);
#line 2625
    tmp___12 = readl((void const volatile   *)dev_priv->regs + 8252U);
#line 2625
    printk("<3>[drm:%s] *ERROR* Ring initialization failed ctl %08x head %08x tail %08x start %08x\n",
           "i915_gem_init_ringbuffer", tmp___12, tmp___11, tmp___10, tmp___9);
#line 2631
    return (-5);
  } else {

  }
#line 2635
  i915_kernel_lost_context(dev);
#line 2637
  return (0);
}
}
#line 2641 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
static void i915_gem_cleanup_ringbuffer(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;

  {
#line 2643
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 2645
  if ((unsigned long )dev_priv->ring.ring_obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 2646
    return;
  } else {

  }
#line 2648
  drm_core_ioremapfree(& dev_priv->ring.map, dev);
#line 2650
  i915_gem_object_unpin(dev_priv->ring.ring_obj);
#line 2651
  drm_gem_object_unreference(dev_priv->ring.ring_obj);
#line 2652
  dev_priv->ring.ring_obj = 0;
#line 2653
  memset((void *)(& dev_priv->ring), 0, 88UL);
#line 2655
  if ((unsigned long )dev_priv->hws_obj != (unsigned long )((struct drm_gem_object *)0)) {
#line 2656
    obj = dev_priv->hws_obj;
#line 2657
    obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 2660
    i915_gem_object_unpin(obj);
#line 2661
    drm_gem_object_unreference(obj);
#line 2662
    dev_priv->hws_obj = 0;
#line 2663
    memset((void *)(& dev_priv->hws_map), 0, 40UL);
#line 2664
    dev_priv->hw_status_page = 0;
#line 2667
    writel(536866816U, (void volatile   *)dev_priv->regs + 8320U);
  } else {

  }
#line 2669
  return;
}
}
#line 2672 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_entervt_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  int ret ;
  int tmp ;
  long tmp___0 ;
  int tmp___1 ;
  long tmp___2 ;
  int tmp___3 ;
  long tmp___4 ;
  int tmp___5 ;
  long tmp___6 ;

  {
#line 2675
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 2678
  if (dev_priv->mm.wedged != 0) {
#line 2679
    printk("<3>[drm:%s] *ERROR* Reenabling wedged hardware, good luck\n", "i915_gem_entervt_ioctl");
#line 2680
    dev_priv->mm.wedged = 0;
  } else {

  }
#line 2683
  ret = i915_gem_init_ringbuffer(dev);
#line 2684
  if (ret != 0) {
#line 2685
    return (ret);
  } else {

  }
#line 2687
  dev_priv->mm.gtt_mapping = io_mapping_create_wc((dev->agp)->base, (dev->agp)->agp_info.aper_size * 1048576UL);
#line 2691
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 2692
  tmp = list_empty((struct list_head  const  *)(& dev_priv->mm.active_list));
#line 2692
  tmp___0 = __builtin_expect(tmp == 0, 0L);
#line 2692
  if (tmp___0 != 0L) {
#line 2692
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (2692), "i" (24UL));
    ldv_24834: ;
#line 2692
    goto ldv_24834;
  } else {

  }
#line 2693
  tmp___1 = list_empty((struct list_head  const  *)(& dev_priv->mm.flushing_list));
#line 2693
  tmp___2 = __builtin_expect(tmp___1 == 0, 0L);
#line 2693
  if (tmp___2 != 0L) {
#line 2693
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (2693), "i" (24UL));
    ldv_24835: ;
#line 2693
    goto ldv_24835;
  } else {

  }
#line 2694
  tmp___3 = list_empty((struct list_head  const  *)(& dev_priv->mm.inactive_list));
#line 2694
  tmp___4 = __builtin_expect(tmp___3 == 0, 0L);
#line 2694
  if (tmp___4 != 0L) {
#line 2694
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (2694), "i" (24UL));
    ldv_24836: ;
#line 2694
    goto ldv_24836;
  } else {

  }
#line 2695
  tmp___5 = list_empty((struct list_head  const  *)(& dev_priv->mm.request_list));
#line 2695
  tmp___6 = __builtin_expect(tmp___5 == 0, 0L);
#line 2695
  if (tmp___6 != 0L) {
#line 2695
    __asm__  volatile   ("1:\tud2\n.pushsection __bug_table,\"a\"\n2:\t.quad 1b, %c0\n\t.word %c1, 0\n\t.org 2b+%c2\n.popsection": : "i" ((char *)"/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"),
                         "i" (2695), "i" (24UL));
    ldv_24837: ;
#line 2695
    goto ldv_24837;
  } else {

  }
#line 2696
  dev_priv->mm.suspended = 0;
#line 2697
  mutex_unlock(& dev->struct_mutex);
#line 2699
  drm_irq_install(dev);
#line 2701
  return (0);
}
}
#line 2705 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
int i915_gem_leavevt_ioctl(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  drm_i915_private_t *dev_priv ;
  int ret ;

  {
#line 2708
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 2711
  ret = i915_gem_idle(dev);
#line 2712
  drm_irq_uninstall(dev);
#line 2714
  io_mapping_free(dev_priv->mm.gtt_mapping);
#line 2715
  return (ret);
}
}
#line 2719 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
void i915_gem_lastclose(struct drm_device *dev ) 
{ 
  int ret ;

  {
#line 2723
  ret = i915_gem_idle(dev);
#line 2724
  if (ret != 0) {
#line 2725
    printk("<3>[drm:%s] *ERROR* failed to idle hardware: %d\n", "i915_gem_lastclose",
           ret);
  } else {

  }
#line 2726
  return;
}
}
#line 2729 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
void i915_gem_load(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  struct lock_class_key __key ;
  atomic_long_t __constr_expr_0 ;

  {
#line 2731
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 2733
  INIT_LIST_HEAD(& dev_priv->mm.active_list);
#line 2734
  INIT_LIST_HEAD(& dev_priv->mm.flushing_list);
#line 2735
  INIT_LIST_HEAD(& dev_priv->mm.inactive_list);
#line 2736
  INIT_LIST_HEAD(& dev_priv->mm.request_list);
#line 2737
  __constr_expr_0.counter = 0L;
#line 2737
  dev_priv->mm.retire_work.work.data = __constr_expr_0;
#line 2737
  lockdep_init_map(& dev_priv->mm.retire_work.work.lockdep_map, "&(&dev_priv->mm.retire_work)->work",
                   & __key, 0);
#line 2737
  INIT_LIST_HEAD(& dev_priv->mm.retire_work.work.entry);
#line 2737
  dev_priv->mm.retire_work.work.func = & i915_gem_retire_work_handler;
#line 2737
  init_timer(& dev_priv->mm.retire_work.timer);
#line 2739
  dev_priv->mm.next_gem_seqno = 1U;
#line 2741
  i915_gem_detect_bit_6_swizzle(dev);
#line 2742
  return;
}
}
#line 2755 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
unsigned long ldv___get_free_pages_82(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 2761
  ldv_check_alloc_flags(ldv_func_arg1);
#line 2763
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 2763
  return (tmp);
}
}
#line 2777 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
void *ldv_kmem_cache_alloc_84(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 2783
  ldv_check_alloc_flags(ldv_func_arg2);
#line 2785
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 2786
  return ((void *)0);
}
}
#line 2800 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
__inline static void *kcalloc(size_t n , size_t size , gfp_t flags ) 
{ 


  {
#line 2807
  ldv_check_alloc_flags(flags);
#line 2809
  ldv_kcalloc_86(n, size, flags);
#line 2810
  return ((void *)0);
}
}
#line 2821 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
void *ldv_kmem_cache_alloc_88(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 2827
  ldv_check_alloc_flags(ldv_func_arg2);
#line 2829
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 2830
  return ((void *)0);
}
}
#line 2864 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem.c.prepared"
struct page *ldv_alloc_page_vma_92(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                   unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 2871
  ldv_check_alloc_flags(ldv_func_arg1);
#line 2873
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 2873
  return (tmp);
}
}
#line 227 "include/linux/gfp.h"
struct page *ldv_alloc_page_vma_108(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                    unsigned long ldv_func_arg3 ) ;
#line 239
unsigned long ldv___get_free_pages_98(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 207 "include/linux/slub_def.h"
void *ldv_kmem_cache_alloc_100(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_104(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 58 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_debug.c.prepared"
unsigned long ldv___get_free_pages_98(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 64
  ldv_check_alloc_flags(ldv_func_arg1);
#line 66
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 66
  return (tmp);
}
}
#line 80 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_debug.c.prepared"
void *ldv_kmem_cache_alloc_100(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 86
  ldv_check_alloc_flags(ldv_func_arg2);
#line 88
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 89
  return ((void *)0);
}
}
#line 124 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_debug.c.prepared"
void *ldv_kmem_cache_alloc_104(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 130
  ldv_check_alloc_flags(ldv_func_arg2);
#line 132
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 133
  return ((void *)0);
}
}
#line 167 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_debug.c.prepared"
struct page *ldv_alloc_page_vma_108(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                    unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 174
  ldv_check_alloc_flags(ldv_func_arg1);
#line 176
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 176
  return (tmp);
}
}
#line 1 "<compiler builtins>"
void __builtin_prefetch(void const   *  , ...) ;
#line 163 "include/linux/kernel.h"
extern int sprintf(char * , char const   *  , ...) ;
#line 227 "include/linux/gfp.h"
struct page *ldv_alloc_page_vma_124(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                    unsigned long ldv_func_arg3 ) ;
#line 239
unsigned long ldv___get_free_pages_114(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 207 "include/linux/slub_def.h"
void *ldv_kmem_cache_alloc_116(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_120(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 115 "include/linux/proc_fs.h"
extern struct proc_dir_entry *create_proc_entry(char const   * , mode_t  , struct proc_dir_entry * ) ;
#line 121
extern void remove_proc_entry(char const   * , struct proc_dir_entry * ) ;
#line 48 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
static int i915_gem_active_info(char *buf , char **start , off_t offset , int request ,
                                int *eof , void *data ) 
{ 
  struct drm_minor *minor ;
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_object *obj_priv ;
  int len ;
  int tmp ;
  struct list_head  const  *__mptr ;
  struct drm_gem_object *obj ;
  int tmp___0 ;
  int tmp___1 ;
  struct list_head  const  *__mptr___0 ;

  {
#line 51
  minor = (struct drm_minor *)data;
#line 52
  dev = minor->dev;
#line 53
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 55
  len = 0;
#line 57
  if ((unsigned long )offset > 4016UL) {
#line 58
    *eof = 1;
#line 59
    return (0);
  } else {

  }
#line 62
  *start = buf + (unsigned long )offset;
#line 63
  *eof = 0;
#line 64
  tmp = sprintf(buf + (unsigned long )len, "Active:\n");
#line 64
  len = tmp + len;
#line 64
  if ((unsigned int )len > 4016U) {
#line 64
    *eof = 1;
#line 64
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 65
  __mptr = (struct list_head  const  *)dev_priv->mm.active_list.next;
#line 65
  obj_priv = (struct drm_i915_gem_object *)__mptr + 0xfffffffffffffff0UL;
#line 65
  goto ldv_23810;
  ldv_23809: 
#line 68
  obj = obj_priv->obj;
#line 69
  if (obj->name != 0) {
#line 70
    tmp___0 = sprintf(buf + (unsigned long )len, "    %p(%d): %08x %08x %d\n", obj,
                      obj->name, obj->read_domains, obj->write_domain, obj_priv->last_rendering_seqno);
#line 70
    len = tmp___0 + len;
#line 70
    if ((unsigned int )len > 4016U) {
#line 70
      *eof = 1;
#line 70
      return ((int )((unsigned int )len - (unsigned int )offset));
    } else {

    }
  } else {
#line 75
    tmp___1 = sprintf(buf + (unsigned long )len, "       %p: %08x %08x %d\n", obj,
                      obj->read_domains, obj->write_domain, obj_priv->last_rendering_seqno);
#line 75
    len = tmp___1 + len;
#line 75
    if ((unsigned int )len > 4016U) {
#line 75
      *eof = 1;
#line 75
      return ((int )((unsigned int )len - (unsigned int )offset));
    } else {

    }
  }
#line 65
  __mptr___0 = (struct list_head  const  *)obj_priv->list.next;
#line 65
  obj_priv = (struct drm_i915_gem_object *)__mptr___0 + 0xfffffffffffffff0UL;
  ldv_23810: 
#line 65
  __builtin_prefetch((void const   *)obj_priv->list.next);
#line 65
  if ((unsigned long )(& obj_priv->list) != (unsigned long )(& dev_priv->mm.active_list)) {
#line 66
    goto ldv_23809;
  } else {

  }

#line 81
  if ((off_t )len > (off_t )request + offset) {
#line 82
    return (request);
  } else {

  }
#line 83
  *eof = 1;
#line 84
  return ((int )((unsigned int )len - (unsigned int )offset));
}
}
#line 87 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
static int i915_gem_flushing_info(char *buf , char **start , off_t offset , int request ,
                                  int *eof , void *data ) 
{ 
  struct drm_minor *minor ;
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_object *obj_priv ;
  int len ;
  int tmp ;
  struct list_head  const  *__mptr ;
  struct drm_gem_object *obj ;
  int tmp___0 ;
  int tmp___1 ;
  struct list_head  const  *__mptr___0 ;

  {
#line 90
  minor = (struct drm_minor *)data;
#line 91
  dev = minor->dev;
#line 92
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 94
  len = 0;
#line 96
  if ((unsigned long )offset > 4016UL) {
#line 97
    *eof = 1;
#line 98
    return (0);
  } else {

  }
#line 101
  *start = buf + (unsigned long )offset;
#line 102
  *eof = 0;
#line 103
  tmp = sprintf(buf + (unsigned long )len, "Flushing:\n");
#line 103
  len = tmp + len;
#line 103
  if ((unsigned int )len > 4016U) {
#line 103
    *eof = 1;
#line 103
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 104
  __mptr = (struct list_head  const  *)dev_priv->mm.flushing_list.next;
#line 104
  obj_priv = (struct drm_i915_gem_object *)__mptr + 0xfffffffffffffff0UL;
#line 104
  goto ldv_23831;
  ldv_23830: 
#line 107
  obj = obj_priv->obj;
#line 108
  if (obj->name != 0) {
#line 109
    tmp___0 = sprintf(buf + (unsigned long )len, "    %p(%d): %08x %08x %d\n", obj,
                      obj->name, obj->read_domains, obj->write_domain, obj_priv->last_rendering_seqno);
#line 109
    len = tmp___0 + len;
#line 109
    if ((unsigned int )len > 4016U) {
#line 109
      *eof = 1;
#line 109
      return ((int )((unsigned int )len - (unsigned int )offset));
    } else {

    }
  } else {
#line 114
    tmp___1 = sprintf(buf + (unsigned long )len, "       %p: %08x %08x %d\n", obj,
                      obj->read_domains, obj->write_domain, obj_priv->last_rendering_seqno);
#line 114
    len = tmp___1 + len;
#line 114
    if ((unsigned int )len > 4016U) {
#line 114
      *eof = 1;
#line 114
      return ((int )((unsigned int )len - (unsigned int )offset));
    } else {

    }
  }
#line 104
  __mptr___0 = (struct list_head  const  *)obj_priv->list.next;
#line 104
  obj_priv = (struct drm_i915_gem_object *)__mptr___0 + 0xfffffffffffffff0UL;
  ldv_23831: 
#line 104
  __builtin_prefetch((void const   *)obj_priv->list.next);
#line 104
  if ((unsigned long )(& obj_priv->list) != (unsigned long )(& dev_priv->mm.flushing_list)) {
#line 105
    goto ldv_23830;
  } else {

  }

#line 119
  if ((off_t )len > (off_t )request + offset) {
#line 120
    return (request);
  } else {

  }
#line 121
  *eof = 1;
#line 122
  return ((int )((unsigned int )len - (unsigned int )offset));
}
}
#line 125 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
static int i915_gem_inactive_info(char *buf , char **start , off_t offset , int request ,
                                  int *eof , void *data ) 
{ 
  struct drm_minor *minor ;
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_object *obj_priv ;
  int len ;
  int tmp ;
  struct list_head  const  *__mptr ;
  struct drm_gem_object *obj ;
  int tmp___0 ;
  int tmp___1 ;
  struct list_head  const  *__mptr___0 ;

  {
#line 128
  minor = (struct drm_minor *)data;
#line 129
  dev = minor->dev;
#line 130
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 132
  len = 0;
#line 134
  if ((unsigned long )offset > 4016UL) {
#line 135
    *eof = 1;
#line 136
    return (0);
  } else {

  }
#line 139
  *start = buf + (unsigned long )offset;
#line 140
  *eof = 0;
#line 141
  tmp = sprintf(buf + (unsigned long )len, "Inactive:\n");
#line 141
  len = tmp + len;
#line 141
  if ((unsigned int )len > 4016U) {
#line 141
    *eof = 1;
#line 141
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 142
  __mptr = (struct list_head  const  *)dev_priv->mm.inactive_list.next;
#line 142
  obj_priv = (struct drm_i915_gem_object *)__mptr + 0xfffffffffffffff0UL;
#line 142
  goto ldv_23852;
  ldv_23851: 
#line 145
  obj = obj_priv->obj;
#line 146
  if (obj->name != 0) {
#line 147
    tmp___0 = sprintf(buf + (unsigned long )len, "    %p(%d): %08x %08x %d\n", obj,
                      obj->name, obj->read_domains, obj->write_domain, obj_priv->last_rendering_seqno);
#line 147
    len = tmp___0 + len;
#line 147
    if ((unsigned int )len > 4016U) {
#line 147
      *eof = 1;
#line 147
      return ((int )((unsigned int )len - (unsigned int )offset));
    } else {

    }
  } else {
#line 152
    tmp___1 = sprintf(buf + (unsigned long )len, "       %p: %08x %08x %d\n", obj,
                      obj->read_domains, obj->write_domain, obj_priv->last_rendering_seqno);
#line 152
    len = tmp___1 + len;
#line 152
    if ((unsigned int )len > 4016U) {
#line 152
      *eof = 1;
#line 152
      return ((int )((unsigned int )len - (unsigned int )offset));
    } else {

    }
  }
#line 142
  __mptr___0 = (struct list_head  const  *)obj_priv->list.next;
#line 142
  obj_priv = (struct drm_i915_gem_object *)__mptr___0 + 0xfffffffffffffff0UL;
  ldv_23852: 
#line 142
  __builtin_prefetch((void const   *)obj_priv->list.next);
#line 142
  if ((unsigned long )(& obj_priv->list) != (unsigned long )(& dev_priv->mm.inactive_list)) {
#line 143
    goto ldv_23851;
  } else {

  }

#line 157
  if ((off_t )len > (off_t )request + offset) {
#line 158
    return (request);
  } else {

  }
#line 159
  *eof = 1;
#line 160
  return ((int )((unsigned int )len - (unsigned int )offset));
}
}
#line 163 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
static int i915_gem_request_info(char *buf , char **start , off_t offset , int request ,
                                 int *eof , void *data ) 
{ 
  struct drm_minor *minor ;
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  struct drm_i915_gem_request *gem_request ;
  int len ;
  int tmp ;
  struct list_head  const  *__mptr ;
  int tmp___0 ;
  struct list_head  const  *__mptr___0 ;

  {
#line 166
  minor = (struct drm_minor *)data;
#line 167
  dev = minor->dev;
#line 168
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 170
  len = 0;
#line 172
  if ((unsigned long )offset > 4016UL) {
#line 173
    *eof = 1;
#line 174
    return (0);
  } else {

  }
#line 177
  *start = buf + (unsigned long )offset;
#line 178
  *eof = 0;
#line 179
  tmp = sprintf(buf + (unsigned long )len, "Request:\n");
#line 179
  len = tmp + len;
#line 179
  if ((unsigned int )len > 4016U) {
#line 179
    *eof = 1;
#line 179
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 180
  __mptr = (struct list_head  const  *)dev_priv->mm.request_list.next;
#line 180
  gem_request = (struct drm_i915_gem_request *)__mptr + 0xfffffffffffffff0UL;
#line 180
  goto ldv_23872;
  ldv_23871: 
#line 183
  tmp___0 = sprintf(buf + (unsigned long )len, "    %d @ %d\n", gem_request->seqno,
                    (int )((unsigned int )jiffies - (unsigned int )gem_request->emitted_jiffies));
#line 183
  len = tmp___0 + len;
#line 183
  if ((unsigned int )len > 4016U) {
#line 183
    *eof = 1;
#line 183
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 180
  __mptr___0 = (struct list_head  const  *)gem_request->list.next;
#line 180
  gem_request = (struct drm_i915_gem_request *)__mptr___0 + 0xfffffffffffffff0UL;
  ldv_23872: 
#line 180
  __builtin_prefetch((void const   *)gem_request->list.next);
#line 180
  if ((unsigned long )(& gem_request->list) != (unsigned long )(& dev_priv->mm.request_list)) {
#line 181
    goto ldv_23871;
  } else {

  }

#line 187
  if ((off_t )len > (off_t )request + offset) {
#line 188
    return (request);
  } else {

  }
#line 189
  *eof = 1;
#line 190
  return ((int )((unsigned int )len - (unsigned int )offset));
}
}
#line 193 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
static int i915_gem_seqno_info(char *buf , char **start , off_t offset , int request ,
                               int *eof , void *data ) 
{ 
  struct drm_minor *minor ;
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  int len ;
  uint32_t tmp ;
  int tmp___0 ;
  int tmp___1 ;
  int tmp___2 ;
  int tmp___3 ;

  {
#line 196
  minor = (struct drm_minor *)data;
#line 197
  dev = minor->dev;
#line 198
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 199
  len = 0;
#line 201
  if ((unsigned long )offset > 4016UL) {
#line 202
    *eof = 1;
#line 203
    return (0);
  } else {

  }
#line 206
  *start = buf + (unsigned long )offset;
#line 207
  *eof = 0;
#line 208
  if ((unsigned long )dev_priv->hw_status_page != (unsigned long )((void *)0)) {
#line 209
    tmp = i915_get_gem_seqno(dev);
#line 209
    tmp___0 = sprintf(buf + (unsigned long )len, "Current sequence: %d\n", tmp);
#line 209
    len = tmp___0 + len;
#line 209
    if ((unsigned int )len > 4016U) {
#line 209
      *eof = 1;
#line 209
      return ((int )((unsigned int )len - (unsigned int )offset));
    } else {

    }
  } else {
#line 212
    tmp___1 = sprintf(buf + (unsigned long )len, "Current sequence: hws uninitialized\n");
#line 212
    len = tmp___1 + len;
#line 212
    if ((unsigned int )len > 4016U) {
#line 212
      *eof = 1;
#line 212
      return ((int )((unsigned int )len - (unsigned int )offset));
    } else {

    }
  }
#line 214
  tmp___2 = sprintf(buf + (unsigned long )len, "Waiter sequence:  %d\n", dev_priv->mm.waiting_gem_seqno);
#line 214
  len = tmp___2 + len;
#line 214
  if ((unsigned int )len > 4016U) {
#line 214
    *eof = 1;
#line 214
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 216
  tmp___3 = sprintf(buf + (unsigned long )len, "IRQ sequence:     %d\n", dev_priv->mm.irq_gem_seqno);
#line 216
  len = tmp___3 + len;
#line 216
  if ((unsigned int )len > 4016U) {
#line 216
    *eof = 1;
#line 216
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 217
  if ((off_t )len > (off_t )request + offset) {
#line 218
    return (request);
  } else {

  }
#line 219
  *eof = 1;
#line 220
  return ((int )((unsigned int )len - (unsigned int )offset));
}
}
#line 224 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
static int i915_interrupt_info(char *buf , char **start , off_t offset , int request ,
                               int *eof , void *data ) 
{ 
  struct drm_minor *minor ;
  struct drm_device *dev ;
  drm_i915_private_t *dev_priv ;
  int len ;
  unsigned int tmp ;
  int tmp___0 ;
  unsigned int tmp___1 ;
  int tmp___2 ;
  unsigned int tmp___3 ;
  int tmp___4 ;
  unsigned int tmp___5 ;
  int tmp___6 ;
  unsigned int tmp___7 ;
  int tmp___8 ;
  int tmp___9 ;
  uint32_t tmp___10 ;
  int tmp___11 ;
  int tmp___12 ;
  int tmp___13 ;
  int tmp___14 ;

  {
#line 227
  minor = (struct drm_minor *)data;
#line 228
  dev = minor->dev;
#line 229
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 230
  len = 0;
#line 232
  if ((unsigned long )offset > 4016UL) {
#line 233
    *eof = 1;
#line 234
    return (0);
  } else {

  }
#line 237
  *start = buf + (unsigned long )offset;
#line 238
  *eof = 0;
#line 239
  tmp = readl((void const volatile   *)dev_priv->regs + 8352U);
#line 239
  tmp___0 = sprintf(buf + (unsigned long )len, "Interrupt enable:    %08x\n", tmp);
#line 239
  len = tmp___0 + len;
#line 239
  if ((unsigned int )len > 4016U) {
#line 239
    *eof = 1;
#line 239
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 241
  tmp___1 = readl((void const volatile   *)dev_priv->regs + 8356U);
#line 241
  tmp___2 = sprintf(buf + (unsigned long )len, "Interrupt identity:  %08x\n", tmp___1);
#line 241
  len = tmp___2 + len;
#line 241
  if ((unsigned int )len > 4016U) {
#line 241
    *eof = 1;
#line 241
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 243
  tmp___3 = readl((void const volatile   *)dev_priv->regs + 8360U);
#line 243
  tmp___4 = sprintf(buf + (unsigned long )len, "Interrupt mask:      %08x\n", tmp___3);
#line 243
  len = tmp___4 + len;
#line 243
  if ((unsigned int )len > 4016U) {
#line 243
    *eof = 1;
#line 243
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 245
  tmp___5 = readl((void const volatile   *)dev_priv->regs + 458788U);
#line 245
  tmp___6 = sprintf(buf + (unsigned long )len, "Pipe A stat:         %08x\n", tmp___5);
#line 245
  len = tmp___6 + len;
#line 245
  if ((unsigned int )len > 4016U) {
#line 245
    *eof = 1;
#line 245
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 247
  tmp___7 = readl((void const volatile   *)dev_priv->regs + 462884U);
#line 247
  tmp___8 = sprintf(buf + (unsigned long )len, "Pipe B stat:         %08x\n", tmp___7);
#line 247
  len = tmp___8 + len;
#line 247
  if ((unsigned int )len > 4016U) {
#line 247
    *eof = 1;
#line 247
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 249
  tmp___9 = sprintf(buf + (unsigned long )len, "Interrupts received: %d\n", dev_priv->irq_received.counter);
#line 249
  len = tmp___9 + len;
#line 249
  if ((unsigned int )len > 4016U) {
#line 249
    *eof = 1;
#line 249
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 251
  if ((unsigned long )dev_priv->hw_status_page != (unsigned long )((void *)0)) {
#line 252
    tmp___10 = i915_get_gem_seqno(dev);
#line 252
    tmp___11 = sprintf(buf + (unsigned long )len, "Current sequence:    %d\n", tmp___10);
#line 252
    len = tmp___11 + len;
#line 252
    if ((unsigned int )len > 4016U) {
#line 252
      *eof = 1;
#line 252
      return ((int )((unsigned int )len - (unsigned int )offset));
    } else {

    }
  } else {
#line 255
    tmp___12 = sprintf(buf + (unsigned long )len, "Current sequence:    hws uninitialized\n");
#line 255
    len = tmp___12 + len;
#line 255
    if ((unsigned int )len > 4016U) {
#line 255
      *eof = 1;
#line 255
      return ((int )((unsigned int )len - (unsigned int )offset));
    } else {

    }
  }
#line 257
  tmp___13 = sprintf(buf + (unsigned long )len, "Waiter sequence:     %d\n", dev_priv->mm.waiting_gem_seqno);
#line 257
  len = tmp___13 + len;
#line 257
  if ((unsigned int )len > 4016U) {
#line 257
    *eof = 1;
#line 257
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 259
  tmp___14 = sprintf(buf + (unsigned long )len, "IRQ sequence:        %d\n", dev_priv->mm.irq_gem_seqno);
#line 259
  len = tmp___14 + len;
#line 259
  if ((unsigned int )len > 4016U) {
#line 259
    *eof = 1;
#line 259
    return ((int )((unsigned int )len - (unsigned int )offset));
  } else {

  }
#line 261
  if ((off_t )len > (off_t )request + offset) {
#line 262
    return (request);
  } else {

  }
#line 263
  *eof = 1;
#line 264
  return ((int )((unsigned int )len - (unsigned int )offset));
}
}
#line 272 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
static struct drm_proc_list i915_gem_proc_list[6U]  = {      {"i915_gem_active", & i915_gem_active_info}, 
        {"i915_gem_flushing", & i915_gem_flushing_info}, 
        {"i915_gem_inactive", & i915_gem_inactive_info}, 
        {"i915_gem_request", & i915_gem_request_info}, 
        {"i915_gem_seqno", & i915_gem_seqno_info}, 
        {"i915_gem_interrupt", & i915_interrupt_info}};
#line 283 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
int i915_gem_proc_init(struct drm_minor *minor ) 
{ 
  struct proc_dir_entry *ent ;
  int i ;
  int j ;

  {
#line 288
  i = 0;
#line 288
  goto ldv_23919;
  ldv_23918: 
#line 289
  ent = create_proc_entry(i915_gem_proc_list[i].name, 33060U, minor->dev_root);
#line 291
  if ((unsigned long )ent == (unsigned long )((struct proc_dir_entry *)0)) {
#line 292
    printk("<3>[drm:%s] *ERROR* Cannot create /proc/dri/.../%s\n", "i915_gem_proc_init",
           i915_gem_proc_list[i].name);
#line 294
    j = 0;
#line 294
    goto ldv_23916;
    ldv_23915: 
#line 295
    remove_proc_entry(i915_gem_proc_list[i].name, minor->dev_root);
#line 294
    j = j + 1;
    ldv_23916: ;
#line 294
    if (j < i) {
#line 295
      goto ldv_23915;
    } else {

    }

#line 297
    return (-1);
  } else {

  }
#line 299
  ent->read_proc = i915_gem_proc_list[i].f;
#line 300
  ent->data = (void *)minor;
#line 288
  i = i + 1;
  ldv_23919: ;
#line 288
  if ((unsigned int )i <= 5U) {
#line 289
    goto ldv_23918;
  } else {

  }

#line 302
  return (0);
}
}
#line 305 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
void i915_gem_proc_cleanup(struct drm_minor *minor ) 
{ 
  int i ;

  {
#line 309
  if ((unsigned long )minor->dev_root == (unsigned long )((struct proc_dir_entry *)0)) {
#line 310
    return;
  } else {

  }
#line 312
  i = 0;
#line 312
  goto ldv_23926;
  ldv_23925: 
#line 313
  remove_proc_entry(i915_gem_proc_list[i].name, minor->dev_root);
#line 312
  i = i + 1;
  ldv_23926: ;
#line 312
  if ((unsigned int )i <= 5U) {
#line 313
    goto ldv_23925;
  } else {

  }

#line 317
  return;
}
}
#line 327 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
unsigned long ldv___get_free_pages_114(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 333
  ldv_check_alloc_flags(ldv_func_arg1);
#line 335
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 335
  return (tmp);
}
}
#line 349 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
void *ldv_kmem_cache_alloc_116(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 355
  ldv_check_alloc_flags(ldv_func_arg2);
#line 357
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 358
  return ((void *)0);
}
}
#line 393 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
void *ldv_kmem_cache_alloc_120(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 399
  ldv_check_alloc_flags(ldv_func_arg2);
#line 401
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 402
  return ((void *)0);
}
}
#line 436 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_proc.c.prepared"
struct page *ldv_alloc_page_vma_124(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                    unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 443
  ldv_check_alloc_flags(ldv_func_arg1);
#line 445
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 445
  return (tmp);
}
}
#line 227 "include/linux/gfp.h"
struct page *ldv_alloc_page_vma_140(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                    unsigned long ldv_func_arg3 ) ;
#line 239
unsigned long ldv___get_free_pages_130(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 207 "include/linux/slub_def.h"
void *ldv_kmem_cache_alloc_132(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_136(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 19 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/io.h"
__inline static unsigned short readw(void const volatile   *addr ) 
{ 
  unsigned short ret ;

  {
#line 19
  __asm__  volatile   ("movw %1,%0": "=r" (ret): "m" (*((unsigned short volatile   *)addr)): "memory");
#line 19
  return (ret);
}
}
#line 101 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_tiling.c.prepared"
void i915_gem_detect_bit_6_swizzle(struct drm_device *dev ) 
{ 
  drm_i915_private_t *dev_priv ;
  uint32_t swizzle_x ;
  uint32_t swizzle_y ;
  uint32_t dcc ;
  unsigned short tmp ;
  unsigned short tmp___0 ;

  {
#line 103
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 104
  swizzle_x = 5U;
#line 105
  swizzle_y = 5U;
#line 107
  if ((((((dev->pci_device != 9602 && dev->pci_device != 9610) && dev->pci_device != 9618) && dev->pci_device != 10098) && (dev->pci_device != 10146 && dev->pci_device != 10158)) && (((((((((dev->pci_device != 10610 && dev->pci_device != 10626) && dev->pci_device != 10642) && dev->pci_device != 10658) && dev->pci_device != 10754) && dev->pci_device != 10770) && dev->pci_device != 10818) && dev->pci_device != 11778) && dev->pci_device != 11794) && dev->pci_device != 11810)) && ((dev->pci_device != 10690 && dev->pci_device != 10674) && dev->pci_device != 10706)) {
#line 111
    swizzle_x = 0U;
#line 112
    swizzle_y = 0U;
  } else
#line 113
  if ((((((((((((dev->pci_device != 10610 && dev->pci_device != 10626) && dev->pci_device != 10642) && dev->pci_device != 10658) && dev->pci_device != 10754) && dev->pci_device != 10770) && dev->pci_device != 10818) && dev->pci_device != 11778) && dev->pci_device != 11794) && dev->pci_device != 11810) && ((dev->pci_device != 10690 && dev->pci_device != 10674) && dev->pci_device != 10706)) || dev->pci_device == 10754) || dev->pci_device == 10818) {
#line 124
    dcc = readl((void const volatile   *)dev_priv->regs + 66048U);
#line 125
    switch (dcc & 3U) {
    case 0U: ;
    case 1U: 
#line 128
    swizzle_x = 0U;
#line 129
    swizzle_y = 0U;
#line 130
    goto ldv_23800;
    case 2U: ;
#line 132
    if (((dev->pci_device == 9602 || dev->pci_device == 9610) || dev->pci_device == 9618) || (dcc & 1024U) != 0U) {
#line 134
      swizzle_x = 2U;
#line 135
      swizzle_y = 1U;
    } else
#line 136
    if ((dev->pci_device == 10754 || dev->pci_device == 10818) && (dcc & 512U) == 0U) {
#line 141
      swizzle_x = 4U;
#line 142
      swizzle_y = 3U;
    } else {
#line 145
      swizzle_x = 5U;
#line 146
      swizzle_y = 5U;
    }
#line 148
    goto ldv_23800;
    }
    ldv_23800: ;
#line 150
    if (dcc == 4294967295U) {
#line 151
      printk("<3>[drm:%s] *ERROR* Couldn\'t read from MCHBAR.  Disabling tiling.\n",
             "i915_gem_detect_bit_6_swizzle");
#line 153
      swizzle_x = 5U;
#line 154
      swizzle_y = 5U;
    } else {

    }
  } else {
#line 177
    tmp = readw((void const volatile   *)dev_priv->regs + 66054U);
#line 177
    tmp___0 = readw((void const volatile   *)dev_priv->regs + 67078U);
#line 177
    if ((int )tmp != (int )tmp___0) {
#line 178
      swizzle_x = 0U;
#line 179
      swizzle_y = 0U;
    } else {
#line 181
      swizzle_x = 2U;
#line 182
      swizzle_y = 1U;
    }
  }
#line 186
  dev_priv->mm.bit_6_swizzle_x = swizzle_x;
#line 187
  dev_priv->mm.bit_6_swizzle_y = swizzle_y;
#line 188
  return;
}
}
#line 195 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_tiling.c.prepared"
int i915_gem_set_tiling(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_set_tiling *args ;
  drm_i915_private_t *dev_priv ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;

  {
#line 198
  args = (struct drm_i915_gem_set_tiling *)data;
#line 199
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 203
  obj = drm_gem_object_lookup(dev, file_priv, (int )args->handle);
#line 204
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 205
    return (-22);
  } else {

  }
#line 206
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 208
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 210
  if (args->tiling_mode == 0U) {
#line 211
    obj_priv->tiling_mode = 0U;
#line 212
    args->swizzle_mode = 0U;
  } else {
#line 214
    if (args->tiling_mode == 1U) {
#line 215
      args->swizzle_mode = dev_priv->mm.bit_6_swizzle_x;
    } else {
#line 217
      args->swizzle_mode = dev_priv->mm.bit_6_swizzle_y;
    }
#line 219
    if (args->swizzle_mode == 5U) {
#line 220
      args->tiling_mode = 0U;
#line 221
      args->swizzle_mode = 0U;
    } else {

    }
  }
#line 224
  obj_priv->tiling_mode = args->tiling_mode;
#line 226
  mutex_unlock(& dev->struct_mutex);
#line 228
  drm_gem_object_unreference(obj);
#line 230
  return (0);
}
}
#line 237 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_tiling.c.prepared"
int i915_gem_get_tiling(struct drm_device *dev , void *data , struct drm_file *file_priv ) 
{ 
  struct drm_i915_gem_get_tiling *args ;
  drm_i915_private_t *dev_priv ;
  struct drm_gem_object *obj ;
  struct drm_i915_gem_object *obj_priv ;

  {
#line 240
  args = (struct drm_i915_gem_get_tiling *)data;
#line 241
  dev_priv = (drm_i915_private_t *)dev->dev_private;
#line 245
  obj = drm_gem_object_lookup(dev, file_priv, (int )args->handle);
#line 246
  if ((unsigned long )obj == (unsigned long )((struct drm_gem_object *)0)) {
#line 247
    return (-22);
  } else {

  }
#line 248
  obj_priv = (struct drm_i915_gem_object *)obj->driver_private;
#line 250
  mutex_lock_nested(& dev->struct_mutex, 0U);
#line 252
  args->tiling_mode = obj_priv->tiling_mode;
#line 253
  switch (obj_priv->tiling_mode) {
  case (uint32_t )1: 
#line 255
  args->swizzle_mode = dev_priv->mm.bit_6_swizzle_x;
#line 256
  goto ldv_23822;
  case (uint32_t )2: 
#line 258
  args->swizzle_mode = dev_priv->mm.bit_6_swizzle_y;
#line 259
  goto ldv_23822;
  case (uint32_t )0: 
#line 261
  args->swizzle_mode = 0U;
#line 262
  goto ldv_23822;
  default: 
#line 264
  printk("<3>[drm:%s] *ERROR* unknown tiling mode\n", "i915_gem_get_tiling");
  }
  ldv_23822: 
#line 267
  mutex_unlock(& dev->struct_mutex);
#line 269
  drm_gem_object_unreference(obj);
#line 271
  return (0);
}
}
#line 285 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_tiling.c.prepared"
unsigned long ldv___get_free_pages_130(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 291
  ldv_check_alloc_flags(ldv_func_arg1);
#line 293
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 293
  return (tmp);
}
}
#line 307 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_tiling.c.prepared"
void *ldv_kmem_cache_alloc_132(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 313
  ldv_check_alloc_flags(ldv_func_arg2);
#line 315
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 316
  return ((void *)0);
}
}
#line 351 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_tiling.c.prepared"
void *ldv_kmem_cache_alloc_136(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 357
  ldv_check_alloc_flags(ldv_func_arg2);
#line 359
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 360
  return ((void *)0);
}
}
#line 394 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_gem_tiling.c.prepared"
struct page *ldv_alloc_page_vma_140(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                    unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 401
  ldv_check_alloc_flags(ldv_func_arg1);
#line 403
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 403
  return (tmp);
}
}
#line 52 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/string_64.h"
extern int memcmp(void const   * , void const   * , size_t  ) ;
#line 227 "include/linux/gfp.h"
struct page *ldv_alloc_page_vma_156(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                    unsigned long ldv_func_arg3 ) ;
#line 239
unsigned long ldv___get_free_pages_146(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 207 "include/linux/slub_def.h"
void *ldv_kmem_cache_alloc_148(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_152(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 332 "include/acpi/acpi_bus.h"
extern int register_acpi_notifier(struct notifier_block * ) ;
#line 333
extern int unregister_acpi_notifier(struct notifier_block * ) ;
#line 577 "include/linux/pci.h"
extern int pci_bus_read_config_dword(struct pci_bus * , unsigned int  , int  , u32 * ) ;
#line 583
extern int pci_bus_write_config_dword(struct pci_bus * , unsigned int  , int  , u32  ) ;
#line 594 "include/linux/pci.h"
__inline static int pci_read_config_dword(struct pci_dev *dev , int where , u32 *val ) 
{ 
  int tmp ;

  {
#line 597
  tmp = pci_bus_read_config_dword(dev->bus, dev->devfn, where, val);
#line 597
  return (tmp);
}
}
#line 607 "include/linux/pci.h"
__inline static int pci_write_config_dword(struct pci_dev *dev , int where , u32 val ) 
{ 
  int tmp ;

  {
#line 610
  tmp = pci_bus_write_config_dword(dev->bus, dev->devfn, where, val);
#line 610
  return (tmp);
}
}
#line 154 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
static u32 asle_set_backlight(struct drm_device *dev , u32 bclp ) 
{ 
  struct drm_i915_private *dev_priv ;
  struct opregion_asle *asle ;
  u32 blc_pwm_ctl ;
  u32 blc_pwm_ctl2 ;

  {
#line 156
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 157
  asle = dev_priv->opregion.asle;
#line 160
  if ((int )bclp >= 0) {
#line 161
    return (8192U);
  } else {

  }
#line 163
  bclp = bclp & 2147483647U;
#line 164
  if (bclp > 255U) {
#line 165
    return (8192U);
  } else {

  }
#line 167
  blc_pwm_ctl = readl((void const volatile   *)dev_priv->regs + 397908U);
#line 168
  blc_pwm_ctl = blc_pwm_ctl & 4294901760U;
#line 169
  blc_pwm_ctl2 = readl((void const volatile   *)dev_priv->regs + 397904U);
#line 171
  if ((blc_pwm_ctl2 & 1073741824U) != 0U) {
#line 172
    pci_write_config_dword(dev->pdev, 244, bclp);
  } else {
#line 174
    writel((bclp * 257U - 1U) | blc_pwm_ctl, (void volatile   *)dev_priv->regs + 397908U);
  }
#line 176
  asle->cblv = (bclp * 100U) / 255U | 2147483648U;
#line 178
  return (0U);
}
}
#line 181 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
static u32 asle_set_als_illum(struct drm_device *dev , u32 alsi ) 
{ 


  {
#line 185
  return (0U);
}
}
#line 188 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
static u32 asle_set_pwm_freq(struct drm_device *dev , u32 pfmb ) 
{ 
  struct drm_i915_private *dev_priv ;
  u32 blc_pwm_ctl ;
  unsigned int tmp ;
  u32 pwm ;

  {
#line 190
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 191
  if ((int )pfmb < 0) {
#line 192
    tmp = readl((void const volatile   *)dev_priv->regs + 397908U);
#line 192
    blc_pwm_ctl = tmp;
#line 193
    pwm = pfmb & 2147483136U;
#line 194
    blc_pwm_ctl = blc_pwm_ctl & 65535U;
#line 195
    pwm = pwm >> 9;
  } else {

  }
#line 198
  return (0U);
}
}
#line 201 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
static u32 asle_set_pfit(struct drm_device *dev , u32 pfit ) 
{ 


  {
#line 205
  if ((int )pfit >= 0) {
#line 206
    return (32768U);
  } else {

  }
#line 207
  return (0U);
}
}
#line 210 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
void opregion_asle_intr(struct drm_device *dev ) 
{ 
  struct drm_i915_private *dev_priv ;
  struct opregion_asle *asle ;
  u32 asle_stat ;
  u32 asle_req ;
  u32 tmp ;
  u32 tmp___0 ;
  u32 tmp___1 ;
  u32 tmp___2 ;

  {
#line 212
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 213
  asle = dev_priv->opregion.asle;
#line 214
  asle_stat = 0U;
#line 217
  if ((unsigned long )asle == (unsigned long )((struct opregion_asle *)0)) {
#line 218
    return;
  } else {

  }
#line 220
  asle_req = asle->aslc & 15U;
#line 222
  if (asle_req == 0U) {
#line 223
    if (drm_debug != 0U) {
#line 223
      printk("<7>[drm:%s] non asle set request??\n", "opregion_asle_intr");
    } else {

    }
#line 224
    return;
  } else {

  }
#line 227
  if ((int )asle_req & 1) {
#line 228
    tmp = asle_set_als_illum(dev, asle->alsi);
#line 228
    asle_stat = tmp | asle_stat;
  } else {

  }
#line 230
  if ((asle_req & 2U) != 0U) {
#line 231
    tmp___0 = asle_set_backlight(dev, asle->bclp);
#line 231
    asle_stat = tmp___0 | asle_stat;
  } else {

  }
#line 233
  if ((asle_req & 4U) != 0U) {
#line 234
    tmp___1 = asle_set_pfit(dev, asle->pfit);
#line 234
    asle_stat = tmp___1 | asle_stat;
  } else {

  }
#line 236
  if ((asle_req & 8U) != 0U) {
#line 237
    tmp___2 = asle_set_pwm_freq(dev, asle->pfmb);
#line 237
    asle_stat = tmp___2 | asle_stat;
  } else {

  }
#line 239
  asle->aslc = asle_stat;
#line 240
  return;
}
}
#line 247 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
void opregion_enable_asle(struct drm_device *dev ) 
{ 
  struct drm_i915_private *dev_priv ;
  struct opregion_asle *asle ;

  {
#line 249
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 250
  asle = dev_priv->opregion.asle;
#line 252
  if ((unsigned long )asle != (unsigned long )((struct opregion_asle *)0)) {
#line 253
    if (((((dev->pci_device == 13687 || dev->pci_device == 13698) || dev->pci_device == 9618) || (dev->pci_device == 10146 || dev->pci_device == 10158)) || dev->pci_device == 10754) || dev->pci_device == 10818) {
#line 256
      ldv_spin_lock();
#line 257
      i915_enable_pipestat(dev_priv, 1, 4194304U);
#line 259
      ldv_spin_unlock();
    } else {

    }
#line 263
    asle->tche = 15U;
#line 265
    asle->ardy = 1U;
  } else {

  }
#line 267
  return;
}
}
#line 273 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
static struct intel_opregion *system_opregion  ;
#line 275 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
int intel_opregion_video_event(struct notifier_block *nb , unsigned long val , void *data ) 
{ 
  struct opregion_acpi *acpi ;

  {
#line 287
  if ((unsigned long )system_opregion == (unsigned long )((struct intel_opregion *)0)) {
#line 288
    return (0);
  } else {

  }
#line 290
  acpi = system_opregion->acpi;
#line 291
  acpi->csts = 0U;
#line 293
  return (1);
}
}
#line 296 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
static struct notifier_block intel_opregion_notifier  =    {& intel_opregion_video_event, 0, 0};
#line 300 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
int intel_opregion_init(struct drm_device *dev ) 
{ 
  struct drm_i915_private *dev_priv ;
  struct intel_opregion *opregion ;
  void *base ;
  u32 asls ;
  u32 mboxes ;
  int err ;
  int tmp ;

  {
#line 302
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 303
  opregion = & dev_priv->opregion;
#line 306
  err = 0;
#line 308
  pci_read_config_dword(dev->pdev, 252, & asls);
#line 309
  if (drm_debug != 0U) {
#line 309
    printk("<7>[drm:%s] graphic opregion physical addr: 0x%x\n", "intel_opregion_init",
           asls);
  } else {

  }
#line 310
  if (asls == 0U) {
#line 311
    if (drm_debug != 0U) {
#line 311
      printk("<7>[drm:%s] ACPI OpRegion not supported!\n", "intel_opregion_init");
    } else {

    }
#line 312
    return (-524);
  } else {

  }
#line 315
  base = ioremap((resource_size_t )asls, 8192UL);
#line 316
  if ((unsigned long )base == (unsigned long )((void *)0)) {
#line 317
    return (-12);
  } else {

  }
#line 319
  opregion->header = (struct opregion_header *)base;
#line 320
  tmp = memcmp((void const   *)(& (opregion->header)->signature), (void const   *)"IntelGraphicsMem",
               16UL);
#line 320
  if (tmp != 0) {
#line 321
    if (drm_debug != 0U) {
#line 321
      printk("<7>[drm:%s] opregion signature mismatch\n", "intel_opregion_init");
    } else {

    }
#line 322
    err = -22;
#line 323
    goto err_out;
  } else {

  }
#line 326
  mboxes = (opregion->header)->mboxes;
#line 327
  if ((int )mboxes & 1) {
#line 328
    if (drm_debug != 0U) {
#line 328
      printk("<7>[drm:%s] Public ACPI methods supported\n", "intel_opregion_init");
    } else {

    }
#line 329
    opregion->acpi = (struct opregion_acpi *)base + 256U;
  } else {
#line 331
    if (drm_debug != 0U) {
#line 331
      printk("<7>[drm:%s] Public ACPI methods not supported\n", "intel_opregion_init");
    } else {

    }
#line 332
    err = -524;
#line 333
    goto err_out;
  }
#line 335
  opregion->enabled = 1;
#line 337
  if ((mboxes & 2U) != 0U) {
#line 338
    if (drm_debug != 0U) {
#line 338
      printk("<7>[drm:%s] SWSCI supported\n", "intel_opregion_init");
    } else {

    }
#line 339
    opregion->swsci = (struct opregion_swsci *)base + 512U;
  } else {

  }
#line 341
  if ((mboxes & 4U) != 0U) {
#line 342
    if (drm_debug != 0U) {
#line 342
      printk("<7>[drm:%s] ASLE supported\n", "intel_opregion_init");
    } else {

    }
#line 343
    opregion->asle = (struct opregion_asle *)base + 768U;
  } else {

  }
#line 349
  (opregion->acpi)->csts = 0U;
#line 350
  (opregion->acpi)->drdy = 1U;
#line 352
  system_opregion = opregion;
#line 353
  register_acpi_notifier(& intel_opregion_notifier);
#line 355
  return (0);
  err_out: 
#line 358
  iounmap((void volatile   *)opregion->header);
#line 359
  opregion->header = 0;
#line 360
  return (err);
}
}
#line 363 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
void intel_opregion_free(struct drm_device *dev ) 
{ 
  struct drm_i915_private *dev_priv ;
  struct intel_opregion *opregion ;

  {
#line 365
  dev_priv = (struct drm_i915_private *)dev->dev_private;
#line 366
  opregion = & dev_priv->opregion;
#line 368
  if (opregion->enabled == 0) {
#line 369
    return;
  } else {

  }
#line 371
  (opregion->acpi)->drdy = 0U;
#line 373
  system_opregion = 0;
#line 374
  unregister_acpi_notifier(& intel_opregion_notifier);
#line 377
  iounmap((void volatile   *)opregion->header);
#line 378
  opregion->header = 0;
#line 379
  opregion->acpi = 0;
#line 380
  opregion->swsci = 0;
#line 381
  opregion->asle = 0;
#line 383
  opregion->enabled = 0;
#line 384
  return;
}
}
#line 423 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
void ldv_main9_sequence_infinite_withcheck_stateful(void) 
{ 
  struct notifier_block *var_group1 ;
  unsigned long var_intel_opregion_video_event_6_p1 ;
  void *var_intel_opregion_video_event_6_p2 ;
  int tmp ;
  int tmp___0 ;

  {
#line 486
  LDV_IN_INTERRUPT = 1;
#line 495
  ldv_initialize();
#line 499
  goto ldv_27372;
  ldv_27371: 
#line 502
  tmp = nondet_int();
#line 502
  switch (tmp) {
  case 0: 
#line 553
  ldv_handler_precall();
#line 554
  intel_opregion_video_event(var_group1, var_intel_opregion_video_event_6_p1, var_intel_opregion_video_event_6_p2);
#line 561
  goto ldv_27369;
  default: ;
#line 562
  goto ldv_27369;
  }
  ldv_27369: ;
  ldv_27372: 
#line 499
  tmp___0 = nondet_int();
#line 499
  if (tmp___0 != 0) {
#line 500
    goto ldv_27371;
  } else {

  }


#line 571
  ldv_check_final_state();
#line 574
  return;
}
}
#line 589 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
unsigned long ldv___get_free_pages_146(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 595
  ldv_check_alloc_flags(ldv_func_arg1);
#line 597
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 597
  return (tmp);
}
}
#line 611 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
void *ldv_kmem_cache_alloc_148(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 617
  ldv_check_alloc_flags(ldv_func_arg2);
#line 619
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 620
  return ((void *)0);
}
}
#line 655 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
void *ldv_kmem_cache_alloc_152(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 661
  ldv_check_alloc_flags(ldv_func_arg2);
#line 663
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 664
  return ((void *)0);
}
}
#line 698 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_opregion.c.prepared"
struct page *ldv_alloc_page_vma_156(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                    unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 705
  ldv_check_alloc_flags(ldv_func_arg1);
#line 707
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 707
  return (tmp);
}
}
#line 227 "include/linux/gfp.h"
struct page *ldv_alloc_page_vma_172(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                    unsigned long ldv_func_arg3 ) ;
#line 239
unsigned long ldv___get_free_pages_162(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) ;
#line 207 "include/linux/slub_def.h"
void *ldv_kmem_cache_alloc_164(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 211
void *ldv_kmem_cache_alloc_168(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) ;
#line 207 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/compat.h"
__inline static void *compat_alloc_user_space(long len ) 
{ 
  struct pt_regs *regs ;
  struct task_struct *tmp ;

  {
#line 209
  tmp = get_current();
#line 209
  regs = (struct pt_regs *)(tmp->thread.sp0 + 0xffffffffffffffffUL);
#line 210
  return ((void *)(regs->sp - (unsigned long )len));
}
}
#line 27 "include/linux/smp_lock.h"
extern void lock_kernel(void) ;
#line 28
extern void unlock_kernel(void) ;
#line 210 "/work/ldvuser/novikov/inst/current/envs/linux/linux/arch/x86/include/asm/uaccess.h"
extern void __put_user_bad(void) ;
#line 988 "include/drm/drmP.h"
extern long drm_compat_ioctl(struct file * , unsigned int  , unsigned long  ) ;
#line 61 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
static int compat_i915_batchbuffer(struct file *file , unsigned int cmd , unsigned long arg ) 
{ 
  drm_i915_batchbuffer32_t batchbuffer32 ;
  drm_i915_batchbuffer_t *batchbuffer ;
  unsigned long tmp ;
  void *tmp___0 ;
  unsigned long flag ;
  unsigned long roksum ;
  struct thread_info *tmp___1 ;
  long tmp___2 ;
  long __pu_err ;
  long __pu_err___0 ;
  long __pu_err___1 ;
  long __pu_err___2 ;
  long __pu_err___3 ;
  long __pu_err___4 ;
  int tmp___3 ;

  {
#line 67
  tmp = copy_from_user((void *)(& batchbuffer32), (void const   *)arg, 24U);
#line 67
  if (tmp != 0UL) {
#line 69
    return (-14);
  } else {

  }
#line 71
  tmp___0 = compat_alloc_user_space(32L);
#line 71
  batchbuffer = (drm_i915_batchbuffer_t *)tmp___0;
#line 72
  tmp___1 = current_thread_info();
#line 72
  __asm__  ("add %3,%1 ; sbb %0,%0 ; cmp %1,%4 ; sbb $0,%0": "=&r" (flag), "=r" (roksum): "1" (batchbuffer),
            "g" (32L), "rm" (tmp___1->addr_limit.seg));
#line 72
  tmp___2 = __builtin_expect(flag == 0UL, 1L);
#line 79
  if (tmp___2 == 0L) {
#line 81
    return (-14);
  } else {
#line 73
    __pu_err = 0L;
#line 73
    switch (4UL) {
    case 1UL: 
#line 73
    __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "iq" (batchbuffer32.start),
                         "m" (*((struct __large_struct *)(& batchbuffer->start))),
                         "i" (-14), "0" (__pu_err));
#line 73
    goto ldv_23308;
    case 2UL: 
#line 73
    __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "ir" (batchbuffer32.start),
                         "m" (*((struct __large_struct *)(& batchbuffer->start))),
                         "i" (-14), "0" (__pu_err));
#line 73
    goto ldv_23308;
    case 4UL: 
#line 73
    __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "ir" (batchbuffer32.start),
                         "m" (*((struct __large_struct *)(& batchbuffer->start))),
                         "i" (-14), "0" (__pu_err));
#line 73
    goto ldv_23308;
    case 8UL: 
#line 73
    __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "Zr" (batchbuffer32.start),
                         "m" (*((struct __large_struct *)(& batchbuffer->start))),
                         "i" (-14), "0" (__pu_err));
#line 73
    goto ldv_23308;
    default: 
#line 73
    __put_user_bad();
    }
    ldv_23308: ;
#line 79
    if (__pu_err != 0L) {
#line 81
      return (-14);
    } else {
#line 74
      __pu_err___0 = 0L;
#line 74
      switch (4UL) {
      case 1UL: 
#line 74
      __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "iq" (batchbuffer32.used),
                           "m" (*((struct __large_struct *)(& batchbuffer->used))),
                           "i" (-14), "0" (__pu_err___0));
#line 74
      goto ldv_23316;
      case 2UL: 
#line 74
      __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "ir" (batchbuffer32.used),
                           "m" (*((struct __large_struct *)(& batchbuffer->used))),
                           "i" (-14), "0" (__pu_err___0));
#line 74
      goto ldv_23316;
      case 4UL: 
#line 74
      __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "ir" (batchbuffer32.used),
                           "m" (*((struct __large_struct *)(& batchbuffer->used))),
                           "i" (-14), "0" (__pu_err___0));
#line 74
      goto ldv_23316;
      case 8UL: 
#line 74
      __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "Zr" (batchbuffer32.used),
                           "m" (*((struct __large_struct *)(& batchbuffer->used))),
                           "i" (-14), "0" (__pu_err___0));
#line 74
      goto ldv_23316;
      default: 
#line 74
      __put_user_bad();
      }
      ldv_23316: ;
#line 79
      if (__pu_err___0 != 0L) {
#line 81
        return (-14);
      } else {
#line 75
        __pu_err___1 = 0L;
#line 75
        switch (4UL) {
        case 1UL: 
#line 75
        __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "iq" (batchbuffer32.DR1),
                             "m" (*((struct __large_struct *)(& batchbuffer->DR1))),
                             "i" (-14), "0" (__pu_err___1));
#line 75
        goto ldv_23324;
        case 2UL: 
#line 75
        __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "ir" (batchbuffer32.DR1),
                             "m" (*((struct __large_struct *)(& batchbuffer->DR1))),
                             "i" (-14), "0" (__pu_err___1));
#line 75
        goto ldv_23324;
        case 4UL: 
#line 75
        __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "ir" (batchbuffer32.DR1),
                             "m" (*((struct __large_struct *)(& batchbuffer->DR1))),
                             "i" (-14), "0" (__pu_err___1));
#line 75
        goto ldv_23324;
        case 8UL: 
#line 75
        __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "Zr" (batchbuffer32.DR1),
                             "m" (*((struct __large_struct *)(& batchbuffer->DR1))),
                             "i" (-14), "0" (__pu_err___1));
#line 75
        goto ldv_23324;
        default: 
#line 75
        __put_user_bad();
        }
        ldv_23324: ;
#line 79
        if (__pu_err___1 != 0L) {
#line 81
          return (-14);
        } else {
#line 76
          __pu_err___2 = 0L;
#line 76
          switch (4UL) {
          case 1UL: 
#line 76
          __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "iq" (batchbuffer32.DR4),
                               "m" (*((struct __large_struct *)(& batchbuffer->DR4))),
                               "i" (-14), "0" (__pu_err___2));
#line 76
          goto ldv_23332;
          case 2UL: 
#line 76
          __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "ir" (batchbuffer32.DR4),
                               "m" (*((struct __large_struct *)(& batchbuffer->DR4))),
                               "i" (-14), "0" (__pu_err___2));
#line 76
          goto ldv_23332;
          case 4UL: 
#line 76
          __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "ir" (batchbuffer32.DR4),
                               "m" (*((struct __large_struct *)(& batchbuffer->DR4))),
                               "i" (-14), "0" (__pu_err___2));
#line 76
          goto ldv_23332;
          case 8UL: 
#line 76
          __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "Zr" (batchbuffer32.DR4),
                               "m" (*((struct __large_struct *)(& batchbuffer->DR4))),
                               "i" (-14), "0" (__pu_err___2));
#line 76
          goto ldv_23332;
          default: 
#line 76
          __put_user_bad();
          }
          ldv_23332: ;
#line 79
          if (__pu_err___2 != 0L) {
#line 81
            return (-14);
          } else {
#line 77
            __pu_err___3 = 0L;
#line 77
            switch (4UL) {
            case 1UL: 
#line 77
            __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___3): "iq" (batchbuffer32.num_cliprects),
                                 "m" (*((struct __large_struct *)(& batchbuffer->num_cliprects))),
                                 "i" (-14), "0" (__pu_err___3));
#line 77
            goto ldv_23340;
            case 2UL: 
#line 77
            __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___3): "ir" (batchbuffer32.num_cliprects),
                                 "m" (*((struct __large_struct *)(& batchbuffer->num_cliprects))),
                                 "i" (-14), "0" (__pu_err___3));
#line 77
            goto ldv_23340;
            case 4UL: 
#line 77
            __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___3): "ir" (batchbuffer32.num_cliprects),
                                 "m" (*((struct __large_struct *)(& batchbuffer->num_cliprects))),
                                 "i" (-14), "0" (__pu_err___3));
#line 77
            goto ldv_23340;
            case 8UL: 
#line 77
            __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___3): "Zr" (batchbuffer32.num_cliprects),
                                 "m" (*((struct __large_struct *)(& batchbuffer->num_cliprects))),
                                 "i" (-14), "0" (__pu_err___3));
#line 77
            goto ldv_23340;
            default: 
#line 77
            __put_user_bad();
            }
            ldv_23340: ;
#line 79
            if (__pu_err___3 != 0L) {
#line 81
              return (-14);
            } else {
#line 79
              __pu_err___4 = 0L;
#line 79
              switch (8UL) {
              case 1UL: 
#line 79
              __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___4): "iq" ((struct drm_clip_rect *)((unsigned long )batchbuffer32.cliprects)),
                                   "m" (*((struct __large_struct *)(& batchbuffer->cliprects))),
                                   "i" (-14), "0" (__pu_err___4));
#line 79
              goto ldv_23348;
              case 2UL: 
#line 79
              __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___4): "ir" ((struct drm_clip_rect *)((unsigned long )batchbuffer32.cliprects)),
                                   "m" (*((struct __large_struct *)(& batchbuffer->cliprects))),
                                   "i" (-14), "0" (__pu_err___4));
#line 79
              goto ldv_23348;
              case 4UL: 
#line 79
              __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___4): "ir" ((struct drm_clip_rect *)((unsigned long )batchbuffer32.cliprects)),
                                   "m" (*((struct __large_struct *)(& batchbuffer->cliprects))),
                                   "i" (-14), "0" (__pu_err___4));
#line 79
              goto ldv_23348;
              case 8UL: 
#line 79
              __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___4): "Zr" ((struct drm_clip_rect *)((unsigned long )batchbuffer32.cliprects)),
                                   "m" (*((struct __large_struct *)(& batchbuffer->cliprects))),
                                   "i" (-14), "0" (__pu_err___4));
#line 79
              goto ldv_23348;
              default: 
#line 79
              __put_user_bad();
              }
              ldv_23348: ;
#line 79
              if (__pu_err___4 != 0L) {
#line 81
                return (-14);
              } else {

              }
            }
          }
        }
      }
    }
  }
#line 83
  tmp___3 = drm_ioctl((file->f_path.dentry)->d_inode, file, 1075864643U, (unsigned long )batchbuffer);
#line 83
  return (tmp___3);
}
}
#line 97 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
static int compat_i915_cmdbuffer(struct file *file , unsigned int cmd , unsigned long arg ) 
{ 
  drm_i915_cmdbuffer32_t cmdbuffer32 ;
  drm_i915_cmdbuffer_t *cmdbuffer ;
  unsigned long tmp ;
  void *tmp___0 ;
  unsigned long flag ;
  unsigned long roksum ;
  struct thread_info *tmp___1 ;
  long tmp___2 ;
  long __pu_err ;
  long __pu_err___0 ;
  long __pu_err___1 ;
  long __pu_err___2 ;
  long __pu_err___3 ;
  long __pu_err___4 ;
  int tmp___3 ;

  {
#line 103
  tmp = copy_from_user((void *)(& cmdbuffer32), (void const   *)arg, 24U);
#line 103
  if (tmp != 0UL) {
#line 105
    return (-14);
  } else {

  }
#line 107
  tmp___0 = compat_alloc_user_space(32L);
#line 107
  cmdbuffer = (drm_i915_cmdbuffer_t *)tmp___0;
#line 108
  tmp___1 = current_thread_info();
#line 108
  __asm__  ("add %3,%1 ; sbb %0,%0 ; cmp %1,%4 ; sbb $0,%0": "=&r" (flag), "=r" (roksum): "1" (cmdbuffer),
            "g" (32L), "rm" (tmp___1->addr_limit.seg));
#line 108
  tmp___2 = __builtin_expect(flag == 0UL, 1L);
#line 115
  if (tmp___2 == 0L) {
#line 117
    return (-14);
  } else {
#line 109
    __pu_err = 0L;
#line 109
    switch (8UL) {
    case 1UL: 
#line 109
    __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "iq" ((char *)((unsigned long )cmdbuffer32.buf)),
                         "m" (*((struct __large_struct *)(& cmdbuffer->buf))), "i" (-14),
                         "0" (__pu_err));
#line 109
    goto ldv_23374;
    case 2UL: 
#line 109
    __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "ir" ((char *)((unsigned long )cmdbuffer32.buf)),
                         "m" (*((struct __large_struct *)(& cmdbuffer->buf))), "i" (-14),
                         "0" (__pu_err));
#line 109
    goto ldv_23374;
    case 4UL: 
#line 109
    __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "ir" ((char *)((unsigned long )cmdbuffer32.buf)),
                         "m" (*((struct __large_struct *)(& cmdbuffer->buf))), "i" (-14),
                         "0" (__pu_err));
#line 109
    goto ldv_23374;
    case 8UL: 
#line 109
    __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "Zr" ((char *)((unsigned long )cmdbuffer32.buf)),
                         "m" (*((struct __large_struct *)(& cmdbuffer->buf))), "i" (-14),
                         "0" (__pu_err));
#line 109
    goto ldv_23374;
    default: 
#line 109
    __put_user_bad();
    }
    ldv_23374: ;
#line 115
    if (__pu_err != 0L) {
#line 117
      return (-14);
    } else {
#line 111
      __pu_err___0 = 0L;
#line 111
      switch (4UL) {
      case 1UL: 
#line 111
      __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "iq" (cmdbuffer32.sz),
                           "m" (*((struct __large_struct *)(& cmdbuffer->sz))), "i" (-14),
                           "0" (__pu_err___0));
#line 111
      goto ldv_23382;
      case 2UL: 
#line 111
      __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "ir" (cmdbuffer32.sz),
                           "m" (*((struct __large_struct *)(& cmdbuffer->sz))), "i" (-14),
                           "0" (__pu_err___0));
#line 111
      goto ldv_23382;
      case 4UL: 
#line 111
      __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "ir" (cmdbuffer32.sz),
                           "m" (*((struct __large_struct *)(& cmdbuffer->sz))), "i" (-14),
                           "0" (__pu_err___0));
#line 111
      goto ldv_23382;
      case 8UL: 
#line 111
      __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "Zr" (cmdbuffer32.sz),
                           "m" (*((struct __large_struct *)(& cmdbuffer->sz))), "i" (-14),
                           "0" (__pu_err___0));
#line 111
      goto ldv_23382;
      default: 
#line 111
      __put_user_bad();
      }
      ldv_23382: ;
#line 115
      if (__pu_err___0 != 0L) {
#line 117
        return (-14);
      } else {
#line 112
        __pu_err___1 = 0L;
#line 112
        switch (4UL) {
        case 1UL: 
#line 112
        __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "iq" (cmdbuffer32.DR1),
                             "m" (*((struct __large_struct *)(& cmdbuffer->DR1))),
                             "i" (-14), "0" (__pu_err___1));
#line 112
        goto ldv_23390;
        case 2UL: 
#line 112
        __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "ir" (cmdbuffer32.DR1),
                             "m" (*((struct __large_struct *)(& cmdbuffer->DR1))),
                             "i" (-14), "0" (__pu_err___1));
#line 112
        goto ldv_23390;
        case 4UL: 
#line 112
        __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "ir" (cmdbuffer32.DR1),
                             "m" (*((struct __large_struct *)(& cmdbuffer->DR1))),
                             "i" (-14), "0" (__pu_err___1));
#line 112
        goto ldv_23390;
        case 8UL: 
#line 112
        __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "Zr" (cmdbuffer32.DR1),
                             "m" (*((struct __large_struct *)(& cmdbuffer->DR1))),
                             "i" (-14), "0" (__pu_err___1));
#line 112
        goto ldv_23390;
        default: 
#line 112
        __put_user_bad();
        }
        ldv_23390: ;
#line 115
        if (__pu_err___1 != 0L) {
#line 117
          return (-14);
        } else {
#line 113
          __pu_err___2 = 0L;
#line 113
          switch (4UL) {
          case 1UL: 
#line 113
          __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "iq" (cmdbuffer32.DR4),
                               "m" (*((struct __large_struct *)(& cmdbuffer->DR4))),
                               "i" (-14), "0" (__pu_err___2));
#line 113
          goto ldv_23398;
          case 2UL: 
#line 113
          __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "ir" (cmdbuffer32.DR4),
                               "m" (*((struct __large_struct *)(& cmdbuffer->DR4))),
                               "i" (-14), "0" (__pu_err___2));
#line 113
          goto ldv_23398;
          case 4UL: 
#line 113
          __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "ir" (cmdbuffer32.DR4),
                               "m" (*((struct __large_struct *)(& cmdbuffer->DR4))),
                               "i" (-14), "0" (__pu_err___2));
#line 113
          goto ldv_23398;
          case 8UL: 
#line 113
          __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "Zr" (cmdbuffer32.DR4),
                               "m" (*((struct __large_struct *)(& cmdbuffer->DR4))),
                               "i" (-14), "0" (__pu_err___2));
#line 113
          goto ldv_23398;
          default: 
#line 113
          __put_user_bad();
          }
          ldv_23398: ;
#line 115
          if (__pu_err___2 != 0L) {
#line 117
            return (-14);
          } else {
#line 114
            __pu_err___3 = 0L;
#line 114
            switch (4UL) {
            case 1UL: 
#line 114
            __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___3): "iq" (cmdbuffer32.num_cliprects),
                                 "m" (*((struct __large_struct *)(& cmdbuffer->num_cliprects))),
                                 "i" (-14), "0" (__pu_err___3));
#line 114
            goto ldv_23406;
            case 2UL: 
#line 114
            __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___3): "ir" (cmdbuffer32.num_cliprects),
                                 "m" (*((struct __large_struct *)(& cmdbuffer->num_cliprects))),
                                 "i" (-14), "0" (__pu_err___3));
#line 114
            goto ldv_23406;
            case 4UL: 
#line 114
            __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___3): "ir" (cmdbuffer32.num_cliprects),
                                 "m" (*((struct __large_struct *)(& cmdbuffer->num_cliprects))),
                                 "i" (-14), "0" (__pu_err___3));
#line 114
            goto ldv_23406;
            case 8UL: 
#line 114
            __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___3): "Zr" (cmdbuffer32.num_cliprects),
                                 "m" (*((struct __large_struct *)(& cmdbuffer->num_cliprects))),
                                 "i" (-14), "0" (__pu_err___3));
#line 114
            goto ldv_23406;
            default: 
#line 114
            __put_user_bad();
            }
            ldv_23406: ;
#line 115
            if (__pu_err___3 != 0L) {
#line 117
              return (-14);
            } else {
#line 115
              __pu_err___4 = 0L;
#line 115
              switch (8UL) {
              case 1UL: 
#line 115
              __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___4): "iq" ((struct drm_clip_rect *)((unsigned long )cmdbuffer32.cliprects)),
                                   "m" (*((struct __large_struct *)(& cmdbuffer->cliprects))),
                                   "i" (-14), "0" (__pu_err___4));
#line 115
              goto ldv_23414;
              case 2UL: 
#line 115
              __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___4): "ir" ((struct drm_clip_rect *)((unsigned long )cmdbuffer32.cliprects)),
                                   "m" (*((struct __large_struct *)(& cmdbuffer->cliprects))),
                                   "i" (-14), "0" (__pu_err___4));
#line 115
              goto ldv_23414;
              case 4UL: 
#line 115
              __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___4): "ir" ((struct drm_clip_rect *)((unsigned long )cmdbuffer32.cliprects)),
                                   "m" (*((struct __large_struct *)(& cmdbuffer->cliprects))),
                                   "i" (-14), "0" (__pu_err___4));
#line 115
              goto ldv_23414;
              case 8UL: 
#line 115
              __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___4): "Zr" ((struct drm_clip_rect *)((unsigned long )cmdbuffer32.cliprects)),
                                   "m" (*((struct __large_struct *)(& cmdbuffer->cliprects))),
                                   "i" (-14), "0" (__pu_err___4));
#line 115
              goto ldv_23414;
              default: 
#line 115
              __put_user_bad();
              }
              ldv_23414: ;
#line 115
              if (__pu_err___4 != 0L) {
#line 117
                return (-14);
              } else {

              }
            }
          }
        }
      }
    }
  }
#line 119
  tmp___3 = drm_ioctl((file->f_path.dentry)->d_inode, file, 1075864651U, (unsigned long )cmdbuffer);
#line 119
  return (tmp___3);
}
}
#line 127 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
static int compat_i915_irq_emit(struct file *file , unsigned int cmd , unsigned long arg ) 
{ 
  drm_i915_irq_emit32_t req32 ;
  drm_i915_irq_emit_t *request ;
  unsigned long tmp ;
  void *tmp___0 ;
  unsigned long flag ;
  unsigned long roksum ;
  struct thread_info *tmp___1 ;
  long tmp___2 ;
  long __pu_err ;
  int tmp___3 ;

  {
#line 133
  tmp = copy_from_user((void *)(& req32), (void const   *)arg, 4U);
#line 133
  if (tmp != 0UL) {
#line 134
    return (-14);
  } else {

  }
#line 136
  tmp___0 = compat_alloc_user_space(8L);
#line 136
  request = (drm_i915_irq_emit_t *)tmp___0;
#line 137
  tmp___1 = current_thread_info();
#line 137
  __asm__  ("add %3,%1 ; sbb %0,%0 ; cmp %1,%4 ; sbb $0,%0": "=&r" (flag), "=r" (roksum): "1" (request),
            "g" (8L), "rm" (tmp___1->addr_limit.seg));
#line 137
  tmp___2 = __builtin_expect(flag == 0UL, 1L);
#line 138
  if (tmp___2 == 0L) {
#line 140
    return (-14);
  } else {
#line 138
    __pu_err = 0L;
#line 138
    switch (8UL) {
    case 1UL: 
#line 138
    __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "iq" ((int *)((unsigned long )req32.irq_seq)),
                         "m" (*((struct __large_struct *)(& request->irq_seq))), "i" (-14),
                         "0" (__pu_err));
#line 138
    goto ldv_23435;
    case 2UL: 
#line 138
    __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "ir" ((int *)((unsigned long )req32.irq_seq)),
                         "m" (*((struct __large_struct *)(& request->irq_seq))), "i" (-14),
                         "0" (__pu_err));
#line 138
    goto ldv_23435;
    case 4UL: 
#line 138
    __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "ir" ((int *)((unsigned long )req32.irq_seq)),
                         "m" (*((struct __large_struct *)(& request->irq_seq))), "i" (-14),
                         "0" (__pu_err));
#line 138
    goto ldv_23435;
    case 8UL: 
#line 138
    __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "Zr" ((int *)((unsigned long )req32.irq_seq)),
                         "m" (*((struct __large_struct *)(& request->irq_seq))), "i" (-14),
                         "0" (__pu_err));
#line 138
    goto ldv_23435;
    default: 
#line 138
    __put_user_bad();
    }
    ldv_23435: ;
#line 138
    if (__pu_err != 0L) {
#line 140
      return (-14);
    } else {

    }
  }
#line 142
  tmp___3 = drm_ioctl((file->f_path.dentry)->d_inode, file, 3221775428U, (unsigned long )request);
#line 142
  return (tmp___3);
}
}
#line 150 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
static int compat_i915_getparam(struct file *file , unsigned int cmd , unsigned long arg ) 
{ 
  drm_i915_getparam32_t req32 ;
  drm_i915_getparam_t *request ;
  unsigned long tmp ;
  void *tmp___0 ;
  unsigned long flag ;
  unsigned long roksum ;
  struct thread_info *tmp___1 ;
  long tmp___2 ;
  long __pu_err ;
  long __pu_err___0 ;
  int tmp___3 ;

  {
#line 156
  tmp = copy_from_user((void *)(& req32), (void const   *)arg, 8U);
#line 156
  if (tmp != 0UL) {
#line 157
    return (-14);
  } else {

  }
#line 159
  tmp___0 = compat_alloc_user_space(16L);
#line 159
  request = (drm_i915_getparam_t *)tmp___0;
#line 160
  tmp___1 = current_thread_info();
#line 160
  __asm__  ("add %3,%1 ; sbb %0,%0 ; cmp %1,%4 ; sbb $0,%0": "=&r" (flag), "=r" (roksum): "1" (request),
            "g" (16L), "rm" (tmp___1->addr_limit.seg));
#line 160
  tmp___2 = __builtin_expect(flag == 0UL, 1L);
#line 162
  if (tmp___2 == 0L) {
#line 164
    return (-14);
  } else {
#line 161
    __pu_err = 0L;
#line 161
    switch (4UL) {
    case 1UL: 
#line 161
    __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "iq" (req32.param),
                         "m" (*((struct __large_struct *)(& request->param))), "i" (-14),
                         "0" (__pu_err));
#line 161
    goto ldv_23457;
    case 2UL: 
#line 161
    __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "ir" (req32.param),
                         "m" (*((struct __large_struct *)(& request->param))), "i" (-14),
                         "0" (__pu_err));
#line 161
    goto ldv_23457;
    case 4UL: 
#line 161
    __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "ir" (req32.param),
                         "m" (*((struct __large_struct *)(& request->param))), "i" (-14),
                         "0" (__pu_err));
#line 161
    goto ldv_23457;
    case 8UL: 
#line 161
    __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "Zr" (req32.param),
                         "m" (*((struct __large_struct *)(& request->param))), "i" (-14),
                         "0" (__pu_err));
#line 161
    goto ldv_23457;
    default: 
#line 161
    __put_user_bad();
    }
    ldv_23457: ;
#line 162
    if (__pu_err != 0L) {
#line 164
      return (-14);
    } else {
#line 162
      __pu_err___0 = 0L;
#line 162
      switch (8UL) {
      case 1UL: 
#line 162
      __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "iq" ((int *)((unsigned long )req32.value)),
                           "m" (*((struct __large_struct *)(& request->value))), "i" (-14),
                           "0" (__pu_err___0));
#line 162
      goto ldv_23465;
      case 2UL: 
#line 162
      __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "ir" ((int *)((unsigned long )req32.value)),
                           "m" (*((struct __large_struct *)(& request->value))), "i" (-14),
                           "0" (__pu_err___0));
#line 162
      goto ldv_23465;
      case 4UL: 
#line 162
      __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "ir" ((int *)((unsigned long )req32.value)),
                           "m" (*((struct __large_struct *)(& request->value))), "i" (-14),
                           "0" (__pu_err___0));
#line 162
      goto ldv_23465;
      case 8UL: 
#line 162
      __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "Zr" ((int *)((unsigned long )req32.value)),
                           "m" (*((struct __large_struct *)(& request->value))), "i" (-14),
                           "0" (__pu_err___0));
#line 162
      goto ldv_23465;
      default: 
#line 162
      __put_user_bad();
      }
      ldv_23465: ;
#line 162
      if (__pu_err___0 != 0L) {
#line 164
        return (-14);
      } else {

      }
    }
  }
#line 166
  tmp___3 = drm_ioctl((file->f_path.dentry)->d_inode, file, 3222299718U, (unsigned long )request);
#line 166
  return (tmp___3);
}
}
#line 177 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
static int compat_i915_alloc(struct file *file , unsigned int cmd , unsigned long arg ) 
{ 
  drm_i915_mem_alloc32_t req32 ;
  drm_i915_mem_alloc_t *request ;
  unsigned long tmp ;
  void *tmp___0 ;
  unsigned long flag ;
  unsigned long roksum ;
  struct thread_info *tmp___1 ;
  long tmp___2 ;
  long __pu_err ;
  long __pu_err___0 ;
  long __pu_err___1 ;
  long __pu_err___2 ;
  int tmp___3 ;

  {
#line 183
  tmp = copy_from_user((void *)(& req32), (void const   *)arg, 16U);
#line 183
  if (tmp != 0UL) {
#line 184
    return (-14);
  } else {

  }
#line 186
  tmp___0 = compat_alloc_user_space(24L);
#line 186
  request = (drm_i915_mem_alloc_t *)tmp___0;
#line 187
  tmp___1 = current_thread_info();
#line 187
  __asm__  ("add %3,%1 ; sbb %0,%0 ; cmp %1,%4 ; sbb $0,%0": "=&r" (flag), "=r" (roksum): "1" (request),
            "g" (24L), "rm" (tmp___1->addr_limit.seg));
#line 187
  tmp___2 = __builtin_expect(flag == 0UL, 1L);
#line 191
  if (tmp___2 == 0L) {
#line 193
    return (-14);
  } else {
#line 188
    __pu_err = 0L;
#line 188
    switch (4UL) {
    case 1UL: 
#line 188
    __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "iq" (req32.region),
                         "m" (*((struct __large_struct *)(& request->region))), "i" (-14),
                         "0" (__pu_err));
#line 188
    goto ldv_23489;
    case 2UL: 
#line 188
    __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "ir" (req32.region),
                         "m" (*((struct __large_struct *)(& request->region))), "i" (-14),
                         "0" (__pu_err));
#line 188
    goto ldv_23489;
    case 4UL: 
#line 188
    __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "ir" (req32.region),
                         "m" (*((struct __large_struct *)(& request->region))), "i" (-14),
                         "0" (__pu_err));
#line 188
    goto ldv_23489;
    case 8UL: 
#line 188
    __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err): "Zr" (req32.region),
                         "m" (*((struct __large_struct *)(& request->region))), "i" (-14),
                         "0" (__pu_err));
#line 188
    goto ldv_23489;
    default: 
#line 188
    __put_user_bad();
    }
    ldv_23489: ;
#line 191
    if (__pu_err != 0L) {
#line 193
      return (-14);
    } else {
#line 189
      __pu_err___0 = 0L;
#line 189
      switch (4UL) {
      case 1UL: 
#line 189
      __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "iq" (req32.alignment),
                           "m" (*((struct __large_struct *)(& request->alignment))),
                           "i" (-14), "0" (__pu_err___0));
#line 189
      goto ldv_23497;
      case 2UL: 
#line 189
      __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "ir" (req32.alignment),
                           "m" (*((struct __large_struct *)(& request->alignment))),
                           "i" (-14), "0" (__pu_err___0));
#line 189
      goto ldv_23497;
      case 4UL: 
#line 189
      __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "ir" (req32.alignment),
                           "m" (*((struct __large_struct *)(& request->alignment))),
                           "i" (-14), "0" (__pu_err___0));
#line 189
      goto ldv_23497;
      case 8UL: 
#line 189
      __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___0): "Zr" (req32.alignment),
                           "m" (*((struct __large_struct *)(& request->alignment))),
                           "i" (-14), "0" (__pu_err___0));
#line 189
      goto ldv_23497;
      default: 
#line 189
      __put_user_bad();
      }
      ldv_23497: ;
#line 191
      if (__pu_err___0 != 0L) {
#line 193
        return (-14);
      } else {
#line 190
        __pu_err___1 = 0L;
#line 190
        switch (4UL) {
        case 1UL: 
#line 190
        __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "iq" (req32.size),
                             "m" (*((struct __large_struct *)(& request->size))),
                             "i" (-14), "0" (__pu_err___1));
#line 190
        goto ldv_23505;
        case 2UL: 
#line 190
        __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "ir" (req32.size),
                             "m" (*((struct __large_struct *)(& request->size))),
                             "i" (-14), "0" (__pu_err___1));
#line 190
        goto ldv_23505;
        case 4UL: 
#line 190
        __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "ir" (req32.size),
                             "m" (*((struct __large_struct *)(& request->size))),
                             "i" (-14), "0" (__pu_err___1));
#line 190
        goto ldv_23505;
        case 8UL: 
#line 190
        __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___1): "Zr" (req32.size),
                             "m" (*((struct __large_struct *)(& request->size))),
                             "i" (-14), "0" (__pu_err___1));
#line 190
        goto ldv_23505;
        default: 
#line 190
        __put_user_bad();
        }
        ldv_23505: ;
#line 191
        if (__pu_err___1 != 0L) {
#line 193
          return (-14);
        } else {
#line 191
          __pu_err___2 = 0L;
#line 191
          switch (8UL) {
          case 1UL: 
#line 191
          __asm__  volatile   ("1:\tmovb %b1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "iq" ((int *)((unsigned long )req32.region_offset)),
                               "m" (*((struct __large_struct *)(& request->region_offset))),
                               "i" (-14), "0" (__pu_err___2));
#line 191
          goto ldv_23513;
          case 2UL: 
#line 191
          __asm__  volatile   ("1:\tmovw %w1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "ir" ((int *)((unsigned long )req32.region_offset)),
                               "m" (*((struct __large_struct *)(& request->region_offset))),
                               "i" (-14), "0" (__pu_err___2));
#line 191
          goto ldv_23513;
          case 4UL: 
#line 191
          __asm__  volatile   ("1:\tmovl %k1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "ir" ((int *)((unsigned long )req32.region_offset)),
                               "m" (*((struct __large_struct *)(& request->region_offset))),
                               "i" (-14), "0" (__pu_err___2));
#line 191
          goto ldv_23513;
          case 8UL: 
#line 191
          __asm__  volatile   ("1:\tmovq %1,%2\n2:\n.section .fixup,\"ax\"\n3:\tmov %3,%0\n\tjmp 2b\n.previous\n .section __ex_table,\"a\"\n .balign 8 \n .quad 1b,3b\n .previous\n": "=r" (__pu_err___2): "Zr" ((int *)((unsigned long )req32.region_offset)),
                               "m" (*((struct __large_struct *)(& request->region_offset))),
                               "i" (-14), "0" (__pu_err___2));
#line 191
          goto ldv_23513;
          default: 
#line 191
          __put_user_bad();
          }
          ldv_23513: ;
#line 191
          if (__pu_err___2 != 0L) {
#line 193
            return (-14);
          } else {

          }
        }
      }
    }
  }
#line 195
  tmp___3 = drm_ioctl((file->f_path.dentry)->d_inode, file, 3222824008U, (unsigned long )request);
#line 195
  return (tmp___3);
}
}
#line 199 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
drm_ioctl_compat_t *i915_compat_ioctls[12U]  = 
#line 199
  {      0,      0,      0,      & compat_i915_batchbuffer, 
        & compat_i915_irq_emit,      0,      & compat_i915_getparam,      0, 
        & compat_i915_alloc,      0,      0,      & compat_i915_cmdbuffer};
#line 216 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
long i915_compat_ioctl(struct file *filp , unsigned int cmd , unsigned long arg ) 
{ 
  unsigned int nr ;
  drm_ioctl_compat_t *fn ;
  int ret ;
  long tmp ;

  {
#line 218
  nr = cmd & 255U;
#line 219
  fn = 0;
#line 222
  if (nr <= 63U) {
#line 223
    tmp = drm_compat_ioctl(filp, cmd, arg);
#line 223
    return (tmp);
  } else {

  }
#line 225
  if (nr <= 75U) {
#line 226
    fn = i915_compat_ioctls[nr - 64U];
  } else {

  }
#line 228
  lock_kernel();
#line 229
  if ((unsigned long )fn != (unsigned long )((drm_ioctl_compat_t *)0)) {
#line 230
    ret = (*fn)(filp, cmd, arg);
  } else {
#line 232
    ret = drm_ioctl((filp->f_path.dentry)->d_inode, filp, cmd, arg);
  }
#line 233
  unlock_kernel();
#line 235
  return ((long )ret);
}
}
#line 249 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
unsigned long ldv___get_free_pages_162(gfp_t ldv_func_arg1 , unsigned int ldv_func_arg2 ) 
{ 
  unsigned long tmp ;

  {
#line 255
  ldv_check_alloc_flags(ldv_func_arg1);
#line 257
  tmp = __get_free_pages(ldv_func_arg1, ldv_func_arg2);
#line 257
  return (tmp);
}
}
#line 271 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
void *ldv_kmem_cache_alloc_164(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 277
  ldv_check_alloc_flags(ldv_func_arg2);
#line 279
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 280
  return ((void *)0);
}
}
#line 315 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
void *ldv_kmem_cache_alloc_168(struct kmem_cache *ldv_func_arg1 , gfp_t ldv_func_arg2 ) 
{ 


  {
#line 321
  ldv_check_alloc_flags(ldv_func_arg2);
#line 323
  kmem_cache_alloc(ldv_func_arg1, ldv_func_arg2);
#line 324
  return ((void *)0);
}
}
#line 358 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/dscv/ri/43_1a/drivers/gpu/drm/i915/i915_ioc32.c.prepared"
struct page *ldv_alloc_page_vma_172(gfp_t ldv_func_arg1 , struct vm_area_struct *ldv_func_arg2 ,
                                    unsigned long ldv_func_arg3 ) 
{ 
  struct page *tmp ;

  {
#line 365
  ldv_check_alloc_flags(ldv_func_arg1);
#line 367
  tmp = alloc_page_vma(ldv_func_arg1, ldv_func_arg2, ldv_func_arg3);
#line 367
  return (tmp);
}
}
#line 10 "/home/ldvuser/ldv/inst/kernel-rules/verifier/rcv.h"
__inline static void ldv_error(void) 
{ 


  {
  LDV_ERROR: 
#line 12
  goto LDV_ERROR;
}
}
#line 25
extern int ldv_undef_int(void) ;
#line 49 "/home/ldvuser/ldv/inst/kernel-rules/verifier/rcv.h"
long __builtin_expect(long exp , long c ) 
{ 


  {
#line 51
  return (exp);
}
}
#line 21 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/rule-instrumentor/43_1a/common-model/ldv_common_model.c"
int ldv_spin  =    LDV_SPIN_UNLOCKED;
#line 25 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/rule-instrumentor/43_1a/common-model/ldv_common_model.c"
void ldv_check_alloc_flags(gfp_t flags ) 
{ 


  {
#line 28
  if (ldv_spin == LDV_SPIN_UNLOCKED || flags == 32U) {

  } else {
#line 28
    ldv_error();
  }
#line 29
  return;
}
}
#line 31
extern struct page *ldv_some_page(void) ;
#line 34 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/rule-instrumentor/43_1a/common-model/ldv_common_model.c"
struct page *ldv_check_alloc_flags_and_return_some_page(gfp_t flags ) 
{ 
  struct page *tmp ;

  {
#line 37
  if (ldv_spin == LDV_SPIN_UNLOCKED || flags == 32U) {

  } else {
#line 37
    ldv_error();
  }
#line 39
  tmp = ldv_some_page();
#line 39
  return (tmp);
}
}
#line 43 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/rule-instrumentor/43_1a/common-model/ldv_common_model.c"
void ldv_check_alloc_nonatomic(void) 
{ 


  {
#line 46
  if (ldv_spin == LDV_SPIN_UNLOCKED) {

  } else {
#line 46
    ldv_error();
  }
#line 47
  return;
}
}
#line 50 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/rule-instrumentor/43_1a/common-model/ldv_common_model.c"
void ldv_spin_lock(void) 
{ 


  {
#line 53
  ldv_spin = LDV_SPIN_LOCKED;
#line 54
  return;
}
}
#line 57 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/rule-instrumentor/43_1a/common-model/ldv_common_model.c"
void ldv_spin_unlock(void) 
{ 


  {
#line 60
  ldv_spin = LDV_SPIN_UNLOCKED;
#line 61
  return;
}
}
#line 64 "/work/ldvuser/novikov/work/current--X--drivers/gpu/drm/i915/i915.ko--X--defaultlinux--X--43_1a--X--cpachecker/linux/csd_deg_dscv/21/dscv_tempdir/rule-instrumentor/43_1a/common-model/ldv_common_model.c"
int ldv_spin_trylock(void) 
{ 
  int is_lock ;

  {
#line 69
  is_lock = ldv_undef_int();
#line 71
  if (is_lock) {
#line 74
    return (0);
  } else {
#line 79
    ldv_spin = LDV_SPIN_LOCKED;
#line 81
    return (1);
  }
}
}
